{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb5a447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50dfaafc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn import preprocessing\n",
    "from scipy.special import expit\n",
    "\n",
    "from numpy.random import default_rng\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import time\n",
    "\n",
    "from ffaAnn_V_I import *\n",
    "\n",
    "\n",
    "\n",
    "class MultiLayerPerceptron():\n",
    "    # ================== Activation Functions ================ #\n",
    "\n",
    "    # accepts a vector or list and returns a list after performing corresponding function on all elements\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(vectorSig):\n",
    "        \"\"\"returns 1/(1+exp(-x)), where the output values lies between zero and one\"\"\"\n",
    "        sig = expit(vectorSig)\n",
    "        return sig\n",
    "\n",
    "    @staticmethod\n",
    "    def binaryStep(x):\n",
    "        \"\"\" It returns '0' is the input is less then zero otherwise it returns one \"\"\"\n",
    "        return np.heaviside(x, 1)\n",
    "\n",
    "    @staticmethod\n",
    "    def linear(x):\n",
    "        \"\"\" y = f(x) It returns the input as it is\"\"\"\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def tanh(x):\n",
    "        \"\"\" It returns the value (1-exp(-2x))/(1+exp(-2x)) and the value returned will be lies in between -1 to 1\"\"\"\n",
    "        return np.tanh(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def relu(x):  # Rectified Linear Unit\n",
    "        \"\"\" It returns zero if the input is less than zero otherwise it returns the given input\"\"\"\n",
    "        x1 = []\n",
    "        for i in x:\n",
    "            if i < 0:\n",
    "                x1.append(0)\n",
    "            else:\n",
    "                x1.append(i)\n",
    "\n",
    "        return x1\n",
    "\n",
    "    @staticmethod\n",
    "    def leakyRelu(x):\n",
    "        \"\"\" It returns zero if the input is less than zero otherwise it returns the given input\"\"\"\n",
    "        x1 = []\n",
    "        for i in x:\n",
    "            if i < 0:\n",
    "                x1.append((0.01 * i))\n",
    "            else:\n",
    "                x1.append(i)\n",
    "\n",
    "        return x1\n",
    "\n",
    "    @staticmethod\n",
    "    def parametricRelu(self, a, x):\n",
    "        \"\"\" It returns zero if the input is less than zero otherwise it returns the given input\"\"\"\n",
    "        x1 = []\n",
    "        for i in x:\n",
    "            if i < 0:\n",
    "                x1.append((a * i))\n",
    "            else:\n",
    "                x1.append(i)\n",
    "\n",
    "        return x1\n",
    "\n",
    "    @staticmethod\n",
    "    def softmax(self, x):\n",
    "        \"\"\" Compute softmax values for each sets of scores in x\"\"\"\n",
    "        return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "    # ============ Activation Functions Part Ends ============= #\n",
    "\n",
    "    # ================= Distance Calculation ================== #\n",
    "\n",
    "    @staticmethod\n",
    "    def chebishev(self, cord1, cord2, exponent_h):\n",
    "        dist = 0.0\n",
    "        if ((type(cord1) == int and type(cord2) == int) or ((type(cord1) == float and type(cord2) == float))):\n",
    "            dist = math.pow((cord1 - cord2), exponent_h)\n",
    "        else:\n",
    "            for i, j in zip(cord1, cord2):\n",
    "                dist += math.pow((i - j), exponent_h)\n",
    "        dist = math.pow(dist, (1.0 / exponent_h))\n",
    "        return dist\n",
    "\n",
    "    @staticmethod\n",
    "    def minimum_distance(self, cord1, cord2):\n",
    "        # min(|x1-y1|, |x2-y2|, |x3-y3|, ...)\n",
    "        dist = float('inf')\n",
    "        if ((type(cord1) == int and type(cord2) == int) or ((type(cord1) == float and type(cord2) == float))):\n",
    "            dist = math.fabs(cord1 - cord2)\n",
    "        else:\n",
    "            for i, j in zip(cord1, cord2):\n",
    "                temp_dist = math.fabs(i - j)\n",
    "                if (temp_dist < dist):\n",
    "                    dist = temp_dist\n",
    "        return dist\n",
    "\n",
    "    @staticmethod\n",
    "    def maximum_distance(self, cord1, cord2):\n",
    "        # max(|x1-y1|, |x2-y2|, |x3-y3|, ...)\n",
    "        dist = float('-inf')\n",
    "        if ((type(cord1) == int and type(cord2) == int) or ((type(cord1) == float and type(cord2) == float))):\n",
    "            dist = math.fabs(cord1 - cord2)\n",
    "        else:\n",
    "            for i, j in zip(cord1, cord2):\n",
    "                temp_dist = math.fabs(i - j)\n",
    "                if (temp_dist > dist):\n",
    "                    dist = temp_dist\n",
    "        return dist\n",
    "\n",
    "    @staticmethod\n",
    "    def manhattan(self, cord1, cord2):\n",
    "        # |x1-y1| + |x2-y2| + |x3-y3| + ...\n",
    "        dist = 0.0\n",
    "        if ((type(cord1) == int and type(cord2) == int) or ((type(cord1) == float and type(cord2) == float))):\n",
    "            dist = math.fabs(cord1 - cord2)\n",
    "        else:\n",
    "            for i, j in zip(cord1, cord2):\n",
    "                dist += math.fabs(i - j)\n",
    "        return dist\n",
    "\n",
    "    @staticmethod\n",
    "    def eucledian(self, cord1, cord2):\n",
    "        dist = 0.0\n",
    "        if ((type(cord1) == int and type(cord2) == int) or ((type(cord1) == float and type(cord2) == float))):\n",
    "            dist = math.pow((cord1 - cord2), 2)\n",
    "        else:\n",
    "            for i, j in zip(cord1, cord2):\n",
    "                dist += math.pow((i - j), 2)\n",
    "        return math.pow(dist, 0.5)\n",
    "\n",
    "    # =========== Distance Calculation Ends ============== #\n",
    "\n",
    "    def __init__(self, dimensions=(8, 5), all_weights=(0.1, 0.2), fileName=\"iris\"):\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dimensions : dimension of the neural network\n",
    "            all_weights : the optimal weights we get from the bio-algoANN models\n",
    "        \"\"\"\n",
    "\n",
    "        self.allPop_Weights = []\n",
    "        self.allPopl_Chromosomes = []\n",
    "        self.allPop_ReceivedOut = []\n",
    "        self.allPop_ErrorVal = []\n",
    "\n",
    "        self.all_weights = all_weights\n",
    "\n",
    "        self.fitness = []\n",
    "\n",
    "        # ================== Input dataset and corresponding output ========================= #\n",
    "\n",
    "        self.fileName = fileName\n",
    "        self.fileName += \".csv\"\n",
    "        data = pd.read_csv(self.fileName)\n",
    "\n",
    "        classes = []\n",
    "        output_values_expected = []\n",
    "        input_values = []\n",
    "\n",
    "        # ~~~~ encoding ~~~~#\n",
    "\n",
    "        # labelencoder = LabelEncoder()\n",
    "        # data[data.columns[-1]] = labelencoder.fit_transform(data[data.columns[-1]])\n",
    "\n",
    "        # one hot encoding - for multi-column\n",
    "        # enc = OneHotEncoder(handle_unknown='ignore')\n",
    "        # combinedData = np.vstack((data[data.columns[-2]], data[data.columns[-1]])).T\n",
    "        # print(combinedData)\n",
    "        # y = enc.fit_transform(combinedData).toarray()\n",
    "        # y = OneHotEncoder().fit_transform(combinedData).toarray()\n",
    "\n",
    "        #\n",
    "        y = LabelBinarizer().fit_transform(data[data.columns[-1]])\n",
    "        # print(y)\n",
    "\n",
    "        # ~~~~ encoding ends~~~~#\n",
    "\n",
    "        for j in range(len(data)):\n",
    "            output_values_expected.append(y[j])\n",
    "\n",
    "        # print(output_values_expected)\n",
    "\n",
    "        input_values = []\n",
    "        for j in range(len(data)):\n",
    "            b = []\n",
    "            for i in range(1, len(data.columns) - 1):\n",
    "                b.append(data[data.columns[i]][j])\n",
    "            input_values.append(b)\n",
    "\n",
    "        self.X = input_values[:]\n",
    "        self.Y = output_values_expected[:]\n",
    "\n",
    "        # input and output\n",
    "        self.X = input_values[:]\n",
    "        self.Y = output_values_expected[:]\n",
    "\n",
    "        self.dimension = dimensions\n",
    "        # print(self.dimension)\n",
    "\n",
    "        # ================ Finding Initial Weights ================ #\n",
    "\n",
    "        self.pop = []  # weights\n",
    "        reshaped_all_weights = []\n",
    "        start = 0\n",
    "        for i in range(len(self.dimension) - 1):\n",
    "            end = start + self.dimension[i + 1] * self.dimension[i]\n",
    "            temp_arr = self.all_weights[start:end]\n",
    "            w = np.reshape(temp_arr[:], (self.dimension[i + 1], self.dimension[i]))\n",
    "            reshaped_all_weights.append(w)\n",
    "            start = end\n",
    "        self.pop.append(reshaped_all_weights)\n",
    "\n",
    "        self.init_pop = self.all_weights\n",
    "\n",
    "    # ================ Initial Weights Part Ends ================ #\n",
    "\n",
    "\n",
    "    def Predict(self, chromo):\n",
    "        # X, Y and pop are used\n",
    "        self.fitness = []\n",
    "        total_error = 0\n",
    "        m_arr = []\n",
    "        k1 = 0\n",
    "        for i in range(len(self.dimension) - 1):\n",
    "            p = self.dimension[i]\n",
    "            q = self.dimension[i + 1]\n",
    "            k2 = k1 + p * q\n",
    "            m_temp = chromo[k1:k2]\n",
    "            m_arr.append(np.reshape(m_temp, (p, q)))\n",
    "            k1 = k2\n",
    "\n",
    "        y_predicted = []\n",
    "        for x, y in zip(self.X, self.Y):\n",
    "\n",
    "            yo = x\n",
    "\n",
    "            for mCount in range(len(m_arr)):\n",
    "                yo = np.dot(yo, m_arr[mCount])\n",
    "                yo = self.sigmoid(yo)\n",
    "            \n",
    "            # converting to sklearn acceptable form\n",
    "            max_yo = max(yo)\n",
    "            for y_vals in range(len(yo)):\n",
    "                if(yo[y_vals] == max_yo):\n",
    "                    yo[y_vals] = 1\n",
    "                else:\n",
    "                    yo[y_vals] = 0\n",
    "            y_predicted.append(yo)\n",
    "        return (y_predicted, self.Y)\n",
    "\n",
    "    def main(self):\n",
    "        Y_PREDICT, Y_ACTUAL = self.Predict(self.init_pop)\n",
    "        Y_PREDICT = np.array(Y_PREDICT)\n",
    "        Y_ACTUAL = np.array(Y_ACTUAL)\n",
    "        \n",
    "        n_classes = 3\n",
    "        \n",
    "        label_binarizer = LabelBinarizer()\n",
    "        label_binarizer.fit(range(n_classes))\n",
    "        Y_PREDICT = label_binarizer.inverse_transform(np.array(Y_PREDICT))\n",
    "        Y_ACTUAL = label_binarizer.inverse_transform(np.array(Y_ACTUAL))\n",
    "        \n",
    "        # find error\n",
    "        \n",
    "        print(\"\\n Actual / Expected\", Y_ACTUAL)\n",
    "        print(\"\\n Predictions\", Y_PREDICT)\n",
    "        print(\"\\n\\nConfusion Matrix\")\n",
    "        print(confusion_matrix(Y_ACTUAL, Y_PREDICT))\n",
    "        \n",
    "        print(\"\\n\\nClassification Report\")\n",
    "        target_names = ['class 0', 'class 1', 'class 2']\n",
    "        print(classification_report(Y_ACTUAL, Y_PREDICT, target_names=target_names))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d36914a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for inputting data :  0.009975194931030273\n",
      "============ Calling FFA to get best weights ===============\n",
      "--------------GENERATION 0-----------\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "--------------GENERATION 1-----------\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "--------------GENERATION 2-----------\n",
      "hi\n",
      "hi\n",
      "--------------GENERATION 3-----------\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "--------------GENERATION 4-----------\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "--------------GENERATION 5-----------\n",
      "hi\n",
      "hi\n",
      "--------------GENERATION 6-----------\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "--------------GENERATION 7-----------\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "--------------GENERATION 8-----------\n",
      "hi\n",
      "hi\n",
      "--------------GENERATION 9-----------\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "--------------GENERATION 10-----------\n",
      "hi\n",
      "hi\n",
      "--------------GENERATION 11-----------\n",
      "hi\n",
      "hi\n",
      "--------------GENERATION 12-----------\n",
      "hi\n",
      "--------------GENERATION 13-----------\n",
      "hi\n",
      "--------------GENERATION 14-----------\n",
      "--------------GENERATION 15-----------\n",
      "hi\n",
      "--------------GENERATION 16-----------\n",
      "--------------GENERATION 17-----------\n",
      "--------------GENERATION 18-----------\n",
      "--------------GENERATION 19-----------\n",
      "--------------GENERATION 20-----------\n",
      "--------------GENERATION 21-----------\n",
      "--------------GENERATION 22-----------\n",
      "--------------GENERATION 23-----------\n",
      "--------------GENERATION 24-----------\n",
      "--------------GENERATION 25-----------\n",
      "--------------GENERATION 26-----------\n",
      "--------------GENERATION 27-----------\n",
      "--------------GENERATION 28-----------\n",
      "--------------GENERATION 29-----------\n",
      "--------------GENERATION 30-----------\n",
      "--------------GENERATION 31-----------\n",
      "--------------GENERATION 32-----------\n",
      "--------------GENERATION 33-----------\n",
      "--------------GENERATION 34-----------\n",
      "--------------GENERATION 35-----------\n",
      "--------------GENERATION 36-----------\n",
      "--------------GENERATION 37-----------\n",
      "--------------GENERATION 38-----------\n",
      "--------------GENERATION 39-----------\n",
      "--------------GENERATION 40-----------\n",
      "--------------GENERATION 41-----------\n",
      "--------------GENERATION 42-----------\n",
      "--------------GENERATION 43-----------\n",
      "--------------GENERATION 44-----------\n",
      "--------------GENERATION 45-----------\n",
      "--------------GENERATION 46-----------\n",
      "--------------GENERATION 47-----------\n",
      "--------------GENERATION 48-----------\n",
      "--------------GENERATION 49-----------\n",
      "--------------GENERATION 50-----------\n",
      "--------------GENERATION 51-----------\n",
      "--------------GENERATION 52-----------\n",
      "--------------GENERATION 53-----------\n",
      "--------------GENERATION 54-----------\n",
      "--------------GENERATION 55-----------\n",
      "--------------GENERATION 56-----------\n",
      "--------------GENERATION 57-----------\n",
      "--------------GENERATION 58-----------\n",
      "--------------GENERATION 59-----------\n",
      "--------------GENERATION 60-----------\n",
      "--------------GENERATION 61-----------\n",
      "--------------GENERATION 62-----------\n",
      "--------------GENERATION 63-----------\n",
      "--------------GENERATION 64-----------\n",
      "--------------GENERATION 65-----------\n",
      "--------------GENERATION 66-----------\n",
      "--------------GENERATION 67-----------\n",
      "--------------GENERATION 68-----------\n",
      "--------------GENERATION 69-----------\n",
      "--------------GENERATION 70-----------\n",
      "--------------GENERATION 71-----------\n",
      "--------------GENERATION 72-----------\n",
      "--------------GENERATION 73-----------\n",
      "--------------GENERATION 74-----------\n",
      "--------------GENERATION 75-----------\n",
      "--------------GENERATION 76-----------\n",
      "--------------GENERATION 77-----------\n",
      "--------------GENERATION 78-----------\n",
      "--------------GENERATION 79-----------\n",
      "--------------GENERATION 80-----------\n",
      "--------------GENERATION 81-----------\n",
      "--------------GENERATION 82-----------\n",
      "--------------GENERATION 83-----------\n",
      "--------------GENERATION 84-----------\n",
      "--------------GENERATION 85-----------\n",
      "--------------GENERATION 86-----------\n",
      "--------------GENERATION 87-----------\n",
      "--------------GENERATION 88-----------\n",
      "hi\n",
      "--------------GENERATION 89-----------\n",
      "--------------GENERATION 90-----------\n",
      "--------------GENERATION 91-----------\n",
      "--------------GENERATION 92-----------\n",
      "hi\n",
      "--------------GENERATION 93-----------\n",
      "--------------GENERATION 94-----------\n",
      "hi\n",
      "--------------GENERATION 95-----------\n",
      "hi\n",
      "--------------GENERATION 96-----------\n",
      "hi\n",
      "--------------GENERATION 97-----------\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "--------------GENERATION 98-----------\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "--------------GENERATION 99-----------\n",
      "Fitness :  160.56019669000392\n",
      "Time taken :  59.06857943534851\n",
      "\n",
      " Fitness :  160.56019669000392 \n",
      " Best Weights :  [6, 0, -12, -3, 0, -6, -15, 1, -6, 0, -9, 0, 14, -1, 2, -11, 5, -13, 4, 15, 10, 2, 0, -11, 0, -9, -1, 1, 5, -6, 0, -1, -18, 5, -1, 4, -1, 0, 1, 5, 3, 11, 5, 4, 0, -17, -16, 6, 7, -5, 10, -2, 10, -21, -1, 2, -6, 5, -1, 0, -4, -9, -5, 0, 7, 2, 0, 0, -1, 1, -9, 2, -12, -11, -3, -9, -2, -2, -13, -8, 4, 8, -5, -9, 0, -3, -1, 0, 5, 0, -1, 4, 1, 12, 0, 0, -1, 34, 3, -8, 5, 0, -16, 16, 19, 0, 8, -31, -1, 11, 0, 0, 0, 0, -8, 4, 2, -8, -5, -21, -1, -7, -1, 0, 0, 9, 7, 0, 38, -28, 0, 0, -1, -5, -9, 8, 24, 0, -6, 0, 0, 15, -13, -3, -1, -1, 9, 2, 0, -9, 4, -11, -2, -1, 1, -4, 5, 8, -5, 1, 11, -13, 0, 6, 0, 5, 6, -11, -10, -6, -4, -2, -1, -1, 10, -6, -6, 0, 0, 4, 0, 10, -11, -3, 0, 5, 5, 7, 0, 0, 5, -7, -15, 4, 0, 10, -13, 12, 0, -2, -8, 0, 9, -17, 4, 0, 10, 2, 9, -1, 0, -11, 0, 9, -3, 1, -12, 1, 9, -1, -14, 11, -10, 5, 7, 2, 5, 11, 17, -17, 5, 0, 0, 3, 5, 7, -4, 1, 0, -1, 7, -1, -16, -2, -1, 0, -5, 0, -5, -7, -1, 23, 7, 12, -9, -6, 0, 5, -3, -5, -1, 0, -2, 10, -13, 0, 5, 0, -1, 1, -10, -1, 2, 0, -5, -13, -1, 0, -6, 10, -5, 1, 0, 23, 0, -1, -4, -14, 0, 15, 0, 1, 6, -4, 10, 4, 24, 0, 0, -5, 0, 10, -1, 0, 0, -14, -4, 24, -7, 0, 7, 10, -1, -1, 9, -26, -3, -2, 7, 0, 0, -14, 0, 18, -21, -2, 6, -38, -2, -9, -4, 13, 4, -5, -5, 0, 6, 5, -9, -1, -15, 1, 0, -7, -14, 6, 0, -5, -16, 0, -9, 5, 4, 3, 5, 0, -28, -4, -12, 0, 0, 5, 1, 6, 0, 0, 0, 0, 0, 0, 0, -12, -4, 4, -4, 12, 3, -3, -6, 0, -2, 0, -5, -8, 0, 8, -4, 4, -1, 1, -3, 0, 8, -9, 0, -5, 0, 0, -9, 7, 2, 0, -3, -6, -3, 11, 7, -1, -1, 0, 4, -15, 0, -6, -2, 0, 0, 0, 0, 10, 37, 6, 0, -16, 0, 4, 0, 0, 7, 0, -5, -5, 0, 0, 0, 0, 0, -11, 5, -6, 0, 5, 2, -5, -3, 0, 12, -16, 0, 0, 31, -5, -20, -5, 0, 2, 0, 0, -3, -1, -10, 7, 7, -5, -10, 2, 15, 0, 0, 1, -25, 8, 10, 9, 12, -1, 1, -8, -4, -3, -2, -4, 0, 11, 12, 9, 5, 0, -4, -4, -5, 2, 22, 0, 0, -8, 0, 0, -5, 13, 12, -38, -9, 0, -12, -8, 0, 12, -9, 6, -3, 0, -3, 0, 0, 2, 12, -1, 0, -2, 0, -21, 0, -5, 9, 0, 5, -11, -6, -2, 0, 12, -1, 6, 27, 6, 0, 8, 0, 4, 0, -10, 0, 4, -1, -3, -19, -5, 1, 0, 0, -1, -15, 0, 13, -8, 0, 5, 0, 6, 0, 0, 7, 10, -8, -16, 8, 0, -6, -2, -14, 5, -7, -25, 4, -2, 0, 0, 11, 9, -8, 0, 8, -3, -14, 0, -18, 6, 0, 0, 0, 15, 2, 0, 1, 2, 0, -11, 0, -4, -1, 13, 1, 0, 0, -13, -5, -33, 7, 0, -5, -2, 0, 0, -10, -1, -1, 5, -27, -2, 0, -3, 5, 0, 9, 6, -16, -4, 0, 3, -8, 6, -32, -1, 10, 0, 8, -13, -5, -8, 0, -15, 2, -20, -10, 2, 0, 6, -1, -5, 2, 0, -8, -6, -2, 4, -11, 0, 11, -1, -1, 1, 0, 0, 1, 0, 0, -14, -4, 7, 12, 0, 8, -6, 9, 0, 1, 0, 3, 6, -14, 0, -8, 0, 9, -5, 0, 1, 10, 0, 0, 0, -1, -1, -29, 0, 8, -8, -21, 0, 33, -7, -14, 1, 0, -1, -5, 0, 2, -8, 0, 1, 0, 13, -1, -16, -1, 0, -5, 17, 4, 3, -6, 9, -5, -6, -11, -18, 1, 6, 0, -5, 7, -4, 0, 2, -12, 0, -3, 1, 0, 17, 0, 0, 36, -14, 4, -4, -4, 2, -3, 0, -6, 6, -26, -37, 5, 0, 1, 3, 0, -8, -2, 7, 6, -6, 6, -6, 6, 0, 0, 5, 14, -1, 0, 0, 2, -1, 4, -5, 10, 0, 0, 13, 4, 8, 0, 0, 0, 0, -1, 8, 0, -1, 10, -15, 2, -9, -3, -2, 0, -13, 0, -8, -7, 6, -50, -8, 3, -10, 3, -1, 2, 0, -8, 22, -1, 4, -11, -1, 4, 0, 2, -10, -4, 3, -11, 13, 8, 0, 0, 4, -5, -16, 0, 0, 0, 7, -6, 0, -1, -25, -26, 0, -8, -7, -1, -9, 0, 6, 0, -29, -10, 0, 0, 0, -1, -13, -18, 9, 2, 0, 11, 0, -9, -5, 3, 13, 8, -1, 5, -1, -12, -18, -2, 0, -5, 0, -1, -8, -17, 0, 7, -4, 0, -10, -9, -27, 24, -1, -1, 5, -3, 0, 7, 12, 0, -6, -2, 18, 7, -14, -2, -10, -2, -8, -12, 13, -5, -10, -1, -1, -3, 0, -5, 0, 0, 3, -5, 7, -4, -9, 4, 1, 0, -15, 13, -1, -8, 4, 0, 0, -5, 16, 5, 0, 15, 2, 2, -9, 0, 0, -6, -3, -1, 6, 7, -23, 9, 16, -11, -14, 0, 24, 5, 14, -1, -3, 0, 1, 5, 8, -11, -16, 6, 0, -5, 0, 8, 0, -5, 8, 1, 0, -5, -2, 4, -2, 0, 1, -4, -6, -5, 5, 5, 2, 10, 8, -1, -1, -4, 0, 7, 9, 0, -1, -8, 0, 0, -1, 4, -3, -7, 0, -2, 0, 0, 0, -15, 0, 0, -8, 8, 0, -1, -15, 0, 0, 4, 15, 0, 12, -15, 4, 1, 0, -55, -26, -3, -2, 5, 0, 8, 7, -3, 0, 5, 0, 21, 6, 15, 0, 6, 1, -3, 10, 0, 6, 6, -1, -3, 0, 0, 6, 0, 3, -4, -18, 0, 11, 1, 2, 0, -5, 0, -4, 0, -5, 0, 8, 0, 4, -8, 0, 5, -30, -1, 1, 0, -28, 0, -11, -1, 0, -4, 0, -17, -5, -10, 10, -19, -5, -2, 3, -6, 1, 2, 0, 0, 0, 0, -12, -11, -5, 0, -1, 8, 9, 5, 0, 0, 5, -4, 12, 0, -5, -2, 0, -29, -5, 6, 2, 6, -5, 1, 0, -1, 17, -6, -11, 2, 7, 4, 10, 1, -1, 0, 19, -12, 6, -26, 4, 12, 0, 0, 10, -1, -11, -2, 2, -14, -5, 13, 12, 7, 0, 0, 3, -1, 11, 19, 0, 0, 0, 8, 23, 0, -1, 4, 4, -5, 0, 0, 0, 0, -5, -10, 6, -1, 0, 6, -1, 8, -6, -1, -6, 0, -5, 8, -5, -1, -12, 0, 0, 0, 0, 7, 8, 3, -1, -1, 0, 0, -16, -6, 0, -1, -16, 23, 0, -14, -21, 0, -3, 0, -5, -9, 1, 0, -26, -1, 6, 1, -3, 0, 4, -4, -18, -25, 0, 0, -1, 10, 0, -4, -6, 0, 14, -1, 8, -8, 15, -4, -4, -3, -28, 7, -14, -1, -4, -14, 0, 2, 0, 0, 0, -2, 10, -7, 0, -5, 0, -2, 4, -4, -37, 0, 2, 9, -18, 0, -13, -1, 0, -11, 0, 0, 4, 10, -19, 19, 0, 0, 12, 0, -3, 0, -12, 0, 5, -3, -7, -2, -1, -10, 13, -1, 8, 1, 0, 0, 0, -10, 11, -7, -6, 5, 0, -1, 0, 6, 0, -20, 0, -7, 0, 27, 20, 0, 5, 0, 2, 0, -1, 4, 11, -9, 9, -6, 0, -1, 0, 0, 0, 0, -9, -1, -7, -6, 0, 0, 0, -4, 0, 18, 2, -12, 4, 2, 0, 2, 18, 0, -20, 0, 9, 0, -1, -3, -8, -1, 0, -7, 0, 0, 2, 0, -9, -6, -15, -5, 21, 4, -22, -3, 0, 4, 7, 0, 10, 2, 0, 0, -6, -1, 0, 0, -16, 7, 0, 4, 0, 0, 3, 5, 0, -1, -3, 0, 1, 0, 1, -5, 0, -14, -36, 0, -3, -2, -4, 0, 0, -8, -5, 5, -9, 1, 4, 2, -5, -4, -1, -25, 1, 6, -28, 0, -10, 0, 1] \n",
      " Dimensions :  [4, 100, 10, 3]\n",
      "Time Taken :  59.10149025917053\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "i = InputData(fileName=\"../ANN/iris\")\n",
    "input_val, output_val = i.main()\n",
    "end_time = time.time()\n",
    "print(\"Time for inputting data : \", end_time - start_time)\n",
    "        \n",
    "print(\"============ Calling FFA to get best weights ===============\")\n",
    "\n",
    "start_time = time.time()\n",
    "a = ffaAnn(initialPopSize=100, m=1, dimensions = [100,10], input_values=input_val, output_values_expected=output_val, iterations = 100)\n",
    "\n",
    "fit, b, weights, dim = a.main()\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Time taken : \", end_time - start_time)\n",
    "\n",
    "print(\"\\n Fitness : \", fit, \"\\n Best Weights : \", weights, \"\\n Dimensions : \", dim)\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "x=b[:]\n",
    "z=[i for i in range(0,100)]\n",
    "plt.plot(z,x)\n",
    "\n",
    "plt.title(\"Firefly Algorithm\")\n",
    "plt.ylabel(\"Fitness\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "end_time = time.time()\n",
    "print(\"Time Taken : \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2830eb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============= MLP Program Begins ============\n",
      "Training\n",
      "\n",
      " Actual / Expected [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2]\n",
      "\n",
      " Predictions [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 2 1 1 1 1 1 1 2 1 1 1 1 1 1 2 2 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1 2 1\n",
      " 1 1 1 1 1 1 2 2 2 1 2 1 2 1 1 2 1 2 2 2 2 2 1 1 2 1 1 2 1 2 1 1 1 1 2 1 1\n",
      " 1 2 1 1 2 2 1 1 1]\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[40  0  0]\n",
      " [ 0 32  8]\n",
      " [ 0 22 18]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      1.00      1.00        40\n",
      "     class 1       0.59      0.80      0.68        40\n",
      "     class 2       0.69      0.45      0.55        40\n",
      "\n",
      "    accuracy                           0.75       120\n",
      "   macro avg       0.76      0.75      0.74       120\n",
      "weighted avg       0.76      0.75      0.74       120\n",
      "\n",
      "Time taken =  0.011968135833740234\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n============= MLP Program Begins ============\")\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"Training\")\n",
    "m = MultiLayerPerceptron(fileName=\"../ANN/iris_train\", dimensions=dim, all_weights=weights)\n",
    "m.main()\n",
    "end_time = time.time()\n",
    "print(\"Time taken = \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3c970b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n",
      "\n",
      " Actual / Expected [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2]\n",
      "\n",
      " Predictions [0 0 0 0 0 0 0 0 0 0 1 1 1 2 1 1 1 1 2 1 2 2 2 2 2 2 2 1 2 1]\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[10  0  0]\n",
      " [ 0  8  2]\n",
      " [ 0  2  8]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      1.00      1.00        10\n",
      "     class 1       0.80      0.80      0.80        10\n",
      "     class 2       0.80      0.80      0.80        10\n",
      "\n",
      "    accuracy                           0.87        30\n",
      "   macro avg       0.87      0.87      0.87        30\n",
      "weighted avg       0.87      0.87      0.87        30\n",
      "\n",
      "Time taken =  0.005984067916870117\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Testing\")\n",
    "m = MultiLayerPerceptron(fileName=\"../ANN/iris_test\", dimensions=dim, all_weights=weights)\n",
    "m.main()\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Time taken = \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245fd1af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
