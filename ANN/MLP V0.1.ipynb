{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb5a447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "50dfaafc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn import preprocessing\n",
    "from scipy.special import expit\n",
    "\n",
    "from numpy.random import default_rng\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import time\n",
    "\n",
    "from ffaAnn_thread_V_I import *\n",
    "\n",
    "\n",
    "\n",
    "class MultiLayerPerceptron():\n",
    "    # ================== Activation Functions ================ #\n",
    "\n",
    "    # accepts a vector or list and returns a list after performing corresponding function on all elements\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(vectorSig):\n",
    "        \"\"\"returns 1/(1+exp(-x)), where the output values lies between zero and one\"\"\"\n",
    "        sig = expit(vectorSig)\n",
    "        return sig\n",
    "\n",
    "    @staticmethod\n",
    "    def binaryStep(x):\n",
    "        \"\"\" It returns '0' is the input is less then zero otherwise it returns one \"\"\"\n",
    "        return np.heaviside(x, 1)\n",
    "\n",
    "    @staticmethod\n",
    "    def linear(x):\n",
    "        \"\"\" y = f(x) It returns the input as it is\"\"\"\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def tanh(x):\n",
    "        \"\"\" It returns the value (1-exp(-2x))/(1+exp(-2x)) and the value returned will be lies in between -1 to 1\"\"\"\n",
    "        return np.tanh(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def relu(x):  # Rectified Linear Unit\n",
    "        \"\"\" It returns zero if the input is less than zero otherwise it returns the given input\"\"\"\n",
    "        x1 = []\n",
    "        for i in x:\n",
    "            if i < 0:\n",
    "                x1.append(0)\n",
    "            else:\n",
    "                x1.append(i)\n",
    "\n",
    "        return x1\n",
    "\n",
    "    @staticmethod\n",
    "    def leakyRelu(x):\n",
    "        \"\"\" It returns zero if the input is less than zero otherwise it returns the given input\"\"\"\n",
    "        x1 = []\n",
    "        for i in x:\n",
    "            if i < 0:\n",
    "                x1.append((0.01 * i))\n",
    "            else:\n",
    "                x1.append(i)\n",
    "\n",
    "        return x1\n",
    "\n",
    "    @staticmethod\n",
    "    def parametricRelu(self, a, x):\n",
    "        \"\"\" It returns zero if the input is less than zero otherwise it returns the given input\"\"\"\n",
    "        x1 = []\n",
    "        for i in x:\n",
    "            if i < 0:\n",
    "                x1.append((a * i))\n",
    "            else:\n",
    "                x1.append(i)\n",
    "\n",
    "        return x1\n",
    "\n",
    "    @staticmethod\n",
    "    def softmax(self, x):\n",
    "        \"\"\" Compute softmax values for each sets of scores in x\"\"\"\n",
    "        return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "    # ============ Activation Functions Part Ends ============= #\n",
    "\n",
    "    # ================= Distance Calculation ================== #\n",
    "\n",
    "    @staticmethod\n",
    "    def chebishev(self, cord1, cord2, exponent_h):\n",
    "        dist = 0.0\n",
    "        if ((type(cord1) == int and type(cord2) == int) or ((type(cord1) == float and type(cord2) == float))):\n",
    "            dist = math.pow((cord1 - cord2), exponent_h)\n",
    "        else:\n",
    "            for i, j in zip(cord1, cord2):\n",
    "                dist += math.pow((i - j), exponent_h)\n",
    "        dist = math.pow(dist, (1.0 / exponent_h))\n",
    "        return dist\n",
    "\n",
    "    @staticmethod\n",
    "    def minimum_distance(self, cord1, cord2):\n",
    "        # min(|x1-y1|, |x2-y2|, |x3-y3|, ...)\n",
    "        dist = float('inf')\n",
    "        if ((type(cord1) == int and type(cord2) == int) or ((type(cord1) == float and type(cord2) == float))):\n",
    "            dist = math.fabs(cord1 - cord2)\n",
    "        else:\n",
    "            for i, j in zip(cord1, cord2):\n",
    "                temp_dist = math.fabs(i - j)\n",
    "                if (temp_dist < dist):\n",
    "                    dist = temp_dist\n",
    "        return dist\n",
    "\n",
    "    @staticmethod\n",
    "    def maximum_distance(self, cord1, cord2):\n",
    "        # max(|x1-y1|, |x2-y2|, |x3-y3|, ...)\n",
    "        dist = float('-inf')\n",
    "        if ((type(cord1) == int and type(cord2) == int) or ((type(cord1) == float and type(cord2) == float))):\n",
    "            dist = math.fabs(cord1 - cord2)\n",
    "        else:\n",
    "            for i, j in zip(cord1, cord2):\n",
    "                temp_dist = math.fabs(i - j)\n",
    "                if (temp_dist > dist):\n",
    "                    dist = temp_dist\n",
    "        return dist\n",
    "\n",
    "    @staticmethod\n",
    "    def manhattan(self, cord1, cord2):\n",
    "        # |x1-y1| + |x2-y2| + |x3-y3| + ...\n",
    "        dist = 0.0\n",
    "        if ((type(cord1) == int and type(cord2) == int) or ((type(cord1) == float and type(cord2) == float))):\n",
    "            dist = math.fabs(cord1 - cord2)\n",
    "        else:\n",
    "            for i, j in zip(cord1, cord2):\n",
    "                dist += math.fabs(i - j)\n",
    "        return dist\n",
    "\n",
    "    @staticmethod\n",
    "    def eucledian(self, cord1, cord2):\n",
    "        dist = 0.0\n",
    "        if ((type(cord1) == int and type(cord2) == int) or ((type(cord1) == float and type(cord2) == float))):\n",
    "            dist = math.pow((cord1 - cord2), 2)\n",
    "        else:\n",
    "            for i, j in zip(cord1, cord2):\n",
    "                dist += math.pow((i - j), 2)\n",
    "        return math.pow(dist, 0.5)\n",
    "\n",
    "    # =========== Distance Calculation Ends ============== #\n",
    "\n",
    "    def __init__(self, dimensions=(8, 5), all_weights=(0.1, 0.2), fileName=\"iris\"):\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dimensions : dimension of the neural network\n",
    "            all_weights : the optimal weights we get from the bio-algoANN models\n",
    "        \"\"\"\n",
    "\n",
    "        self.allPop_Weights = []\n",
    "        self.allPopl_Chromosomes = []\n",
    "        self.allPop_ReceivedOut = []\n",
    "        self.allPop_ErrorVal = []\n",
    "\n",
    "        self.all_weights = all_weights\n",
    "\n",
    "        self.fitness = []\n",
    "\n",
    "        # ================== Input dataset and corresponding output ========================= #\n",
    "\n",
    "        self.fileName = fileName\n",
    "        self.fileName += \".csv\"\n",
    "        data = pd.read_csv(self.fileName)\n",
    "\n",
    "        classes = []\n",
    "        output_values_expected = []\n",
    "        input_values = []\n",
    "\n",
    "        # ~~~~ encoding ~~~~#\n",
    "\n",
    "        # labelencoder = LabelEncoder()\n",
    "        # data[data.columns[-1]] = labelencoder.fit_transform(data[data.columns[-1]])\n",
    "\n",
    "        # one hot encoding - for multi-column\n",
    "        # enc = OneHotEncoder(handle_unknown='ignore')\n",
    "        # combinedData = np.vstack((data[data.columns[-2]], data[data.columns[-1]])).T\n",
    "        # print(combinedData)\n",
    "        # y = enc.fit_transform(combinedData).toarray()\n",
    "        # y = OneHotEncoder().fit_transform(combinedData).toarray()\n",
    "\n",
    "        #\n",
    "        y = LabelBinarizer().fit_transform(data[data.columns[-1]])\n",
    "        # print(y)\n",
    "\n",
    "        # ~~~~ encoding ends~~~~#\n",
    "\n",
    "        for j in range(len(data)):\n",
    "            output_values_expected.append(y[j])\n",
    "\n",
    "        # print(output_values_expected)\n",
    "\n",
    "        input_values = []\n",
    "        for j in range(len(data)):\n",
    "            b = []\n",
    "            for i in range(1, len(data.columns) - 1):\n",
    "                b.append(data[data.columns[i]][j])\n",
    "            input_values.append(b)\n",
    "\n",
    "        self.X = input_values[:]\n",
    "        self.Y = output_values_expected[:]\n",
    "\n",
    "        # input and output\n",
    "        self.X = input_values[:]\n",
    "        self.Y = output_values_expected[:]\n",
    "\n",
    "        self.dimension = dimensions\n",
    "        # print(self.dimension)\n",
    "\n",
    "        # ================ Finding Initial Weights ================ #\n",
    "\n",
    "        self.pop = []  # weights\n",
    "        reshaped_all_weights = []\n",
    "        start = 0\n",
    "        for i in range(len(self.dimension) - 1):\n",
    "            end = start + self.dimension[i + 1] * self.dimension[i]\n",
    "            temp_arr = self.all_weights[start:end]\n",
    "            w = np.reshape(temp_arr[:], (self.dimension[i + 1], self.dimension[i]))\n",
    "            reshaped_all_weights.append(w)\n",
    "            start = end\n",
    "        self.pop.append(reshaped_all_weights)\n",
    "\n",
    "        self.init_pop = self.all_weights\n",
    "\n",
    "    # ================ Initial Weights Part Ends ================ #\n",
    "\n",
    "\n",
    "    def Predict(self, chromo):\n",
    "        # X, Y and pop are used\n",
    "        self.fitness = []\n",
    "        total_error = 0\n",
    "        m_arr = []\n",
    "        k1 = 0\n",
    "        for i in range(len(self.dimension) - 1):\n",
    "            p = self.dimension[i]\n",
    "            q = self.dimension[i + 1]\n",
    "            k2 = k1 + p * q\n",
    "            m_temp = chromo[k1:k2]\n",
    "            m_arr.append(np.reshape(m_temp, (p, q)))\n",
    "            k1 = k2\n",
    "\n",
    "        y_predicted = []\n",
    "        for x, y in zip(self.X, self.Y):\n",
    "\n",
    "            yo = x\n",
    "\n",
    "            for mCount in range(len(m_arr)):\n",
    "                yo = np.dot(yo, m_arr[mCount])\n",
    "                yo = self.sigmoid(yo)\n",
    "            \n",
    "            # converting to sklearn acceptable form\n",
    "            max_yo = max(yo)\n",
    "            for y_vals in range(len(yo)):\n",
    "                if(yo[y_vals] == max_yo):\n",
    "                    yo[y_vals] = 1\n",
    "                else:\n",
    "                    yo[y_vals] = 0\n",
    "            y_predicted.append(yo)\n",
    "        return (y_predicted, self.Y)\n",
    "\n",
    "    def main(self):\n",
    "        Y_PREDICT, Y_ACTUAL = self.Predict(self.init_pop)\n",
    "        Y_PREDICT = np.array(Y_PREDICT)\n",
    "        Y_ACTUAL = np.array(Y_ACTUAL)\n",
    "        \n",
    "        n_classes = 3\n",
    "        \n",
    "        label_binarizer = LabelBinarizer()\n",
    "        label_binarizer.fit(range(n_classes))\n",
    "        Y_PREDICT = label_binarizer.inverse_transform(np.array(Y_PREDICT))\n",
    "        Y_ACTUAL = label_binarizer.inverse_transform(np.array(Y_ACTUAL))\n",
    "        return (Y_PREDICT, Y_ACTUAL)\n",
    "        # find training and testing error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d36914a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for inputting data :  0.007977962493896484\n",
      "============ Calling FFA to get best weights ===============\n",
      "--------------GENERATION 0-----------\n",
      "--------------GENERATION 1-----------\n",
      "--------------GENERATION 2-----------\n",
      "--------------GENERATION 3-----------\n",
      "--------------GENERATION 4-----------\n",
      "--------------GENERATION 5-----------\n",
      "--------------GENERATION 6-----------\n",
      "--------------GENERATION 7-----------\n",
      "--------------GENERATION 8-----------\n",
      "--------------GENERATION 9-----------\n",
      "--------------GENERATION 10-----------\n",
      "--------------GENERATION 11-----------\n",
      "--------------GENERATION 12-----------\n",
      "--------------GENERATION 13-----------\n",
      "--------------GENERATION 14-----------\n",
      "--------------GENERATION 15-----------\n",
      "--------------GENERATION 16-----------\n",
      "--------------GENERATION 17-----------\n",
      "--------------GENERATION 18-----------\n",
      "--------------GENERATION 19-----------\n",
      "--------------GENERATION 20-----------\n",
      "--------------GENERATION 21-----------\n",
      "--------------GENERATION 22-----------\n",
      "--------------GENERATION 23-----------\n",
      "--------------GENERATION 24-----------\n",
      "--------------GENERATION 25-----------\n",
      "--------------GENERATION 26-----------\n",
      "--------------GENERATION 27-----------\n",
      "--------------GENERATION 28-----------\n",
      "--------------GENERATION 29-----------\n",
      "--------------GENERATION 30-----------\n",
      "--------------GENERATION 31-----------\n",
      "--------------GENERATION 32-----------\n",
      "--------------GENERATION 33-----------\n",
      "--------------GENERATION 34-----------\n",
      "--------------GENERATION 35-----------\n",
      "--------------GENERATION 36-----------\n",
      "--------------GENERATION 37-----------\n",
      "--------------GENERATION 38-----------\n",
      "--------------GENERATION 39-----------\n",
      "--------------GENERATION 40-----------\n",
      "--------------GENERATION 41-----------\n",
      "--------------GENERATION 42-----------\n",
      "--------------GENERATION 43-----------\n",
      "--------------GENERATION 44-----------\n",
      "--------------GENERATION 45-----------\n",
      "--------------GENERATION 46-----------\n",
      "--------------GENERATION 47-----------\n",
      "--------------GENERATION 48-----------\n",
      "--------------GENERATION 49-----------\n",
      "--------------GENERATION 50-----------\n",
      "--------------GENERATION 51-----------\n",
      "--------------GENERATION 52-----------\n",
      "--------------GENERATION 53-----------\n",
      "--------------GENERATION 54-----------\n",
      "--------------GENERATION 55-----------\n",
      "--------------GENERATION 56-----------\n",
      "--------------GENERATION 57-----------\n",
      "--------------GENERATION 58-----------\n",
      "--------------GENERATION 59-----------\n",
      "--------------GENERATION 60-----------\n",
      "--------------GENERATION 61-----------\n",
      "--------------GENERATION 62-----------\n",
      "--------------GENERATION 63-----------\n",
      "--------------GENERATION 64-----------\n",
      "--------------GENERATION 65-----------\n",
      "--------------GENERATION 66-----------\n",
      "--------------GENERATION 67-----------\n",
      "--------------GENERATION 68-----------\n",
      "--------------GENERATION 69-----------\n",
      "--------------GENERATION 70-----------\n",
      "--------------GENERATION 71-----------\n",
      "--------------GENERATION 72-----------\n",
      "--------------GENERATION 73-----------\n",
      "--------------GENERATION 74-----------\n",
      "--------------GENERATION 75-----------\n",
      "--------------GENERATION 76-----------\n",
      "--------------GENERATION 77-----------\n",
      "--------------GENERATION 78-----------\n",
      "--------------GENERATION 79-----------\n",
      "--------------GENERATION 80-----------\n",
      "--------------GENERATION 81-----------\n",
      "--------------GENERATION 82-----------\n",
      "--------------GENERATION 83-----------\n",
      "--------------GENERATION 84-----------\n",
      "--------------GENERATION 85-----------\n",
      "--------------GENERATION 86-----------\n",
      "--------------GENERATION 87-----------\n",
      "--------------GENERATION 88-----------\n",
      "--------------GENERATION 89-----------\n",
      "--------------GENERATION 90-----------\n",
      "--------------GENERATION 91-----------\n",
      "--------------GENERATION 92-----------\n",
      "--------------GENERATION 93-----------\n",
      "--------------GENERATION 94-----------\n",
      "--------------GENERATION 95-----------\n",
      "--------------GENERATION 96-----------\n",
      "--------------GENERATION 97-----------\n",
      "--------------GENERATION 98-----------\n",
      "--------------GENERATION 99-----------\n",
      "Fitness :  -187.18506918622538\n",
      "Time taken :  82.25392317771912\n",
      "\n",
      " Fitness :  -187.18506918622538 \n",
      " Best Weights :  [-3, -29, -4, 0, -15, -1, 0, -6, 9, -34, -18, 0, 0, -1, 0, 0, 0, -3, 0, -2, 0, 0, 0, -1, -10, 0, 0, 0, 0, 0, -22, 0, 0, -1, 3, 0, -2, -11, -2, 0, -1, -10, 0, 0, 0, -1, 0, -1, 0, -7, 1, 0, 0, -12, 0, 0, -7, 0, -29, 0, -2, 0, 7, -6, -1, 0, -3, 0, 0, 4, 0, 0, -4, 0, -16, 0, -5, 0, -4, 0, 0, 2, 0, -6, 0, 0, 0, 0, 0, -9, 0, 0, 0, 0, -3, 11, 0, 0, 0, 1, 0, 0, 0, 0, 0, 33, -1, 0, -16, 0, 0, 0, 1, 3, 0, 5, 0, 0, 0, 2, -5, 18, 0, 0, 0, 0, -5, -1, 0, 0, -25, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, -2, 0, 0, 2, -7, 0, 0, 0, -11, 0, 0, 0, 0, 0, -10, 0, 0, -9, 0, -11, 0, -1, 0, 4, -11, 0, 4, -6, 13, -1, 0, 0, -1, -7, 0, -4, 2, 0, 0, 0, 3, 0, -1, 0, -3, -15, -1, 0, -7, 0, 0, 0, -4, 4, -6, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 16, 0, 0, 0, -5, 0, 0, 0, 0, 0, 0, 15, -17, -1, 0, 0, -7, -3, -13, 0, 19, -1, -7, 0, 0, 16, 0, 0, 0, -8, -7, 0, 3, 13, 0, 0, 2, 0, -1, -56, 0, 0, 0, 0, 0, 0, 0, 4, -5, 0, 0, 0, 0, -2, 0, 0, 0, 5, 0, -19, -2, 5, -3, 0, -22, 0, 0, -8, 0, 15, -4, 0, 0, -1, 0, 0, 0, 0, -2, 0, 0, -1, -1, 0, 0, 3, -1, -1, -1, 2, -10, -11, 0, -5, -3, 0, 0, -19, 8, -3, -1, -15, 0, -4, -1, 0, 0, 0, 0, 0, 0, 11, 0, 0, 0, -2, 33, 6, 0, -1, -1, 0, 0, -4, -1, -19, -6, 0, -3, 2, 0, 0, -6, 0, 0, 0, 0, -6, 0, 0, -2, 13, -1, 0, -14, 0, 0, 0, 3, 5, 0, 0, 0, 0, 0, 0, 1, 0, 2, 6, 0, 4, 0, 0, 0, 0, 0, -2, 0, 0, -20, 0, 2, 0, -2, -2, -2, 0, 1, 0, 0, 0, -1, 0, 0, -3, 0, -12, -2, 0, -1, 0, 0, 0, -21, 0, 0, 3, 0, 0, 0, -13, 11, -6, 0, 0, -1, 0, -1, 2, 0, 1, 3, -4, 5, 2, 0, 0, -2, 10, 0, 6, 0, -1, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, -2, 0, -2, 0, 0, 0, 2, 0, 27, 8, 0, 22, 6, 4, 0, -2, 13, 0, 0, 32, -16, 0, 0, 3, 0, 0, 0, 0, 0, 19, 0, 0, 18, 0, 0, 0, -3, 0, 0, 0, 0, -2, 3, 0, 0, 0, 0, 0, 0, 1, -3, 0, 0, 0, 0, 0, 0, 0, 4, 0, -14, -1, 0, 0, 0, 25, 0, 40, 0, 7, 0, 0, 4, -1, 0, 0, 18, -1, 14, 0, 0, -4, 0, 0, 7, -4, -24, 0, 0, -3, 0, 0, 0, 0, 20, -6, 0, 0, 0, 0, -15, 0, 0, 15, 0, -6, -4, -1, 27, -28, 0, 27, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -28, 7, 0, 0, 0, 21, 0, 0, 0, 0, 0, -3, -15, -24, 0, 0, 0, 0, 0, 0, 1, -3, -2, 5, 0, 0, -2, 0, 0, 0, 4, 0, 0, -7, 0, -5, 21, 0, -1, 29, 0, 0, 5, 0, -6, 18, 0, 0, 0, 0, -1, 0, 3, -1, 0, 0, 0, 0, -2, 0, -1, 0, -1, 0, -11, 0, -13, 3, 0, 0, 0, 0, 0, 0, 0, 1, 25, 0, -31, -4, 0, 3, 0, 0, 0, 0, -3, -2, 0, 0, 0, 0, 0, 0, -4, -4, 0, -3, 0, 0, 0, -7, 0, 0, 0, 8, 28, -1, 0, -3, 0, 3, 1, 0, 0, 0, 0, 0, 32, 0, -4, -15, 0, 0, -5, 0, 0, 0, 4, 0, -5, 0, 0, 0, 1, 0, -11, -7, 30, 15, 0, 0, -10, -5, -34, 0, -3, 0, 1, 0, 5, -7, 6, 0, 0, 0, 0, 0, -1, 4, 0, 0, 1, 0, 0, 8, 2, 4, 5, 0, -2, -22, 0, 5, 0, -22, 0, 0, -34, 3, -2, 0, 0, -3, -3, 0, 19, 0, 0, 0, -2, -1, 1, 0, -13, 0, 0, 0, 0, 0, -6, 0, -3, 0, 0, 0, -31, -23, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, -3, 0, 11, 0, -2, 0, 5, 0, 0, -2, 0, 0, 0, -8, 0, -1, -3, -1, 0, 0, 0, -4, 0, 0, 0, -2, 0, 0, 0, 0, 4, 0, 0, 15, 0, 0, 0, 0, 0, 0, 0, 2, 0, -10, 0, -2, -4, 5, 1, -2, -1, 0, -1, 0, 0, 0, -2, 0, -2, 0, 0, -24, -9, 0, 0, 0, 0, 0, 0, 0, 27, -3, 0, 0, 0, 0, 14, 0, 0, 0, 0, 2, 0, 0, 5, 9, 0, 0, 0, -8, 0, 0, 0, 0, 0, 0, 0, 0, -15, -2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 18, 0, 17, 13, -1, -8, 1, -3, 2, -3, 0, 0, 4, 0, 0, -5, 0, 1, 9, 0, 13, 0, 1, 0, 0, 0, -4, -6, 0, -29, 0, 0, 0, 3, 0, -1, 0, -3, 13, 34, 0, 6, -1, -1, 1, -6, 0, -13, 0, 0, 0, 0, 0, 0, 0, 0, 0, -7, 0, 3, 0, 0, 0, -2, 20, 0, 2, 0, 0, 0, 0, 0, -24, 0, -1, 0, 9, -4, 0, 0, 0, -16, 0, 0, -3, 1, 1, 0, 0, 0, -1, 0, 0, 4, -4, 0, 0, -5, 28, -1, 6, 0, 0, 0, -6, 0, 7, -11, -4, 0, 0, -5, 0, 0, 0, -2, 4, 0, 0, 0, -7, 5, 0, 0, 0, 3, 0, 0, 3, 0, -5, -3, 0, 2, -2, 0, 16, -1, 1, 0, 1, 3, 0, -3, 0, 0, 0, 0, -1, 0, 0, 0, 0, -23, 0, -1, 0, 0, -33, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, -1, 5, 0, 9, 0, 0, 7, 0, 0, 4, -1, 0, 0, 0, 0, 0, -2, 10, 0, 0, 0, -1, 0, -19, 0, 8, -3, 0, 0, -1, 0, 11, 0, -3, 0, 0, 0, 7, -2, -6, 0, 0, -5, -12, -1, 0, -23, 0, 0, -3, -2, 0, 2, 0, 8, 14, 0, -13, 0, -2, 1, -1, 0, 0, 5, 0, -3, 0, 0, 0, 8, 0, 0, -4, 0, -3, 0, -2, -12, 0, 0, 0, 0, -2, 0, 0, 0, -5, 0, 0, 0, 0, 0, -1, 2, 1, 0, 0, -5, -1, 0, 35, 2, 0, 0, 0, 0, 0, 0, 0, -5, 17, 4, 0, 0, 2, 0, 0, 0, -2, 0, 0, 0, 0, 0, 5, 0, -2, 0, -2, -4, -2, -2, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, -1, 10, 0, -5, -1, 0, 0, 2, 0, -2, 0, 0, 3, 10, 0, 0, 1, 1, 0, 14, -4, 4, 0, 0, 0, 13, 21, 3, 3, 0, 0, 2, 0, 0, -2, 0, 32, 2, -1, 1, 0, 0, -5, -3, 1, -3, 19, -17, 9, -2, 0, 0, 16, -41, -7, 11, -15, 16, -2, 15, 1, 0, 0, 0, 0, 0, 0, 0, 0, 4, 5, 2, 0, 0, 0, 0, 0, 0, 0, 0, -17, 5, 10, 0, 0, 13, 0, 0, 0, 0, -16, 0, 0, 0, 0, 0, -1, 0, 1, 6, 0, 0, 2, 0, -2, -1, 6, 0, 0, 0, 0, 1, 0, 0, 0, 3, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, -17, 4, -21, -5, 10, -32, -3, 21, 0, 0, 15, 0, 4, 0, -5, -21, 3, 1, 0, 0, 0, 0, -3, -3, 14, 4, 0, -21, 1, 26, 1, -2, 6, 0, -31, 17, 0, 0, 0, -1, 0, 0, -7, 0, 0, 0, 6, 0, 0, 0, 0, 0, -1, 0, 0, -30, 0, 4, 0, 0, 0, 0, -6, 0, 0, -20, -7, 23, 6, 0, -19, 0, 0, 0, 0, 9, -22, 1] \n",
      " Dimensions :  [4, 100, 10, 3]\n",
      "Time Taken :  82.26987934112549\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "i = InputData(fileName=\"../ANN/iris\")\n",
    "input_val, output_val = i.main()\n",
    "end_time = time.time()\n",
    "print(\"Time for inputting data : \", end_time - start_time)\n",
    "        \n",
    "print(\"============ Calling FFA to get best weights ===============\")\n",
    "\n",
    "start_time = time.time()\n",
    "a = ffaAnn(initialPopSize=100, m=10, dimensions = [100,10], input_values=input_val, output_values_expected=output_val, iterations = 100)\n",
    "\n",
    "fit, b, weights, dim = a.main()\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Time taken : \", end_time - start_time)\n",
    "\n",
    "print(\"\\n Fitness : \", fit, \"\\n Best Weights : \", weights, \"\\n Dimensions : \", dim)\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "x=b[:]\n",
    "z=[i for i in range(0,100)]\n",
    "plt.plot(z,x)\n",
    "\n",
    "plt.title(\"Firefly Algorithm\")\n",
    "plt.ylabel(\"Fitness\")\n",
    "plt.xlabel(\"Time\")\n",
    "end_time = time.time()\n",
    "print(\"Time Taken : \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2830eb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============= MLP Program Begins ============\n",
      "Training\n",
      "\n",
      " Actual / Expected [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2]\n",
      "\n",
      " Predictitons [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 1 1 1 2 1 1 1 1 1 2\n",
      " 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 1 2 2 2 2 2 2]\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[40  0  0]\n",
      " [ 0 35  5]\n",
      " [ 1  3 36]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.98      1.00      0.99        40\n",
      "     class 1       0.92      0.88      0.90        40\n",
      "     class 2       0.88      0.90      0.89        40\n",
      "\n",
      "    accuracy                           0.93       120\n",
      "   macro avg       0.92      0.92      0.92       120\n",
      "weighted avg       0.92      0.93      0.92       120\n",
      "\n",
      "Time taken =  0.018949270248413086\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n============= MLP Program Begins ============\")\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"Training\")\n",
    "m = MultiLayerPerceptron(fileName=\"../ANN/iris_train\", dimensions=dim, all_weights=weights)\n",
    "Y_PREDICT, Y_ACTUAL = m.main()\n",
    "print(\"\\n Actual / Expected\", Y_ACTUAL)\n",
    "print(\"\\n Predictions\", Y_PREDICT)\n",
    "print(\"\\n\\nConfusion Matrix\")\n",
    "print(confusion_matrix(Y_ACTUAL, Y_PREDICT))\n",
    "\n",
    "print(\"\\n\\nClassification Report\")\n",
    "target_names = ['class 0', 'class 1', 'class 2']\n",
    "print(classification_report(Y_ACTUAL, Y_PREDICT, target_names=target_names))\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Time taken = \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b3c970b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n",
      "\n",
      " Actual / Expected [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2]\n",
      "\n",
      " Predictitons [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 1 1 1 2 1 1 1 1 1 2\n",
      " 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 1 2 2 2 2 2 2]\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[40  0  0]\n",
      " [ 0 35  5]\n",
      " [ 1  3 36]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.98      1.00      0.99        40\n",
      "     class 1       0.92      0.88      0.90        40\n",
      "     class 2       0.88      0.90      0.89        40\n",
      "\n",
      "    accuracy                           0.93       120\n",
      "   macro avg       0.92      0.92      0.92       120\n",
      "weighted avg       0.92      0.93      0.92       120\n",
      "\n",
      "Time taken =  0.018946170806884766\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Testing\")\n",
    "m = MultiLayerPerceptron(fileName=\"../ANN/iris_train\", dimensions=dim, all_weights=weights)\n",
    "Y_PREDICT, Y_ACTUAL = m.main()\n",
    "print(\"\\n Actual / Expected\", Y_ACTUAL)\n",
    "print(\"\\n Predictions\", Y_PREDICT)\n",
    "print(\"\\n\\nConfusion Matrix\")\n",
    "print(confusion_matrix(Y_ACTUAL, Y_PREDICT))\n",
    "\n",
    "print(\"\\n\\nClassification Report\")\n",
    "target_names = ['class 0', 'class 1', 'class 2']\n",
    "print(classification_report(Y_ACTUAL, Y_PREDICT, target_names=target_names))\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Time taken = \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245fd1af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
