{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e62cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fedefee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn import preprocessing\n",
    "from scipy.special import expit\n",
    "\n",
    "from numpy.random import default_rng\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import time\n",
    "\n",
    "from psoAnn_thread_V_I import *\n",
    "\n",
    "\n",
    "\n",
    "class MultiLayerPerceptron():\n",
    "    # ================== Activation Functions ================ #\n",
    "\n",
    "    # accepts a vector or list and returns a list after performing corresponding function on all elements\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(vectorSig):\n",
    "        \"\"\"returns 1/(1+exp(-x)), where the output values lies between zero and one\"\"\"\n",
    "        sig = expit(vectorSig)\n",
    "        return sig\n",
    "\n",
    "    @staticmethod\n",
    "    def binaryStep(x):\n",
    "        \"\"\" It returns '0' is the input is less then zero otherwise it returns one \"\"\"\n",
    "        return np.heaviside(x, 1)\n",
    "\n",
    "    @staticmethod\n",
    "    def linear(x):\n",
    "        \"\"\" y = f(x) It returns the input as it is\"\"\"\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def tanh(x):\n",
    "        \"\"\" It returns the value (1-exp(-2x))/(1+exp(-2x)) and the value returned will be lies in between -1 to 1\"\"\"\n",
    "        return np.tanh(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def relu(x):  # Rectified Linear Unit\n",
    "        \"\"\" It returns zero if the input is less than zero otherwise it returns the given input\"\"\"\n",
    "        x1 = []\n",
    "        for i in x:\n",
    "            if i < 0:\n",
    "                x1.append(0)\n",
    "            else:\n",
    "                x1.append(i)\n",
    "\n",
    "        return x1\n",
    "\n",
    "    @staticmethod\n",
    "    def leakyRelu(x):\n",
    "        \"\"\" It returns zero if the input is less than zero otherwise it returns the given input\"\"\"\n",
    "        x1 = []\n",
    "        for i in x:\n",
    "            if i < 0:\n",
    "                x1.append((0.01 * i))\n",
    "            else:\n",
    "                x1.append(i)\n",
    "\n",
    "        return x1\n",
    "\n",
    "    @staticmethod\n",
    "    def parametricRelu(self, a, x):\n",
    "        \"\"\" It returns zero if the input is less than zero otherwise it returns the given input\"\"\"\n",
    "        x1 = []\n",
    "        for i in x:\n",
    "            if i < 0:\n",
    "                x1.append((a * i))\n",
    "            else:\n",
    "                x1.append(i)\n",
    "\n",
    "        return x1\n",
    "\n",
    "    @staticmethod\n",
    "    def softmax(self, x):\n",
    "        \"\"\" Compute softmax values for each sets of scores in x\"\"\"\n",
    "        return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "    # ============ Activation Functions Part Ends ============= #\n",
    "\n",
    "    # ================= Distance Calculation ================== #\n",
    "\n",
    "    @staticmethod\n",
    "    def chebishev(self, cord1, cord2, exponent_h):\n",
    "        dist = 0.0\n",
    "        if ((type(cord1) == int and type(cord2) == int) or ((type(cord1) == float and type(cord2) == float))):\n",
    "            dist = math.pow((cord1 - cord2), exponent_h)\n",
    "        else:\n",
    "            for i, j in zip(cord1, cord2):\n",
    "                dist += math.pow((i - j), exponent_h)\n",
    "        dist = math.pow(dist, (1.0 / exponent_h))\n",
    "        return dist\n",
    "\n",
    "    @staticmethod\n",
    "    def minimum_distance(self, cord1, cord2):\n",
    "        # min(|x1-y1|, |x2-y2|, |x3-y3|, ...)\n",
    "        dist = float('inf')\n",
    "        if ((type(cord1) == int and type(cord2) == int) or ((type(cord1) == float and type(cord2) == float))):\n",
    "            dist = math.fabs(cord1 - cord2)\n",
    "        else:\n",
    "            for i, j in zip(cord1, cord2):\n",
    "                temp_dist = math.fabs(i - j)\n",
    "                if (temp_dist < dist):\n",
    "                    dist = temp_dist\n",
    "        return dist\n",
    "\n",
    "    @staticmethod\n",
    "    def maximum_distance(self, cord1, cord2):\n",
    "        # max(|x1-y1|, |x2-y2|, |x3-y3|, ...)\n",
    "        dist = float('-inf')\n",
    "        if ((type(cord1) == int and type(cord2) == int) or ((type(cord1) == float and type(cord2) == float))):\n",
    "            dist = math.fabs(cord1 - cord2)\n",
    "        else:\n",
    "            for i, j in zip(cord1, cord2):\n",
    "                temp_dist = math.fabs(i - j)\n",
    "                if (temp_dist > dist):\n",
    "                    dist = temp_dist\n",
    "        return dist\n",
    "\n",
    "    @staticmethod\n",
    "    def manhattan(self, cord1, cord2):\n",
    "        # |x1-y1| + |x2-y2| + |x3-y3| + ...\n",
    "        dist = 0.0\n",
    "        if ((type(cord1) == int and type(cord2) == int) or ((type(cord1) == float and type(cord2) == float))):\n",
    "            dist = math.fabs(cord1 - cord2)\n",
    "        else:\n",
    "            for i, j in zip(cord1, cord2):\n",
    "                dist += math.fabs(i - j)\n",
    "        return dist\n",
    "\n",
    "    @staticmethod\n",
    "    def eucledian(self, cord1, cord2):\n",
    "        dist = 0.0\n",
    "        if ((type(cord1) == int and type(cord2) == int) or ((type(cord1) == float and type(cord2) == float))):\n",
    "            dist = math.pow((cord1 - cord2), 2)\n",
    "        else:\n",
    "            for i, j in zip(cord1, cord2):\n",
    "                dist += math.pow((i - j), 2)\n",
    "        return math.pow(dist, 0.5)\n",
    "\n",
    "    # =========== Distance Calculation Ends ============== #\n",
    "\n",
    "    def __init__(self, dimensions=(8, 5), all_weights=(0.1, 0.2), fileName=\"iris\"):\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dimensions : dimension of the neural network\n",
    "            all_weights : the optimal weights we get from the bio-algoANN models\n",
    "        \"\"\"\n",
    "\n",
    "        self.allPop_Weights = []\n",
    "        self.allPopl_Chromosomes = []\n",
    "        self.allPop_ReceivedOut = []\n",
    "        self.allPop_ErrorVal = []\n",
    "\n",
    "        self.all_weights = all_weights\n",
    "\n",
    "        self.fitness = []\n",
    "\n",
    "        # ================== Input dataset and corresponding output ========================= #\n",
    "\n",
    "        self.fileName = fileName\n",
    "        self.fileName += \".csv\"\n",
    "        data = pd.read_csv(self.fileName)\n",
    "\n",
    "        classes = []\n",
    "        output_values_expected = []\n",
    "        input_values = []\n",
    "\n",
    "        # ~~~~ encoding ~~~~#\n",
    "\n",
    "        # labelencoder = LabelEncoder()\n",
    "        # data[data.columns[-1]] = labelencoder.fit_transform(data[data.columns[-1]])\n",
    "\n",
    "        # one hot encoding - for multi-column\n",
    "        # enc = OneHotEncoder(handle_unknown='ignore')\n",
    "        # combinedData = np.vstack((data[data.columns[-2]], data[data.columns[-1]])).T\n",
    "        # print(combinedData)\n",
    "        # y = enc.fit_transform(combinedData).toarray()\n",
    "        # y = OneHotEncoder().fit_transform(combinedData).toarray()\n",
    "\n",
    "        #\n",
    "        y = LabelBinarizer().fit_transform(data[data.columns[-1]])\n",
    "        # print(y)\n",
    "\n",
    "        # ~~~~ encoding ends~~~~#\n",
    "\n",
    "        for j in range(len(data)):\n",
    "            output_values_expected.append(y[j])\n",
    "\n",
    "        # print(output_values_expected)\n",
    "\n",
    "        input_values = []\n",
    "        for j in range(len(data)):\n",
    "            b = []\n",
    "            for i in range(1, len(data.columns) - 1):\n",
    "                b.append(data[data.columns[i]][j])\n",
    "            input_values.append(b)\n",
    "\n",
    "        self.X = input_values[:]\n",
    "        self.Y = output_values_expected[:]\n",
    "\n",
    "        # input and output\n",
    "        self.X = input_values[:]\n",
    "        self.Y = output_values_expected[:]\n",
    "\n",
    "        self.dimension = dimensions\n",
    "        # print(self.dimension)\n",
    "\n",
    "        # ================ Finding Initial Weights ================ #\n",
    "\n",
    "        self.pop = []  # weights\n",
    "        reshaped_all_weights = []\n",
    "        start = 0\n",
    "        for i in range(len(self.dimension) - 1):\n",
    "            end = start + self.dimension[i + 1] * self.dimension[i]\n",
    "            temp_arr = self.all_weights[start:end]\n",
    "            w = np.reshape(temp_arr[:], (self.dimension[i + 1], self.dimension[i]))\n",
    "            reshaped_all_weights.append(w)\n",
    "            start = end\n",
    "        self.pop.append(reshaped_all_weights)\n",
    "\n",
    "        self.init_pop = self.all_weights\n",
    "\n",
    "    # ================ Initial Weights Part Ends ================ #\n",
    "\n",
    "\n",
    "    def Predict(self, chromo):\n",
    "        # X, Y and pop are used\n",
    "        self.fitness = []\n",
    "        total_error = 0\n",
    "        m_arr = []\n",
    "        k1 = 0\n",
    "        for i in range(len(self.dimension) - 1):\n",
    "            p = self.dimension[i]\n",
    "            q = self.dimension[i + 1]\n",
    "            k2 = k1 + p * q\n",
    "            m_temp = chromo[k1:k2]\n",
    "            m_arr.append(np.reshape(m_temp, (p, q)))\n",
    "            k1 = k2\n",
    "\n",
    "        y_predicted = []\n",
    "        for x, y in zip(self.X, self.Y):\n",
    "\n",
    "            yo = x\n",
    "\n",
    "            for mCount in range(len(m_arr)):\n",
    "                yo = np.dot(yo, m_arr[mCount])\n",
    "                yo = self.sigmoid(yo)\n",
    "            \n",
    "            # converting to sklearn acceptable form\n",
    "            max_yo = max(yo)\n",
    "            for y_vals in range(len(yo)):\n",
    "                if(yo[y_vals] == max_yo):\n",
    "                    yo[y_vals] = 1\n",
    "                else:\n",
    "                    yo[y_vals] = 0\n",
    "            y_predicted.append(yo)\n",
    "        return (y_predicted, self.Y)\n",
    "\n",
    "    def main(self):\n",
    "        Y_PREDICT, Y_ACTUAL = self.Predict(self.init_pop)\n",
    "        Y_PREDICT = np.array(Y_PREDICT)\n",
    "        Y_ACTUAL = np.array(Y_ACTUAL)\n",
    "        \n",
    "        n_classes = 3\n",
    "        \n",
    "        label_binarizer = LabelBinarizer()\n",
    "        label_binarizer.fit(range(n_classes))\n",
    "        Y_PREDICT = label_binarizer.inverse_transform(np.array(Y_PREDICT))\n",
    "        Y_ACTUAL = label_binarizer.inverse_transform(np.array(Y_ACTUAL))\n",
    "        \n",
    "        # find error\n",
    "        \n",
    "        print(\"\\n Actual / Expected\", Y_ACTUAL)\n",
    "        print(\"\\n Predictions\", Y_PREDICT)\n",
    "        print(\"\\n\\nConfusion Matrix\")\n",
    "        print(confusion_matrix(Y_ACTUAL, Y_PREDICT))\n",
    "        \n",
    "        print(\"\\n\\nClassification Report\")\n",
    "        target_names = ['class 0', 'class 1', 'class 2']\n",
    "        print(classification_report(Y_ACTUAL, Y_PREDICT, target_names=target_names))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6cab7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for inputting data :  0.00498652458190918\n",
      "============ Calling PSO to get best weights ===============\n",
      "--------------GENERATION 0-----------\n",
      "-253.30173931169307\n",
      "--------------GENERATION 1-----------\n",
      "-236.17705152791774\n",
      "--------------GENERATION 2-----------\n",
      "-279.83974437864146\n",
      "--------------GENERATION 3-----------\n",
      "-255.5734873159525\n",
      "--------------GENERATION 4-----------\n",
      "-120.99999999852317\n",
      "--------------GENERATION 5-----------\n",
      "-130.441241321886\n",
      "--------------GENERATION 6-----------\n",
      "-104.99999999999895\n",
      "--------------GENERATION 7-----------\n",
      "-150.0\n",
      "--------------GENERATION 8-----------\n",
      "-150.0\n",
      "--------------GENERATION 9-----------\n",
      "-148.99999999959704\n",
      "--------------GENERATION 10-----------\n",
      "-140.999999921166\n",
      "--------------GENERATION 11-----------\n",
      "-145.99997461486475\n",
      "--------------GENERATION 12-----------\n",
      "-144.9993621414693\n",
      "--------------GENERATION 13-----------\n",
      "-141.9975700635367\n",
      "--------------GENERATION 14-----------\n",
      "-147.99990885613352\n",
      "--------------GENERATION 15-----------\n",
      "-149.9985931423184\n",
      "--------------GENERATION 16-----------\n",
      "-148.99999999769955\n",
      "--------------GENERATION 17-----------\n",
      "-150.0\n",
      "--------------GENERATION 18-----------\n",
      "-150.0\n",
      "--------------GENERATION 19-----------\n",
      "-150.0\n",
      "--------------GENERATION 20-----------\n",
      "-150.0\n",
      "--------------GENERATION 21-----------\n",
      "-150.0\n",
      "--------------GENERATION 22-----------\n",
      "-150.0\n",
      "--------------GENERATION 23-----------\n",
      "-150.0\n",
      "--------------GENERATION 24-----------\n",
      "-150.0\n",
      "--------------GENERATION 25-----------\n",
      "-150.0\n",
      "--------------GENERATION 26-----------\n",
      "-149.99999999991388\n",
      "--------------GENERATION 27-----------\n",
      "-151.00000940725377\n",
      "--------------GENERATION 28-----------\n",
      "-150.9999999960465\n",
      "--------------GENERATION 29-----------\n",
      "-149.99999911189593\n",
      "--------------GENERATION 30-----------\n",
      "-139.00015323469307\n",
      "--------------GENERATION 31-----------\n",
      "-137.00010933567893\n",
      "--------------GENERATION 32-----------\n",
      "-143.58454681354732\n",
      "--------------GENERATION 33-----------\n",
      "-145.99999901655755\n",
      "--------------GENERATION 34-----------\n",
      "-150.9999350471045\n",
      "--------------GENERATION 35-----------\n",
      "-149.0001151557661\n",
      "--------------GENERATION 36-----------\n",
      "-149.00033481472138\n",
      "--------------GENERATION 37-----------\n",
      "-149.97498886608008\n",
      "--------------GENERATION 38-----------\n",
      "-149.97564355983215\n",
      "--------------GENERATION 39-----------\n",
      "-150.87492048214983\n",
      "--------------GENERATION 40-----------\n",
      "-149.8884207889753\n",
      "--------------GENERATION 41-----------\n",
      "-149.8872361309793\n",
      "--------------GENERATION 42-----------\n",
      "-149.9624090107021\n",
      "--------------GENERATION 43-----------\n",
      "-149.97197618147342\n",
      "--------------GENERATION 44-----------\n",
      "-149.99999999935403\n",
      "--------------GENERATION 45-----------\n",
      "-148.99999999990473\n",
      "--------------GENERATION 46-----------\n",
      "-148.99999999990473\n",
      "--------------GENERATION 47-----------\n",
      "-149.04343605076772\n",
      "--------------GENERATION 48-----------\n",
      "-149.68809862667277\n",
      "--------------GENERATION 49-----------\n",
      "-149.9647270902033\n",
      "--------------GENERATION 50-----------\n",
      "-149.9758100764127\n",
      "--------------GENERATION 51-----------\n",
      "-149.78026939140986\n",
      "--------------GENERATION 52-----------\n",
      "-149.30102173552552\n",
      "--------------GENERATION 53-----------\n",
      "-148.89901022490557\n",
      "--------------GENERATION 54-----------\n",
      "-149.77515831974105\n",
      "--------------GENERATION 55-----------\n",
      "-149.91471712835528\n",
      "--------------GENERATION 56-----------\n",
      "-149.94464657746371\n",
      "--------------GENERATION 57-----------\n",
      "-149.99296960341076\n",
      "--------------GENERATION 58-----------\n",
      "-149.9964676859156\n",
      "--------------GENERATION 59-----------\n",
      "-149.99904081174122\n",
      "--------------GENERATION 60-----------\n",
      "-149.9990406727425\n",
      "--------------GENERATION 61-----------\n",
      "-149.99904065289857\n",
      "--------------GENERATION 62-----------\n",
      "-149.99904065289857\n",
      "--------------GENERATION 63-----------\n",
      "-149.99904065289857\n",
      "--------------GENERATION 64-----------\n",
      "-149.99911716667094\n",
      "--------------GENERATION 65-----------\n",
      "-149.99894052420157\n",
      "--------------GENERATION 66-----------\n",
      "-149.99297279839126\n",
      "--------------GENERATION 67-----------\n",
      "-149.9929724970732\n",
      "--------------GENERATION 68-----------\n",
      "-149.9985613316023\n",
      "--------------GENERATION 69-----------\n",
      "-149.99740015809726\n",
      "--------------GENERATION 70-----------\n",
      "-149.9999999997358\n",
      "--------------GENERATION 71-----------\n",
      "-149.99999999990274\n",
      "--------------GENERATION 72-----------\n",
      "-149.99295418701968\n",
      "--------------GENERATION 73-----------\n",
      "-149.98269517501726\n",
      "--------------GENERATION 74-----------\n",
      "-149.975293762667\n",
      "--------------GENERATION 75-----------\n",
      "-149.92521427788336\n",
      "--------------GENERATION 76-----------\n",
      "-149.92521406998642\n",
      "--------------GENERATION 77-----------\n",
      "-149.94002519566473\n",
      "--------------GENERATION 78-----------\n",
      "-149.86208920743292\n",
      "--------------GENERATION 79-----------\n",
      "-148.99999999996436\n",
      "--------------GENERATION 80-----------\n",
      "-148.99999999999503\n",
      "--------------GENERATION 81-----------\n",
      "-149.99999999999935\n",
      "--------------GENERATION 82-----------\n",
      "-149.99999999999503\n",
      "--------------GENERATION 83-----------\n",
      "-149.97429029744177\n",
      "--------------GENERATION 84-----------\n",
      "-149.9488347533504\n",
      "--------------GENERATION 85-----------\n",
      "-149.94890135876113\n",
      "--------------GENERATION 86-----------\n",
      "-149.9323720603868\n",
      "--------------GENERATION 87-----------\n",
      "-149.86711164006635\n",
      "--------------GENERATION 88-----------\n",
      "-149.67797326702666\n",
      "--------------GENERATION 89-----------\n",
      "-149.99999999974636\n",
      "--------------GENERATION 90-----------\n",
      "-149.99999999999923\n",
      "--------------GENERATION 91-----------\n",
      "-150.0\n",
      "--------------GENERATION 92-----------\n",
      "-150.0\n",
      "--------------GENERATION 93-----------\n",
      "-150.0\n",
      "--------------GENERATION 94-----------\n",
      "-150.0\n",
      "--------------GENERATION 95-----------\n",
      "-150.0\n",
      "--------------GENERATION 96-----------\n",
      "-150.0\n",
      "--------------GENERATION 97-----------\n",
      "-150.0\n",
      "--------------GENERATION 98-----------\n",
      "-150.0\n",
      "--------------GENERATION 99-----------\n",
      "-150.0\n",
      "Global :  [-32.99382202631795]\n",
      "Time taken :  39.29892826080322\n",
      "\n",
      " Fitness :  [-32.99382202631795] \n",
      " Best Weights :  [ -30.66836818  189.30678676   43.09699749 ... -181.00310616  -88.74824893\n",
      " -111.7150235 ] \n",
      " Dimensions :  [4, 100, 10, 3]\n",
      "Time Taken :  39.31289100646973\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "i = InputData(fileName=\"../ANN/iris\")\n",
    "input_val, output_val = i.main()\n",
    "end_time = time.time()\n",
    "print(\"Time for inputting data : \", end_time - start_time)\n",
    "        \n",
    "print(\"============ Calling PSO to get best weights ===============\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "a = psoAnn(initialPopSize=100, m=10, input_values=input_val, output_values_expected=output_val, iterations = 100, dimensions = [100,10])\n",
    "\n",
    "fit, b, weights, dim = a.main()\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Time taken : \", end_time - start_time)\n",
    "\n",
    "print(\"\\n Fitness : \", fit, \"\\n Best Weights : \", weights, \"\\n Dimensions : \", dim)\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "x=b[:]\n",
    "z=[i for i in range(0,100)]\n",
    "plt.plot(z,x)\n",
    "\n",
    "plt.title(\"PSO\")\n",
    "plt.ylabel(\"Fitness\")\n",
    "plt.xlabel(\"Time\")\n",
    "end_time = time.time()\n",
    "print(\"Time Taken : \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "676443f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============= MLP Program Begins ============\n",
      "Training\n",
      "\n",
      " Actual / Expected [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2]\n",
      "\n",
      " Predictions [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 2 0 2 1 2 1 2 1 1 1 1 1 1 0 1 1 1 2\n",
      " 2 2 1 1 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2\n",
      " 2 2 2 2 2 2 2 2 2]\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[40  0  0]\n",
      " [ 5 27  8]\n",
      " [ 0  1 39]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.89      1.00      0.94        40\n",
      "     class 1       0.96      0.68      0.79        40\n",
      "     class 2       0.83      0.97      0.90        40\n",
      "\n",
      "    accuracy                           0.88       120\n",
      "   macro avg       0.89      0.88      0.88       120\n",
      "weighted avg       0.89      0.88      0.88       120\n",
      "\n",
      "Time taken =  0.010968923568725586\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n============= MLP Program Begins ============\")\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"Training\")\n",
    "m = MultiLayerPerceptron(fileName=\"../ANN/iris_train\", dimensions=dim, all_weights=weights)\n",
    "m.main()\n",
    "end_time = time.time()\n",
    "print(\"Time taken = \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c834af83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n",
      "\n",
      " Actual / Expected [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2]\n",
      "\n",
      " Predictions [0 0 0 0 0 0 0 0 0 0 2 1 1 0 1 2 1 1 0 1 2 2 2 2 2 2 2 2 2 2]\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[10  0  0]\n",
      " [ 2  6  2]\n",
      " [ 0  0 10]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.83      1.00      0.91        10\n",
      "     class 1       1.00      0.60      0.75        10\n",
      "     class 2       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.87        30\n",
      "   macro avg       0.89      0.87      0.86        30\n",
      "weighted avg       0.89      0.87      0.86        30\n",
      "\n",
      "Time taken =  0.00797891616821289\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Testing\")\n",
    "m = MultiLayerPerceptron(fileName=\"../ANN/iris_test\", dimensions=dim, all_weights=weights)\n",
    "m.main()\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Time taken = \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e52f45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
