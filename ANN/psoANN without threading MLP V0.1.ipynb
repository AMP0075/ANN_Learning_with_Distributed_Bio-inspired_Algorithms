{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e62cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fedefee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn import preprocessing\n",
    "from scipy.special import expit\n",
    "\n",
    "from numpy.random import default_rng\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import time\n",
    "\n",
    "from psoAnn_V_I import *\n",
    "\n",
    "\n",
    "\n",
    "class MultiLayerPerceptron():\n",
    "    # ================== Activation Functions ================ #\n",
    "\n",
    "    # accepts a vector or list and returns a list after performing corresponding function on all elements\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(vectorSig):\n",
    "        \"\"\"returns 1/(1+exp(-x)), where the output values lies between zero and one\"\"\"\n",
    "        sig = expit(vectorSig)\n",
    "        return sig\n",
    "\n",
    "    @staticmethod\n",
    "    def binaryStep(x):\n",
    "        \"\"\" It returns '0' is the input is less then zero otherwise it returns one \"\"\"\n",
    "        return np.heaviside(x, 1)\n",
    "\n",
    "    @staticmethod\n",
    "    def linear(x):\n",
    "        \"\"\" y = f(x) It returns the input as it is\"\"\"\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def tanh(x):\n",
    "        \"\"\" It returns the value (1-exp(-2x))/(1+exp(-2x)) and the value returned will be lies in between -1 to 1\"\"\"\n",
    "        return np.tanh(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def relu(x):  # Rectified Linear Unit\n",
    "        \"\"\" It returns zero if the input is less than zero otherwise it returns the given input\"\"\"\n",
    "        x1 = []\n",
    "        for i in x:\n",
    "            if i < 0:\n",
    "                x1.append(0)\n",
    "            else:\n",
    "                x1.append(i)\n",
    "\n",
    "        return x1\n",
    "\n",
    "    @staticmethod\n",
    "    def leakyRelu(x):\n",
    "        \"\"\" It returns zero if the input is less than zero otherwise it returns the given input\"\"\"\n",
    "        x1 = []\n",
    "        for i in x:\n",
    "            if i < 0:\n",
    "                x1.append((0.01 * i))\n",
    "            else:\n",
    "                x1.append(i)\n",
    "\n",
    "        return x1\n",
    "\n",
    "    @staticmethod\n",
    "    def parametricRelu(self, a, x):\n",
    "        \"\"\" It returns zero if the input is less than zero otherwise it returns the given input\"\"\"\n",
    "        x1 = []\n",
    "        for i in x:\n",
    "            if i < 0:\n",
    "                x1.append((a * i))\n",
    "            else:\n",
    "                x1.append(i)\n",
    "\n",
    "        return x1\n",
    "\n",
    "    @staticmethod\n",
    "    def softmax(self, x):\n",
    "        \"\"\" Compute softmax values for each sets of scores in x\"\"\"\n",
    "        return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "    # ============ Activation Functions Part Ends ============= #\n",
    "\n",
    "    # ================= Distance Calculation ================== #\n",
    "\n",
    "    @staticmethod\n",
    "    def chebishev(self, cord1, cord2, exponent_h):\n",
    "        dist = 0.0\n",
    "        if ((type(cord1) == int and type(cord2) == int) or ((type(cord1) == float and type(cord2) == float))):\n",
    "            dist = math.pow((cord1 - cord2), exponent_h)\n",
    "        else:\n",
    "            for i, j in zip(cord1, cord2):\n",
    "                dist += math.pow((i - j), exponent_h)\n",
    "        dist = math.pow(dist, (1.0 / exponent_h))\n",
    "        return dist\n",
    "\n",
    "    @staticmethod\n",
    "    def minimum_distance(self, cord1, cord2):\n",
    "        # min(|x1-y1|, |x2-y2|, |x3-y3|, ...)\n",
    "        dist = float('inf')\n",
    "        if ((type(cord1) == int and type(cord2) == int) or ((type(cord1) == float and type(cord2) == float))):\n",
    "            dist = math.fabs(cord1 - cord2)\n",
    "        else:\n",
    "            for i, j in zip(cord1, cord2):\n",
    "                temp_dist = math.fabs(i - j)\n",
    "                if (temp_dist < dist):\n",
    "                    dist = temp_dist\n",
    "        return dist\n",
    "\n",
    "    @staticmethod\n",
    "    def maximum_distance(self, cord1, cord2):\n",
    "        # max(|x1-y1|, |x2-y2|, |x3-y3|, ...)\n",
    "        dist = float('-inf')\n",
    "        if ((type(cord1) == int and type(cord2) == int) or ((type(cord1) == float and type(cord2) == float))):\n",
    "            dist = math.fabs(cord1 - cord2)\n",
    "        else:\n",
    "            for i, j in zip(cord1, cord2):\n",
    "                temp_dist = math.fabs(i - j)\n",
    "                if (temp_dist > dist):\n",
    "                    dist = temp_dist\n",
    "        return dist\n",
    "\n",
    "    @staticmethod\n",
    "    def manhattan(self, cord1, cord2):\n",
    "        # |x1-y1| + |x2-y2| + |x3-y3| + ...\n",
    "        dist = 0.0\n",
    "        if ((type(cord1) == int and type(cord2) == int) or ((type(cord1) == float and type(cord2) == float))):\n",
    "            dist = math.fabs(cord1 - cord2)\n",
    "        else:\n",
    "            for i, j in zip(cord1, cord2):\n",
    "                dist += math.fabs(i - j)\n",
    "        return dist\n",
    "\n",
    "    @staticmethod\n",
    "    def eucledian(self, cord1, cord2):\n",
    "        dist = 0.0\n",
    "        if ((type(cord1) == int and type(cord2) == int) or ((type(cord1) == float and type(cord2) == float))):\n",
    "            dist = math.pow((cord1 - cord2), 2)\n",
    "        else:\n",
    "            for i, j in zip(cord1, cord2):\n",
    "                dist += math.pow((i - j), 2)\n",
    "        return math.pow(dist, 0.5)\n",
    "\n",
    "    # =========== Distance Calculation Ends ============== #\n",
    "\n",
    "    def __init__(self, dimensions=(8, 5), all_weights=(0.1, 0.2), fileName=\"iris\"):\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dimensions : dimension of the neural network\n",
    "            all_weights : the optimal weights we get from the bio-algoANN models\n",
    "        \"\"\"\n",
    "\n",
    "        self.allPop_Weights = []\n",
    "        self.allPopl_Chromosomes = []\n",
    "        self.allPop_ReceivedOut = []\n",
    "        self.allPop_ErrorVal = []\n",
    "\n",
    "        self.all_weights = all_weights\n",
    "\n",
    "        self.fitness = []\n",
    "\n",
    "        # ================== Input dataset and corresponding output ========================= #\n",
    "\n",
    "        self.fileName = fileName\n",
    "        self.fileName += \".csv\"\n",
    "        data = pd.read_csv(self.fileName)\n",
    "\n",
    "        classes = []\n",
    "        output_values_expected = []\n",
    "        input_values = []\n",
    "\n",
    "        # ~~~~ encoding ~~~~#\n",
    "\n",
    "        # labelencoder = LabelEncoder()\n",
    "        # data[data.columns[-1]] = labelencoder.fit_transform(data[data.columns[-1]])\n",
    "\n",
    "        # one hot encoding - for multi-column\n",
    "        # enc = OneHotEncoder(handle_unknown='ignore')\n",
    "        # combinedData = np.vstack((data[data.columns[-2]], data[data.columns[-1]])).T\n",
    "        # print(combinedData)\n",
    "        # y = enc.fit_transform(combinedData).toarray()\n",
    "        # y = OneHotEncoder().fit_transform(combinedData).toarray()\n",
    "\n",
    "        #\n",
    "        y = LabelBinarizer().fit_transform(data[data.columns[-1]])\n",
    "        # print(y)\n",
    "\n",
    "        # ~~~~ encoding ends~~~~#\n",
    "\n",
    "        for j in range(len(data)):\n",
    "            output_values_expected.append(y[j])\n",
    "\n",
    "        # print(output_values_expected)\n",
    "\n",
    "        input_values = []\n",
    "        for j in range(len(data)):\n",
    "            b = []\n",
    "            for i in range(1, len(data.columns) - 1):\n",
    "                b.append(data[data.columns[i]][j])\n",
    "            input_values.append(b)\n",
    "\n",
    "        self.X = input_values[:]\n",
    "        self.Y = output_values_expected[:]\n",
    "\n",
    "        # input and output\n",
    "        self.X = input_values[:]\n",
    "        self.Y = output_values_expected[:]\n",
    "\n",
    "        self.dimension = dimensions\n",
    "        # print(self.dimension)\n",
    "\n",
    "        # ================ Finding Initial Weights ================ #\n",
    "\n",
    "        self.pop = []  # weights\n",
    "        reshaped_all_weights = []\n",
    "        start = 0\n",
    "        for i in range(len(self.dimension) - 1):\n",
    "            end = start + self.dimension[i + 1] * self.dimension[i]\n",
    "            temp_arr = self.all_weights[start:end]\n",
    "            w = np.reshape(temp_arr[:], (self.dimension[i + 1], self.dimension[i]))\n",
    "            reshaped_all_weights.append(w)\n",
    "            start = end\n",
    "        self.pop.append(reshaped_all_weights)\n",
    "\n",
    "        self.init_pop = self.all_weights\n",
    "\n",
    "    # ================ Initial Weights Part Ends ================ #\n",
    "\n",
    "\n",
    "    def Predict(self, chromo):\n",
    "        # X, Y and pop are used\n",
    "        self.fitness = []\n",
    "        total_error = 0\n",
    "        m_arr = []\n",
    "        k1 = 0\n",
    "        for i in range(len(self.dimension) - 1):\n",
    "            p = self.dimension[i]\n",
    "            q = self.dimension[i + 1]\n",
    "            k2 = k1 + p * q\n",
    "            m_temp = chromo[k1:k2]\n",
    "            m_arr.append(np.reshape(m_temp, (p, q)))\n",
    "            k1 = k2\n",
    "\n",
    "        y_predicted = []\n",
    "        for x, y in zip(self.X, self.Y):\n",
    "\n",
    "            yo = x\n",
    "\n",
    "            for mCount in range(len(m_arr)):\n",
    "                yo = np.dot(yo, m_arr[mCount])\n",
    "                yo = self.sigmoid(yo)\n",
    "            \n",
    "            # converting to sklearn acceptable form\n",
    "            max_yo = max(yo)\n",
    "            for y_vals in range(len(yo)):\n",
    "                if(yo[y_vals] == max_yo):\n",
    "                    yo[y_vals] = 1\n",
    "                else:\n",
    "                    yo[y_vals] = 0\n",
    "            y_predicted.append(yo)\n",
    "        return (y_predicted, self.Y)\n",
    "\n",
    "    def main(self):\n",
    "        Y_PREDICT, Y_ACTUAL = self.Predict(self.init_pop)\n",
    "        Y_PREDICT = np.array(Y_PREDICT)\n",
    "        Y_ACTUAL = np.array(Y_ACTUAL)\n",
    "        \n",
    "        n_classes = 3\n",
    "        \n",
    "        label_binarizer = LabelBinarizer()\n",
    "        label_binarizer.fit(range(n_classes))\n",
    "        Y_PREDICT = label_binarizer.inverse_transform(np.array(Y_PREDICT))\n",
    "        Y_ACTUAL = label_binarizer.inverse_transform(np.array(Y_ACTUAL))\n",
    "        \n",
    "        # find error\n",
    "        \n",
    "        print(\"\\n Actual / Expected\", Y_ACTUAL)\n",
    "        print(\"\\n Predictions\", Y_PREDICT)\n",
    "        print(\"\\n\\nConfusion Matrix\")\n",
    "        print(confusion_matrix(Y_ACTUAL, Y_PREDICT))\n",
    "        \n",
    "        print(\"\\n\\nClassification Report\")\n",
    "        target_names = ['class 0', 'class 1', 'class 2']\n",
    "        print(classification_report(Y_ACTUAL, Y_PREDICT, target_names=target_names))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6cab7fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for inputting data :  0.006544351577758789\n",
      "============ Calling PSO to get best weights ===============\n",
      "--------------GENERATION 0-----------\n",
      "-220.97669435878737\n",
      "--------------GENERATION 1-----------\n",
      "-204.98529086906856\n",
      "--------------GENERATION 2-----------\n",
      "-175.99996894304476\n",
      "--------------GENERATION 3-----------\n",
      "-175.99999839246664\n",
      "--------------GENERATION 4-----------\n",
      "-211.99999991185996\n",
      "--------------GENERATION 5-----------\n",
      "-204.99999999953377\n",
      "--------------GENERATION 6-----------\n",
      "-126.98178442999752\n",
      "--------------GENERATION 7-----------\n",
      "-207.9999999999685\n",
      "--------------GENERATION 8-----------\n",
      "-166.29246564127908\n",
      "--------------GENERATION 9-----------\n",
      "-163.99984031717233\n",
      "--------------GENERATION 10-----------\n",
      "-175.99999999739418\n",
      "--------------GENERATION 11-----------\n",
      "-169.91349137020757\n",
      "--------------GENERATION 12-----------\n",
      "-150.23823179085394\n",
      "--------------GENERATION 13-----------\n",
      "-150.00000007774926\n",
      "--------------GENERATION 14-----------\n",
      "-150.00000000000352\n",
      "--------------GENERATION 15-----------\n",
      "-149.99889671873493\n",
      "--------------GENERATION 16-----------\n",
      "-149.99999999386\n",
      "--------------GENERATION 17-----------\n",
      "-238.00000000000006\n",
      "--------------GENERATION 18-----------\n",
      "-239.03244906872183\n",
      "--------------GENERATION 19-----------\n",
      "-246.0\n",
      "--------------GENERATION 20-----------\n",
      "-150.9999998457809\n",
      "--------------GENERATION 21-----------\n",
      "-152.00137737588543\n",
      "--------------GENERATION 22-----------\n",
      "-150.04905480269613\n",
      "--------------GENERATION 23-----------\n",
      "-195.41742304066307\n",
      "--------------GENERATION 24-----------\n",
      "-195.9906386064477\n",
      "--------------GENERATION 25-----------\n",
      "-195.00753044849253\n",
      "--------------GENERATION 26-----------\n",
      "-270.73062711952673\n",
      "--------------GENERATION 27-----------\n",
      "-220.5264932324703\n",
      "--------------GENERATION 28-----------\n",
      "-151.73774502693496\n",
      "--------------GENERATION 29-----------\n",
      "-150.9956540253406\n",
      "--------------GENERATION 30-----------\n",
      "-150.05984654163962\n",
      "--------------GENERATION 31-----------\n",
      "-209.62183523507628\n",
      "--------------GENERATION 32-----------\n",
      "-217.44226545957386\n",
      "--------------GENERATION 33-----------\n",
      "-219.44251544061117\n",
      "--------------GENERATION 34-----------\n",
      "-200.0100707561667\n",
      "--------------GENERATION 35-----------\n",
      "-203.47759587458097\n",
      "--------------GENERATION 36-----------\n",
      "-171.95399936705817\n",
      "--------------GENERATION 37-----------\n",
      "-150.73959455260916\n",
      "--------------GENERATION 38-----------\n",
      "-142.00000259227346\n",
      "--------------GENERATION 39-----------\n",
      "-141.03274248356124\n",
      "--------------GENERATION 40-----------\n",
      "-147.7756447689336\n",
      "--------------GENERATION 41-----------\n",
      "-170.99998685398813\n",
      "--------------GENERATION 42-----------\n",
      "-172.99999999663444\n",
      "--------------GENERATION 43-----------\n",
      "-172.99999999895417\n",
      "--------------GENERATION 44-----------\n",
      "-144.9184158236951\n",
      "--------------GENERATION 45-----------\n",
      "-148.999370319493\n",
      "--------------GENERATION 46-----------\n",
      "-149.00000022587167\n",
      "--------------GENERATION 47-----------\n",
      "-167.00000000110472\n",
      "--------------GENERATION 48-----------\n",
      "-199.00525284728045\n",
      "--------------GENERATION 49-----------\n",
      "-198.99999971804644\n",
      "--------------GENERATION 50-----------\n",
      "-193.99999459394974\n",
      "--------------GENERATION 51-----------\n",
      "-193.99999459394982\n",
      "--------------GENERATION 52-----------\n",
      "-202.99999985645215\n",
      "--------------GENERATION 53-----------\n",
      "-202.99998766154988\n",
      "--------------GENERATION 54-----------\n",
      "-213.80592736369942\n",
      "--------------GENERATION 55-----------\n",
      "-180.33497687903971\n",
      "--------------GENERATION 56-----------\n",
      "-181.01776032782905\n",
      "--------------GENERATION 57-----------\n",
      "-182.0000332666875\n",
      "--------------GENERATION 58-----------\n",
      "-177.01022960639904\n",
      "--------------GENERATION 59-----------\n",
      "-219.65036674170844\n",
      "--------------GENERATION 60-----------\n",
      "-194.97820610870144\n",
      "--------------GENERATION 61-----------\n",
      "-177.96299521732843\n",
      "--------------GENERATION 62-----------\n",
      "-194.94208698685156\n",
      "--------------GENERATION 63-----------\n",
      "-186.29780855613853\n",
      "--------------GENERATION 64-----------\n",
      "-159.66536425539238\n",
      "--------------GENERATION 65-----------\n",
      "-156.992414707731\n",
      "--------------GENERATION 66-----------\n",
      "-156.9823961484722\n",
      "--------------GENERATION 67-----------\n",
      "-158.98459197120735\n",
      "--------------GENERATION 68-----------\n",
      "-158.99241515667768\n",
      "--------------GENERATION 69-----------\n",
      "-163.6362477412249\n",
      "--------------GENERATION 70-----------\n",
      "-196.81084376578949\n",
      "--------------GENERATION 71-----------\n",
      "-203.5562022925979\n",
      "--------------GENERATION 72-----------\n",
      "-206.8358871540876\n",
      "--------------GENERATION 73-----------\n",
      "-198.99928651029794\n",
      "--------------GENERATION 74-----------\n",
      "-191.9984392464723\n",
      "--------------GENERATION 75-----------\n",
      "-191.9957602302505\n",
      "--------------GENERATION 76-----------\n",
      "-165.0016786570018\n",
      "--------------GENERATION 77-----------\n",
      "-164.00000000016473\n",
      "--------------GENERATION 78-----------\n",
      "-164.00000000016473\n",
      "--------------GENERATION 79-----------\n",
      "-158.9999999999988\n",
      "--------------GENERATION 80-----------\n",
      "-150.00000007774838\n",
      "--------------GENERATION 81-----------\n",
      "-152.00000007774895\n",
      "--------------GENERATION 82-----------\n",
      "-170.0000000000042\n",
      "--------------GENERATION 83-----------\n",
      "-162.9999999999996\n",
      "--------------GENERATION 84-----------\n",
      "-171.00000000189482\n",
      "--------------GENERATION 85-----------\n",
      "-207.9999625585671\n",
      "--------------GENERATION 86-----------\n",
      "-196.98199618225613\n",
      "--------------GENERATION 87-----------\n",
      "-195.94980785296244\n",
      "--------------GENERATION 88-----------\n",
      "-205.99962671165238\n",
      "--------------GENERATION 89-----------\n",
      "-222.99999767522092\n",
      "--------------GENERATION 90-----------\n",
      "-214.99994830572913\n",
      "--------------GENERATION 91-----------\n",
      "-195.98705883901505\n",
      "--------------GENERATION 92-----------\n",
      "-188.8621023043766\n",
      "--------------GENERATION 93-----------\n",
      "-190.94080186446\n",
      "--------------GENERATION 94-----------\n",
      "-205.9003039454884\n",
      "--------------GENERATION 95-----------\n",
      "-177.00000000000455\n",
      "--------------GENERATION 96-----------\n",
      "-170.99999999998295\n",
      "--------------GENERATION 97-----------\n",
      "-171.00003420058073\n",
      "--------------GENERATION 98-----------\n",
      "-170.08982510146973\n",
      "--------------GENERATION 99-----------\n",
      "-172.58830745279008\n",
      "Global :  53.00001836445382\n",
      "Time taken :  38.16949248313904\n",
      "\n",
      " Fitness :  [-53.00001836445382] \n",
      " Best Weights :  [ 62.21331046 -83.55942884 -45.5114572  ... -28.48501523 211.25039474\n",
      " 214.13751284] \n",
      " Dimensions :  [4, 100, 10, 40, 20, 3]\n",
      "Time Taken :  38.18145966529846\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAa+UlEQVR4nO3de5RdZZ3m8e9T96ROUZVUFaECDAkByaJRItTQ3JruFm1BuwGV6cFxEGxGnNUq9mU5Mu2sUVndvdQWGZ3pyWoEFGlbbRAahmlpMV7Q7gG7AgjhGi6JJKmECpAr5Fq/+ePsSo5lFTmVnLfOqb2fz1q1Umef22+78cmb3373uxURmJlZcTTVuwAzM5teDn4zs4Jx8JuZFYyD38ysYBz8ZmYF4+A3MysYB7+ZWcE4+M3GkbRK0muStknaIOlrkkqSfk3S9yS9LGmTpOWS3lHxvh5JSyWtl/SqpEclfaCe+2I2EQe/2cR+LyJKwCnAIPDfgP8D3AscARwOXAVsAZDUBnwfOAY4A+gGPg58VtKfTHv1Zq+jpd4FmDWyiFgr6bvAScBC4CsRsSt7+p8rXnop8G+A34yI7dm2eyRdBdwo6YaI2DJthZu9Do/4zV6HpKOBdwAPAc8AfyvpIknzxr30bcB3K0J/zHeADsr/CjBrCA5+s4n9g6RNwE+BHwN/Cfw2sAq4FhiWdJ+k47PX9wHD4z8kIvYAG7PnzRqCg99sYhdFRE9EHBMRfxgRr0XEmoj4SEQsotzL3w58PXv9RmBg/IdIaqEc+hunrXKzA3Dwmx2EiHgB+GvKvX8on9g9X1LnuJe+B9gJ3D+N5Zm9Lge/WRUkzZH0GUnHSWqS1Af8AfsD/RZgDXCrpAWSWiW9Hfgy8OmI2Fyn0s1+hYPfrDq7gAWUR/ZbgBWUR/KXA0TETuCtwAvAA9lrvgh8MiL+avrLNZucfCMWM7Ni8YjfzKxgHPxmZgXj4DczKxgHv5lZwcyItXr6+vpiwYIF9S7DzGxGWb58+caI6B+/fUYE/4IFCxgaGqp3GWZmM4qk1RNtd6vHzKxgHPxmZgXj4DczKxgHv5lZwTj4zcwKxsFvZlYwDn4zs4KZEfP4D9ayJzbw8xc2HfB1czrbuPzMBUhKX5SZWZ3lOvh//PQIt9w/4fUL+4ytSn3moj5OOKJrGqoyM6uvXAf/NReexDUXnvS6r1m++hXes/RfWLfpNQe/mRVC4Xv883s6AFi3+bU6V2JmNj0KH/yHd3XQ3CSGN+2odylmZtOi8MHf3CTmdbV7xG9mhVH44AcY6JnlEb+ZFYaDHxjo7mDYI34zKwgHP2PBv4MYm9tpZpZjDn5goHsWO/eM8vL2XfUuxcwsOQc/+6d0Dm92n9/M8s/BT3nEDw5+MyuGpMEv6Y8lPSZphaRvSuqQtFDSA5KekfRtSW0pa6jGwL4Rv0/wmln+JQt+SUcCVwGDEXES0AxcAnwOuC4ijgNeAa5IVUO1+jrbaW0W6zyl08wKIHWrpwWYJakFmA0MA28Bbsuevxm4KHENB9TUJI7wlE4zK4hkwR8Ra4EvAL+gHPibgeXApojYk71sDXDkRO+XdKWkIUlDIyMjqcrcZ6DbF3GZWTGkbPXMAS4EFgLzgU7gvGrfHxHXR8RgRAz29/cnqnK/+d0dXrbBzAohZavnrcDzETESEbuB24GzgJ6s9QNwFLA2YQ1VG+iZxYYtOxgd9UVcZpZvKYP/F8DpkmarfGurc4HHgR8CF2evuQy4M2ENVZvf3cHuvcHGbTvrXYqZWVIpe/wPUD6J+yDwaPZd1wOfAP5E0jNAL3BjqhqmYmwu/zrP5TeznEt6B66I+BTwqXGbnwNOS/m9B2PfXP5Nr7Hk6J76FmNmlpCv3M3M94jfzArCwZ/pmd1KR2sTw5s8s8fM8s3Bn5HE/O5ZXq/HzHLPwV9hoMdz+c0s/xz8FXz1rpkVgYO/wvzuDl7cuoM9e0frXYqZWTIO/goDPbMYDdiw1RdxmVl+OfgrHNFdnsu/3n1+M8sxB3+F/lI7AC9t8713zSy/HPwVekvlm4G95Juum1mOOfgrzO3Mgt8LtZlZjjn4K7S3NNPV0cJGt3rMLMcc/OP0ldrd6jGzXHPwj9Pb2eZWj5nlmoN/nN5Sm2f1mFmuOfjH6S2189J2j/jNLL8c/OP0dbbx8vZd7PW9d80spxz84/SW2hkN2PSq2z1mlk8O/nF8EZeZ5Z2Df5zezvKyDRs9s8fMcsrBP07f2IjfM3vMLKcc/OP07luozSN+M8snB/84PbNaaZJ7/GaWXw7+cZqaxNzOdq/XY2a55eCfQF/JyzaYWX61pPpgSScA367YdCzw34Ee4IPASLb9zyLiH1PVcTB6S21u9ZhZbiUb8UfEUxGxJCKWAKcCrwJ3ZE9fN/Zco4U+lKd0esRvZnk1Xa2ec4FnI2L1NH3fIfFCbWaWZ9MV/JcA36x4/BFJj0i6SdKcid4g6UpJQ5KGRkZGJnpJMn2ldrbu3MOO3Xun9XvNzKZD8uCX1AZcANyabVoKLAKWAMPAtRO9LyKuj4jBiBjs7+9PXeYv6c1uwfiy+/xmlkPTMeI/H3gwIjYARMSGiNgbEaPAV4DTpqGGKdl/EZeD38zyZzqC/71UtHkkDVQ89y5gxTTUMCVjC7Vt9Lr8ZpZDyaZzAkjqBN4GfKhi8+clLQECWDXuuYbQ1+kRv5nlV9Lgj4jtQO+4bZem/M5a2Lc0s6d0mlkO+crdCcxua6ajtckXcZlZLjn4JyCJ3s52r8lvZrnk4J9Eny/iMrOccvBPorfUzkue1WNmOeTgn0Rvp0f8ZpZPDv5J9JbaeWnbLiKi3qWYmdWUg38SfaU2du0dZevOPfUuxcysphz8k+j1TdfNLKeSXsA1k/VmV+9e+72n6Cu109wkzl18OGcs6kVSnaszMzt4Dv5JLD6iiyN7ZnHf0+UloXfuGeXGnz7P4iO6uPzMBSw6vHTQn31cf4k52QqgZmbTTTPh5OXg4GAMDQ3VtYYdu/dy58Nr+eo/r+LJ9VsP6bP6u9q5+6NnM++wjhpVZ2b2qyQtj4jBX9nu4J+aiGDF2i1sfm33Qb1/647d/OmtP2fxEV1868ozaGvxaRYzS2Oy4HerZ4ok8cajug/pM0YDPvx3D3LN3Y/x5xe9sUaVmZlVx8FfB+980wCPrDmWv7nvOeZ2tnNcdr5gQe9s3nRUT32LM7Pcc/DXycfffgKPD2/hy8tW7tvW2dbMis+83bOGzCwpB3+dtDQ38bUPnMaql7YTAd95cA1Lf/QsW3bsoXtWa73LM7Mcc/DXUXOTWNRfbvO8YV75z43bdjr4zSwpTylpEH3ZDd43bvWKoGaWloO/QewLfi8RYWaJOfgbxP7g94jfzNJy8DeIuZ1tNMnBb2bpOfgbRHOTmOv7/JrZNHDwN5C+UhsjW93jN7O0HPwNpL/LI34zS8/B30D6Sg5+M0svWfBLOkHSwxU/WyT9kaS5ku6VtDL7c06qGmaacqtnp+/za2ZJJQv+iHgqIpZExBLgVOBV4A7gamBZRBwPLMseG+UR/849o2zzfX7NLKHpavWcCzwbEauBC4Gbs+03AxdNUw0Nzxdxmdl0mK7gvwT4Zvb7vIgYzn5fD8yb6A2SrpQ0JGloZGRkOmqsu74uX8RlZuklD35JbcAFwK3jn4tyM3vChnZEXB8RgxEx2N/fn7jKxtBXKt+H1+v1mFlKUw5+SXMkvWkKbzkfeDAiNmSPN0gayD5rAHhxqjXkVb+XbTCzaVBV8Ev6kaTDJM0FHgS+IumLVX7He9nf5gG4C7gs+/0y4M5qi827uZ1tSDDiHr+ZJVTtiL87IrYA7wa+HhG/Drz1QG+S1Am8Dbi9YvNngbdJWpl9xmenVnJ+tTQ3MXd2m0f8ZpZUtTdiacnaMr8PfLLaD4+I7UDvuG0vUZ7lYxPoK7W7x29mSVU74r8G+CfgmYj4V0nHAisP8B47CH1dHvGbWVpVjfgj4lYqZuVExHPAe1IVVWR9pXYe+sWmepdhZjlW7cndz2cnd1slLZM0Iuk/pi6uiLxej5mlVm2r53eyk7u/C6wCjgM+nqqoIusrtfPqrr1s97INZpZItcE/1hJ6J3BrRGxOVE/h7buIy6N+M0uk2uC/W9KTlBdbWyapH9iRrqzi8rINZpZaVcEfEVcDZwKDEbGb8kqbF6YsrKjGrt71nbjMLJVqT+7OBv4QWJptmg8MpiqqyPq8bIOZJVZtq+erwC7Ko36AtcCfJ6mo4Hrd4zezxKoN/kUR8XlgN0BEvAooWVUF1trcxJzZrQ5+M0um2uDfJWkW2RLKkhYBTqZEyss2uMdvZmlUu1bPp4B7gKMlfQM4C7g8VVFF54u4zCylapdsuFfSg8DplFs8H4uIjUkrK7C+rnYeXbOp3mWYWU5VO+IH6ABeyd5zoiQi4r40ZRVbX6nN9901s2SqCn5JnwP+PfAYMJptDsDBn0BfqZ1tO/ewY/deOlqb612OmeVMtSP+i4ATIsKN52lwWEf5sGzdscfBb2Y1V+2snueA1pSF2H5dHeX/qbfu2F3nSswsj6od8b8KPCxpGRXTOCPiqiRVFVypvXxYtnmFTjNLoNrgvyv7qRQ1rsUypazVs22Hg9/Maq/a4O+JiC9VbpD0sQT1GNCVBf8WB7+ZJVBtj/+yCbZdXsM6rEJXe7nH71aPmaXwuiN+Se8F/gOwUFJlq6cLeDllYUXWtW9Wj0/umlntHajV8y/AMNAHXFuxfSvwSKqiis49fjNL6XWDPyJWA6uBM6anHIPyCp0drU1sdavHzBI4UKvnpxFxtqSt/PIsHgEREYclra7ASu2tbPWI38wSOFCr530AEdF1MB8uqQe4ATiJ8l8cfwC8HfggMJK97M8i4h8P5vPzrKujxSd3zSyJA83quWPsF0nfOYjP/xJwT0QsBk4Gnsi2XxcRS7Ifh/4EujpafHLXzJI40Ii/8i5bx07lgyV1A+eQTfuMiF2Ub+gylY8prFJ7i0/umlkSBxrxxyS/V2Mh5XbOVyU9JOkGSZ3Zcx+R9IikmyTNmejNkq6UNCRpaGRkZKKX5Fp5xO/gN7PaO1DwnyxpS3Zy903Z71skbZW05QDvbQFOAZZGxJuB7cDVwFJgEbCE8lTRayd6c0RcHxGDETHY398/hV3Kh1J7q3v8ZpbEgaZzHsqawGuANRHxQPb4NuDqiNgw9gJJXwHuPoTvyK2ujha2uMdvZglUu2TDlEXEeuAFSSdkm84FHpc0UPGydwErUtUwk43N6onwWnhmVltTufXiwfgo8A1JbZTX9P8A8GVJSyifM1gFfChxDTNSqb2FCHh1114621MfJjMrkqSJEhEPA4PjNl+a8jvzYv/NWPY4+M2sppK1euzQ7FuvZ6f7/GZWWw7+BuU1+c0sFQd/g+pq9wqdZpaGg79BVfb4zcxqycHfoNzjN7NUHPwNav9duDziN7PacvA3qM42B7+ZpeHgb1DNTaKzrdnr9ZhZzTn4G1hXR6vX5DezmnPwN7CS78JlZgk4+BuY1+Q3sxQc/A2s1O7gN7Pac/A3sMPc4zezBBz8DazU7h6/mdWeg7+BlTp8w3Uzqz0HfwPr6mhh+6697B31XbjMrHYc/A2sNLZCp9s9ZlZDDv4Gdti+FTp9gtfMasfB38D2r9DpEb+Z1Y6Dv4F5hU4zS8HB38BKvguXmSXg4G9g++7C5VaPmdWQg7+B7W/1+OSumdWOg7+BudVjZik4+BvY7LZmmuSTu2ZWW0mDX1KPpNskPSnpCUlnSJor6V5JK7M/56SsYSaT5PV6zKzmUo/4vwTcExGLgZOBJ4CrgWURcTywLHtsk+jqaGWLe/xmVkPJgl9SN3AOcCNAROyKiE3AhcDN2ctuBi5KVUMedHmhNjOrsZQj/oXACPBVSQ9JukFSJzAvIoaz16wH5k30ZklXShqSNDQyMpKwzMbW5dsvmlmNpQz+FuAUYGlEvBnYzri2TkQEMOHSkxFxfUQMRsRgf39/wjIbm+/CZWa1ljL41wBrIuKB7PFtlP8i2CBpACD788WENcx4pY5Wj/jNrKaSBX9ErAdekHRCtulc4HHgLuCybNtlwJ2pasiD8g3XfXLXzGqnJfHnfxT4hqQ24DngA5T/svl7SVcAq4HfT1zDjNblVo+Z1VjS4I+Ih4HBCZ46N+X35klXRws794yya88obS2+3s7MDl3qEb8dorFlGy698QFam6sL/uYm8YnzFnPi/MNSlmZmM5SHkA3uzOP6OP3YuewZDV7bvbeqn6FVL/PFe5+qd+lm1qA84m9wb5jXxbeuPGNK77nu3qf50rKVPDuyjUX9pUSVmdlM5RF/Dl16xjG0tTRxw0+er3cpZtaAHPw51Fdq5z2nHMntD65h47ad9S7HzBqMgz+nrjj7WHbuGeWW/7e63qWYWYNx8OfUcYeXOHfx4dxy/2p27N5b73LMrIH45G6OffCcY7nk+vs57S++P+FU0I++5TguP2thHSozs3py8OfYry+cy9XnL2bNK6/+ynP3rNjAj54ecfCbFZCDP8ck8Z9/c9GEz63fvIM1r7w2zRWZWSNwj7+gBrpnsW6Tg9+siBz8BTXQ08GWHXvY7iWfzQrHwV9Q87tnATC82aN+s6Jx8BfUQHcHAOs27ahzJWY23Rz8BTW/xyN+s6Jy8BfUvMM6kDziNysiB39BtbU00Vdq94jfrIAc/AU20N3B8GaP+M2KxsFfYA5+s2Jy8BfYQPcshje9RkTUuxQzm0YO/gKb39PB9l172bLDF3GZFYmDv8AGfBGXWSE5+Atsfk/5Iq5hT+k0KxQHf4GNjfjXecRvVigO/gI7vKudJnnEb1Y0SYNf0ipJj0p6WNJQtu3TktZm2x6W9I6UNdjkWpqbOLzLUzrNimY6bsTy2xGxcdy26yLiC9Pw3XYAAz0dPrlrVjBu9RTc/O5ZHvGbFUzq4A/ge5KWS7qyYvtHJD0i6SZJcyZ6o6QrJQ1JGhoZGUlcZnENdHewzhdxmRVK6uA/OyJOAc4HPizpHGApsAhYAgwD1070xoi4PiIGI2Kwv78/cZnFNdAzi517Rnnl1d31LsXMpknS4I+ItdmfLwJ3AKdFxIaI2BsRo8BXgNNS1mCvb/6+G7K4z29WFMmCX1KnpK6x34HfAVZIGqh42buAFalqsAMb2HdDFvf5zYoi5ayeecAdksa+5+8i4h5Jt0haQrn/vwr4UMIa7ADGRvzrPbPHrDCSBX9EPAecPMH2S1N9p01db6mdliaxziN+s8KYjnn81sCam8S8wzr4v48Ms/aVxh31/97J83nbifPqXYZZLjj4jQuWzOeeFet5dO3mepcyoZe27eT+517inDf00d7SXO9yzGY8B7/xifMW84nzFte7jEnd9/QI77/pZ9z18Dr+3eDR9S7HbMbzlbvW8H7j+D4WH9HFDT953heamdWAg98aniT+028cy1MbtnLfyvHLPpnZVDn4bUa44OT5HN7Vzg0/ea7epZjNeA5+mxHaWpq4/KwF/GTlRh5ft6Xe5ZjNaD65azPG+047hv/1g2d4/00/Y87s1nqXYzYt/vLdb+TfLphb08908NuM0T27lWsuPIkfPLmh3qWYTZtZrbWfwuzgtxnl4lOP4uJTj6p3GWYzmnv8ZmYF4+A3MysYB7+ZWcE4+M3MCsbBb2ZWMA5+M7OCcfCbmRWMg9/MrGA0E5a5lTQCrD7It/cBRVzSsYj7XcR9hmLudxH3Gaa+38dERP/4jTMi+A+FpKGIGKx3HdOtiPtdxH2GYu53EfcZarffbvWYmRWMg9/MrGCKEPzX17uAOinifhdxn6GY+13EfYYa7Xfue/xmZvbLijDiNzOzCg5+M7OCyXXwSzpP0lOSnpF0db3rSUHS0ZJ+KOlxSY9J+li2fa6keyWtzP6cU+9aa01Ss6SHJN2dPV4o6YHseH9bUlu9a6w1ST2SbpP0pKQnJJ2R92Mt6Y+z/7ZXSPqmpI48HmtJN0l6UdKKim0THluVfTnb/0cknTKV78pt8EtqBv4aOB84EXivpBPrW1USe4A/jYgTgdOBD2f7eTWwLCKOB5Zlj/PmY8ATFY8/B1wXEccBrwBX1KWqtL4E3BMRi4GTKe9/bo+1pCOBq4DBiDgJaAYuIZ/H+mvAeeO2TXZszweOz36uBJZO5YtyG/zAacAzEfFcROwCvgVcWOeaai4ihiPiwez3rZSD4EjK+3pz9rKbgYvqUmAiko4C3gnckD0W8BbgtuwledznbuAc4EaAiNgVEZvI+bGmfIvYWZJagNnAMDk81hFxH/DyuM2THdsLga9H2f1Aj6SBar8rz8F/JPBCxeM12bbckrQAeDPwADAvIoazp9YD8+pVVyL/A/gvwGj2uBfYFBF7ssd5PN4LgRHgq1mL6wZJneT4WEfEWuALwC8oB/5mYDn5P9ZjJju2h5RveQ7+QpFUAr4D/FFEbKl8LspzdnMzb1fS7wIvRsTyetcyzVqAU4ClEfFmYDvj2jo5PNZzKI9uFwLzgU5+tR1SCLU8tnkO/rXA0RWPj8q25Y6kVsqh/42IuD3bvGHsn37Zny/Wq74EzgIukLSKcgvvLZR73z1ZOwDyebzXAGsi4oHs8W2U/yLI87F+K/B8RIxExG7gdsrHP+/Hesxkx/aQ8i3Pwf+vwPHZ2f82yieE7qpzTTWX9bZvBJ6IiC9WPHUXcFn2+2XAndNdWyoR8V8j4qiIWED5uP4gIt4H/BC4OHtZrvYZICLWAy9IOiHbdC7wODk+1pRbPKdLmp39tz62z7k+1hUmO7Z3Ae/PZvecDmyuaAkdWETk9gd4B/A08CzwyXrXk2gfz6b8z79HgIezn3dQ7nkvA1YC3wfm1rvWRPv/W8Dd2e/HAj8DngFuBdrrXV+C/V0CDGXH+x+AOXk/1sBngCeBFcAtQHsejzXwTcrnMXZT/tfdFZMdW0CUZy0+CzxKedZT1d/lJRvMzAomz60eMzObgIPfzKxgHPxmZgXj4DczKxgHv5lZwTj4zSpI6pX0cPazXtLa7Pdtkv53veszqwVP5zSbhKRPA9si4gv1rsWsljziN6uCpN+qWPf/05JulvQTSaslvVvS5yU9KumebAkNJJ0q6ceSlkv6p6msnmiWkoPf7OAsorxG0AXA3wI/jIg3Aq8B78zC/38CF0fEqcBNwF/Uq1izSi0HfomZTeC7EbFb0qOUbw5yT7b9UWABcAJwEnBveYkZmilfjm9Wdw5+s4OzEyAiRiXtjv0ny0Yp//9KwGMRcUa9CjSbjFs9Zmk8BfRLOgPKS2dL+rU612QGOPjNkojy7T4vBj4n6eeUV009s65FmWU8ndPMrGA84jczKxgHv5lZwTj4zcwKxsFvZlYwDn4zs4Jx8JuZFYyD38ysYP4/C132rcPo8B0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "i = InputData(fileName=\"../ANN/iris\")\n",
    "input_val, output_val = i.main()\n",
    "end_time = time.time()\n",
    "print(\"Time for inputting data : \", end_time - start_time)\n",
    "        \n",
    "print(\"============ Calling PSO to get best weights ===============\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "a = psoAnn(initialPopSize=100, input_values=input_val, output_values_expected=output_val, iterations = 100, dimensions = [100,10])\n",
    "\n",
    "fit, b, weights, dim = a.main()\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Time taken : \", end_time - start_time)\n",
    "\n",
    "print(\"\\n Fitness : \", fit, \"\\n Best Weights : \", weights, \"\\n Dimensions : \", dim)\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "x=b[:]\n",
    "z=[i for i in range(0,100)]\n",
    "plt.plot(z,x)\n",
    "\n",
    "plt.title(\"PSO\")\n",
    "plt.ylabel(\"Fitness\")\n",
    "plt.xlabel(\"Time\")\n",
    "end_time = time.time()\n",
    "print(\"Time Taken : \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "676443f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============= MLP Program Begins ============\n",
      "Training\n",
      "\n",
      " Actual / Expected [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2]\n",
      "\n",
      " Predictions [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2\n",
      " 1 1 1 1 1 1 2 2 2 2 2 2 2 1 2 1 2 2 2 2 2 1 2 1 2 2 2 2 2 2 2 2 1 2 2 2 2\n",
      " 2 2 2 2 1 2 2 2 1]\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[40  0  0]\n",
      " [ 0 38  2]\n",
      " [ 0  7 33]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      1.00      1.00        40\n",
      "     class 1       0.84      0.95      0.89        40\n",
      "     class 2       0.94      0.82      0.88        40\n",
      "\n",
      "    accuracy                           0.93       120\n",
      "   macro avg       0.93      0.92      0.92       120\n",
      "weighted avg       0.93      0.93      0.92       120\n",
      "\n",
      "Time taken =  0.010965585708618164\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n============= MLP Program Begins ============\")\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"Training\")\n",
    "m = MultiLayerPerceptron(fileName=\"../ANN/iris_train\", dimensions=dim, all_weights=weights)\n",
    "m.main()\n",
    "end_time = time.time()\n",
    "print(\"Time taken = \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c834af83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n",
      "\n",
      " Actual / Expected [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2]\n",
      "\n",
      " Predictions [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1 1 2 1 2 2 2 1 1 2 2 2]\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[10  0  0]\n",
      " [ 1  9  0]\n",
      " [ 0  3  7]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.91      1.00      0.95        10\n",
      "     class 1       0.75      0.90      0.82        10\n",
      "     class 2       1.00      0.70      0.82        10\n",
      "\n",
      "    accuracy                           0.87        30\n",
      "   macro avg       0.89      0.87      0.86        30\n",
      "weighted avg       0.89      0.87      0.86        30\n",
      "\n",
      "Time taken =  0.005980730056762695\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Testing\")\n",
    "m = MultiLayerPerceptron(fileName=\"../ANN/iris_test\", dimensions=dim, all_weights=weights)\n",
    "m.main()\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Time taken = \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e52f45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
