{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb5a447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50dfaafc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn import preprocessing\n",
    "from scipy.special import expit\n",
    "\n",
    "from numpy.random import default_rng\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import time\n",
    "\n",
    "from ffaAnn_thread_V_I import *\n",
    "\n",
    "\n",
    "\n",
    "class MultiLayerPerceptron():\n",
    "    # ================== Activation Functions ================ #\n",
    "\n",
    "    # accepts a vector or list and returns a list after performing corresponding function on all elements\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(vectorSig):\n",
    "        \"\"\"returns 1/(1+exp(-x)), where the output values lies between zero and one\"\"\"\n",
    "        sig = expit(vectorSig)\n",
    "        return sig\n",
    "\n",
    "    @staticmethod\n",
    "    def binaryStep(x):\n",
    "        \"\"\" It returns '0' is the input is less then zero otherwise it returns one \"\"\"\n",
    "        return np.heaviside(x, 1)\n",
    "\n",
    "    @staticmethod\n",
    "    def linear(x):\n",
    "        \"\"\" y = f(x) It returns the input as it is\"\"\"\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def tanh(x):\n",
    "        \"\"\" It returns the value (1-exp(-2x))/(1+exp(-2x)) and the value returned will be lies in between -1 to 1\"\"\"\n",
    "        return np.tanh(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def relu(x):  # Rectified Linear Unit\n",
    "        \"\"\" It returns zero if the input is less than zero otherwise it returns the given input\"\"\"\n",
    "        x1 = []\n",
    "        for i in x:\n",
    "            if i < 0:\n",
    "                x1.append(0)\n",
    "            else:\n",
    "                x1.append(i)\n",
    "\n",
    "        return x1\n",
    "\n",
    "    @staticmethod\n",
    "    def leakyRelu(x):\n",
    "        \"\"\" It returns zero if the input is less than zero otherwise it returns the given input\"\"\"\n",
    "        x1 = []\n",
    "        for i in x:\n",
    "            if i < 0:\n",
    "                x1.append((0.01 * i))\n",
    "            else:\n",
    "                x1.append(i)\n",
    "\n",
    "        return x1\n",
    "\n",
    "    @staticmethod\n",
    "    def parametricRelu(self, a, x):\n",
    "        \"\"\" It returns zero if the input is less than zero otherwise it returns the given input\"\"\"\n",
    "        x1 = []\n",
    "        for i in x:\n",
    "            if i < 0:\n",
    "                x1.append((a * i))\n",
    "            else:\n",
    "                x1.append(i)\n",
    "\n",
    "        return x1\n",
    "\n",
    "    @staticmethod\n",
    "    def softmax(self, x):\n",
    "        \"\"\" Compute softmax values for each sets of scores in x\"\"\"\n",
    "        return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "    # ============ Activation Functions Part Ends ============= #\n",
    "\n",
    "    # ================= Distance Calculation ================== #\n",
    "\n",
    "    @staticmethod\n",
    "    def chebishev(self, cord1, cord2, exponent_h):\n",
    "        dist = 0.0\n",
    "        if ((type(cord1) == int and type(cord2) == int) or ((type(cord1) == float and type(cord2) == float))):\n",
    "            dist = math.pow((cord1 - cord2), exponent_h)\n",
    "        else:\n",
    "            for i, j in zip(cord1, cord2):\n",
    "                dist += math.pow((i - j), exponent_h)\n",
    "        dist = math.pow(dist, (1.0 / exponent_h))\n",
    "        return dist\n",
    "\n",
    "    @staticmethod\n",
    "    def minimum_distance(self, cord1, cord2):\n",
    "        # min(|x1-y1|, |x2-y2|, |x3-y3|, ...)\n",
    "        dist = float('inf')\n",
    "        if ((type(cord1) == int and type(cord2) == int) or ((type(cord1) == float and type(cord2) == float))):\n",
    "            dist = math.fabs(cord1 - cord2)\n",
    "        else:\n",
    "            for i, j in zip(cord1, cord2):\n",
    "                temp_dist = math.fabs(i - j)\n",
    "                if (temp_dist < dist):\n",
    "                    dist = temp_dist\n",
    "        return dist\n",
    "\n",
    "    @staticmethod\n",
    "    def maximum_distance(self, cord1, cord2):\n",
    "        # max(|x1-y1|, |x2-y2|, |x3-y3|, ...)\n",
    "        dist = float('-inf')\n",
    "        if ((type(cord1) == int and type(cord2) == int) or ((type(cord1) == float and type(cord2) == float))):\n",
    "            dist = math.fabs(cord1 - cord2)\n",
    "        else:\n",
    "            for i, j in zip(cord1, cord2):\n",
    "                temp_dist = math.fabs(i - j)\n",
    "                if (temp_dist > dist):\n",
    "                    dist = temp_dist\n",
    "        return dist\n",
    "\n",
    "    @staticmethod\n",
    "    def manhattan(self, cord1, cord2):\n",
    "        # |x1-y1| + |x2-y2| + |x3-y3| + ...\n",
    "        dist = 0.0\n",
    "        if ((type(cord1) == int and type(cord2) == int) or ((type(cord1) == float and type(cord2) == float))):\n",
    "            dist = math.fabs(cord1 - cord2)\n",
    "        else:\n",
    "            for i, j in zip(cord1, cord2):\n",
    "                dist += math.fabs(i - j)\n",
    "        return dist\n",
    "\n",
    "    @staticmethod\n",
    "    def eucledian(self, cord1, cord2):\n",
    "        dist = 0.0\n",
    "        if ((type(cord1) == int and type(cord2) == int) or ((type(cord1) == float and type(cord2) == float))):\n",
    "            dist = math.pow((cord1 - cord2), 2)\n",
    "        else:\n",
    "            for i, j in zip(cord1, cord2):\n",
    "                dist += math.pow((i - j), 2)\n",
    "        return math.pow(dist, 0.5)\n",
    "\n",
    "    # =========== Distance Calculation Ends ============== #\n",
    "\n",
    "    def __init__(self, dimensions=(8, 5), all_weights=(0.1, 0.2), fileName=\"iris\"):\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dimensions : dimension of the neural network\n",
    "            all_weights : the optimal weights we get from the bio-algoANN models\n",
    "        \"\"\"\n",
    "\n",
    "        self.allPop_Weights = []\n",
    "        self.allPopl_Chromosomes = []\n",
    "        self.allPop_ReceivedOut = []\n",
    "        self.allPop_ErrorVal = []\n",
    "\n",
    "        self.all_weights = all_weights\n",
    "\n",
    "        self.fitness = []\n",
    "\n",
    "        # ================== Input dataset and corresponding output ========================= #\n",
    "\n",
    "        self.fileName = fileName\n",
    "        self.fileName += \".csv\"\n",
    "        data = pd.read_csv(self.fileName)\n",
    "\n",
    "        classes = []\n",
    "        output_values_expected = []\n",
    "        input_values = []\n",
    "\n",
    "        # ~~~~ encoding ~~~~#\n",
    "\n",
    "        # labelencoder = LabelEncoder()\n",
    "        # data[data.columns[-1]] = labelencoder.fit_transform(data[data.columns[-1]])\n",
    "\n",
    "        # one hot encoding - for multi-column\n",
    "        # enc = OneHotEncoder(handle_unknown='ignore')\n",
    "        # combinedData = np.vstack((data[data.columns[-2]], data[data.columns[-1]])).T\n",
    "        # print(combinedData)\n",
    "        # y = enc.fit_transform(combinedData).toarray()\n",
    "        # y = OneHotEncoder().fit_transform(combinedData).toarray()\n",
    "\n",
    "        #\n",
    "        y = LabelBinarizer().fit_transform(data[data.columns[-1]])\n",
    "        # print(y)\n",
    "\n",
    "        # ~~~~ encoding ends~~~~#\n",
    "\n",
    "        for j in range(len(data)):\n",
    "            output_values_expected.append(y[j])\n",
    "\n",
    "        # print(output_values_expected)\n",
    "\n",
    "        input_values = []\n",
    "        for j in range(len(data)):\n",
    "            b = []\n",
    "            for i in range(1, len(data.columns) - 1):\n",
    "                b.append(data[data.columns[i]][j])\n",
    "            input_values.append(b)\n",
    "\n",
    "        self.X = input_values[:]\n",
    "        self.Y = output_values_expected[:]\n",
    "\n",
    "        # input and output\n",
    "        self.X = input_values[:]\n",
    "        self.Y = output_values_expected[:]\n",
    "\n",
    "        self.dimension = dimensions\n",
    "        # print(self.dimension)\n",
    "\n",
    "        # ================ Finding Initial Weights ================ #\n",
    "\n",
    "        self.pop = []  # weights\n",
    "        reshaped_all_weights = []\n",
    "        start = 0\n",
    "        for i in range(len(self.dimension) - 1):\n",
    "            end = start + self.dimension[i + 1] * self.dimension[i]\n",
    "            temp_arr = self.all_weights[start:end]\n",
    "            w = np.reshape(temp_arr[:], (self.dimension[i + 1], self.dimension[i]))\n",
    "            reshaped_all_weights.append(w)\n",
    "            start = end\n",
    "        self.pop.append(reshaped_all_weights)\n",
    "\n",
    "        self.init_pop = self.all_weights\n",
    "\n",
    "    # ================ Initial Weights Part Ends ================ #\n",
    "\n",
    "\n",
    "    def Predict(self, chromo):\n",
    "        # X, Y and pop are used\n",
    "        self.fitness = []\n",
    "        total_error = 0\n",
    "        m_arr = []\n",
    "        k1 = 0\n",
    "        for i in range(len(self.dimension) - 1):\n",
    "            p = self.dimension[i]\n",
    "            q = self.dimension[i + 1]\n",
    "            k2 = k1 + p * q\n",
    "            m_temp = chromo[k1:k2]\n",
    "            m_arr.append(np.reshape(m_temp, (p, q)))\n",
    "            k1 = k2\n",
    "\n",
    "        y_predicted = []\n",
    "        for x, y in zip(self.X, self.Y):\n",
    "\n",
    "            yo = x\n",
    "\n",
    "            for mCount in range(len(m_arr)):\n",
    "                yo = np.dot(yo, m_arr[mCount])\n",
    "                yo = self.sigmoid(yo)\n",
    "            \n",
    "            # converting to sklearn acceptable form\n",
    "            max_yo = max(yo)\n",
    "            for y_vals in range(len(yo)):\n",
    "                if(yo[y_vals] == max_yo):\n",
    "                    yo[y_vals] = 1\n",
    "                else:\n",
    "                    yo[y_vals] = 0\n",
    "            y_predicted.append(yo)\n",
    "        return (y_predicted, self.Y)\n",
    "\n",
    "    def main(self):\n",
    "        Y_PREDICT, Y_ACTUAL = self.Predict(self.init_pop)\n",
    "        Y_PREDICT = np.array(Y_PREDICT)\n",
    "        Y_ACTUAL = np.array(Y_ACTUAL)\n",
    "        \n",
    "        n_classes = 3\n",
    "        \n",
    "        label_binarizer = LabelBinarizer()\n",
    "        label_binarizer.fit(range(n_classes))\n",
    "        Y_PREDICT = label_binarizer.inverse_transform(np.array(Y_PREDICT))\n",
    "        Y_ACTUAL = label_binarizer.inverse_transform(np.array(Y_ACTUAL))\n",
    "        \n",
    "        # find error\n",
    "        \n",
    "        print(\"\\n Actual / Expected\", Y_ACTUAL)\n",
    "        print(\"\\n Predictions\", Y_PREDICT)\n",
    "        print(\"\\n\\nConfusion Matrix\")\n",
    "        print(confusion_matrix(Y_ACTUAL, Y_PREDICT))\n",
    "        \n",
    "        print(\"\\n\\nClassification Report\")\n",
    "        target_names = ['class 0', 'class 1', 'class 2']\n",
    "        print(classification_report(Y_ACTUAL, Y_PREDICT, target_names=target_names))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d36914a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for inputting data :  0.01380610466003418\n",
      "============ Calling FFA to get best weights ===============\n",
      "--------------GENERATION 0-----------\n",
      "--------------GENERATION 1-----------\n",
      "--------------GENERATION 2-----------\n",
      "--------------GENERATION 3-----------\n",
      "--------------GENERATION 4-----------\n",
      "--------------GENERATION 5-----------\n",
      "--------------GENERATION 6-----------\n",
      "--------------GENERATION 7-----------\n",
      "--------------GENERATION 8-----------\n",
      "--------------GENERATION 9-----------\n",
      "--------------GENERATION 10-----------\n",
      "--------------GENERATION 11-----------\n",
      "--------------GENERATION 12-----------\n",
      "--------------GENERATION 13-----------\n",
      "--------------GENERATION 14-----------\n",
      "--------------GENERATION 15-----------\n",
      "--------------GENERATION 16-----------\n",
      "--------------GENERATION 17-----------\n",
      "--------------GENERATION 18-----------\n",
      "--------------GENERATION 19-----------\n",
      "--------------GENERATION 20-----------\n",
      "--------------GENERATION 21-----------\n",
      "--------------GENERATION 22-----------\n",
      "--------------GENERATION 23-----------\n",
      "--------------GENERATION 24-----------\n",
      "--------------GENERATION 25-----------\n",
      "--------------GENERATION 26-----------\n",
      "--------------GENERATION 27-----------\n",
      "--------------GENERATION 28-----------\n",
      "--------------GENERATION 29-----------\n",
      "--------------GENERATION 30-----------\n",
      "--------------GENERATION 31-----------\n",
      "--------------GENERATION 32-----------\n",
      "--------------GENERATION 33-----------\n",
      "--------------GENERATION 34-----------\n",
      "--------------GENERATION 35-----------\n",
      "--------------GENERATION 36-----------\n",
      "--------------GENERATION 37-----------\n",
      "--------------GENERATION 38-----------\n",
      "--------------GENERATION 39-----------\n",
      "--------------GENERATION 40-----------\n",
      "--------------GENERATION 41-----------\n",
      "--------------GENERATION 42-----------\n",
      "--------------GENERATION 43-----------\n",
      "--------------GENERATION 44-----------\n",
      "--------------GENERATION 45-----------\n",
      "--------------GENERATION 46-----------\n",
      "--------------GENERATION 47-----------\n",
      "--------------GENERATION 48-----------\n",
      "--------------GENERATION 49-----------\n",
      "--------------GENERATION 50-----------\n",
      "--------------GENERATION 51-----------\n",
      "--------------GENERATION 52-----------\n",
      "--------------GENERATION 53-----------\n",
      "--------------GENERATION 54-----------\n",
      "--------------GENERATION 55-----------\n",
      "--------------GENERATION 56-----------\n",
      "--------------GENERATION 57-----------\n",
      "--------------GENERATION 58-----------\n",
      "--------------GENERATION 59-----------\n",
      "--------------GENERATION 60-----------\n",
      "--------------GENERATION 61-----------\n",
      "--------------GENERATION 62-----------\n",
      "--------------GENERATION 63-----------\n",
      "--------------GENERATION 64-----------\n",
      "--------------GENERATION 65-----------\n",
      "--------------GENERATION 66-----------\n",
      "--------------GENERATION 67-----------\n",
      "--------------GENERATION 68-----------\n",
      "--------------GENERATION 69-----------\n",
      "--------------GENERATION 70-----------\n",
      "--------------GENERATION 71-----------\n",
      "--------------GENERATION 72-----------\n",
      "--------------GENERATION 73-----------\n",
      "--------------GENERATION 74-----------\n",
      "--------------GENERATION 75-----------\n",
      "--------------GENERATION 76-----------\n",
      "--------------GENERATION 77-----------\n",
      "--------------GENERATION 78-----------\n",
      "--------------GENERATION 79-----------\n",
      "--------------GENERATION 80-----------\n",
      "--------------GENERATION 81-----------\n",
      "--------------GENERATION 82-----------\n",
      "--------------GENERATION 83-----------\n",
      "--------------GENERATION 84-----------\n",
      "--------------GENERATION 85-----------\n",
      "--------------GENERATION 86-----------\n",
      "--------------GENERATION 87-----------\n",
      "--------------GENERATION 88-----------\n",
      "--------------GENERATION 89-----------\n",
      "--------------GENERATION 90-----------\n",
      "--------------GENERATION 91-----------\n",
      "--------------GENERATION 92-----------\n",
      "--------------GENERATION 93-----------\n",
      "--------------GENERATION 94-----------\n",
      "--------------GENERATION 95-----------\n",
      "--------------GENERATION 96-----------\n",
      "--------------GENERATION 97-----------\n",
      "--------------GENERATION 98-----------\n",
      "--------------GENERATION 99-----------\n",
      "Fitness :  -151.78345684953354\n",
      "Time taken :  66.5745780467987\n",
      "\n",
      " Fitness :  -151.78345684953354 \n",
      " Best Weights :  [0, 0, 7, 0, 13, 0, 2, -2, 0, 15, -1, -4, -17, -13, 22, -7, 2, -3, 0, -13, -14, 0, -16, 0, 0, 8, 0, -10, -14, -10, -20, 22, 0, 0, 0, 0, 0, 0, 0, -20, 0, -8, 0, 17, 2, -25, 6, 0, 0, 14, -16, 23, -22, -12, -29, 0, 0, 0, -1, -4, 14, 11, 2, 7, 0, 0, -10, 2, -3, 0, 12, 2, -2, -3, -21, 0, 0, 0, -6, 0, 2, 0, 16, -9, -19, -3, -15, -3, 0, -4, 12, 0, 0, 0, -6, 3, -5, 14, -11, -8, -17, 0, 0, 0, 1, -6, 13, 26, 15, 2, -9, 8, 0, 0, 0, 0, -2, 0, 0, 6, 13, 18, -2, 11, -11, 14, 13, -5, 0, 3, 0, 13, 0, 0, 3, 0, -1, 3, 7, 29, 4, 1, -2, 0, -13, -11, 14, 10, 0, -33, 2, -8, 21, -5, 0, -7, 14, 19, 55, 0, 0, 0, 3, 2, 8, -19, 0, 0, 21, -12, -2, -13, 0, 10, 2, 0, 31, -20, 0, 0, -25, -15, 0, 0, 5, 0, 0, 0, 26, 14, 0, 10, 0, 0, 3, 7, 0, 0, -2, 13, 3, -5, 0, -16, -13, 3, 0, 5, 0, 0, 0, -19, 22, 0, 0, 16, -20, -23, -22, -16, 0, 6, 0, 4, 0, 0, 2, 0, 0, -27, -3, 0, 12, 2, -18, 24, 14, 3, 0, 0, 0, -20, 13, -3, -9, 0, 39, 29, 0, 0, 0, 0, 0, -10, 2, 0, 14, 15, 0, -9, 0, 0, 0, 5, -14, 0, 16, 0, 0, 0, -16, 17, 0, -5, -3, 14, 0, 0, -11, 0, 29, 0, -6, -24, -12, -14, 0, 2, 0, 0, 9, 2, 0, 0, 0, -12, 16, -3, 19, 0, 26, -13, 2, 0, 24, 3, 22, 14, 0, 3, 0, -1, 5, 23, 0, 0, 26, 23, 0, 0, -5, 0, 0, -6, 0, 3, 0, 0, 0, -16, 0, 1, -10, 0, 20, -12, -12, 3, 0, -6, -7, -28, 0, -19, 22, 0, 12, -5, 0, 24, 12, 0, 0, -2, 0, 5, 12, -1, 0, 0, -16, 24, -22, -3, -7, -10, 0, 0, 0, 0, 0, 0, 0, -2, -15, 0, 2, 0, -1, 4, 0, -23, 0, 13, 0, 0, 5, 12, 0, -1, 3, 0, 0, -10, 0, 0, 27, 0, 0, 0, 12, 22, -6, 0, 0, 9, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, -7, 26, 0, 15, -14, 23, -16, 2, -1, 0, 2, 0, 0, 0, -11, 0, 6, 0, 0, -11, 0, 32, 0, -9, 0, 0, 0, -9, 15, 9, 0, 2, -10, 0, 6, 0, 3, 0, 13, 0, 0, -14, 0, -10, 0, 0, 0, 23, 10, 0, 6, 0, 2, 23, 2, -23, 0, -11, 0, 0, 0, 0, 15, -11, 0, 0, 2, -3, 0, 0, -27, 10, 9, 3, 0, 9, -30, 10, 12, 6, 0, 0, 0, 0, 0, 9, 0, -11, 0, 0, 0, -24, 2, -16, -5, 0, 0, -3, 16, 1, 0, 26, 5, -7, 0, -14, 4, 0, 0, -7, -11, 0, -9, 11, 27, 0, 0, 0, -21, 13, 4, 8, 0, -22, 20, 19, 0, 0, 0, 0, 0, 4, 0, -8, -12, -12, 0, 14, 0, 11, -26, 7, 0, 14, 0, 0, 0, 0, -13, 14, 10, 0, 11, 0, 13, -2, 2, -2, -6, 0, 0, 0, 3, 0, -9, 24, -24, 0, -12, 0, 22, 0, 0, 0, 8, 0, 31, -2, -5, 0, -17, -27, 2, -11, -34, -11, 0, 0, 0, 12, 0, 0, -15, 0, 1, 0, -8, 0, 0, 0, -23, 0, 3, 0, 0, 0, 0, 22, 2, 0, 0, 0, 3, 3, -3, 0, -10, 0, -13, -2, 0, -9, 0, 0, 26, 0, 0, 20, 0, 9, 0, 0, -11, 0, 0, 0, 3, 3, 9, -12, -2, 0, 0, 10, -2, -9, 0, 3, 15, 0, 13, 0, 2, 0, 2, 0, -8, 0, 0, 0, 0, 0, -32, 0, 0, 14, 0, 0, -19, -12, 17, 10, 0, 6, 0, 0, 0, 9, 2, 12, 0, 2, 2, 3, -12, 0, 8, 0, -2, 0, 19, 0, -5, 14, 19, 0, 38, -8, 0, 2, -16, -5, -26, 0, 0, 0, 0, 0, -5, -19, 20, 0, 0, 0, 3, 0, 0, -3, 12, 2, -26, -15, 30, 0, 11, 34, -15, -25, 2, 0, 8, 7, 0, 0, 0, 33, 0, 6, -27, 0, 0, 0, 22, 0, 2, 0, 0, 0, -11, 0, -13, 16, 16, 29, 2, -16, 0, 5, 0, 0, 5, 0, 0, -2, -12, -22, 0, 0, 0, 13, 5, 0, -5, 7, -11, 3, 0, 0, -17, 1, 14, -30, 7, -4, 0, 0, 0, -13, 0, 0, 0, -18, 0, 14, 0, 7, -2, 14, 12, -22, -12, 0, 0, -5, 0, 0, -9, 0, -20, 3, -3, -2, 0, 0, 2, -5, -15, 2, 24, -12, -25, 0, 2, 0, -2, 0, -1, 0, -8, 0, 27, 0, 22, 0, 7, -25, 0, 0, 4, -13, 11, 9, 0, 11, 0, 4, 1, 0, 0, -12, 9, -1, -9, 0, 2, 0, -20, 0, 0, 6, 0, 0, -2, 14, 10, 0, 0, -11, -14, 0, 17, 0, 6, 0, 11, 11, 0, 0, -16, -1, 7, 0, 8, 14, 0, -14, 0, -4, 0, 13, 4, 2, 6, 0, -14, 0, 0, -19, 0, 8, -8, 0, -2, 3, -1, 0, -15, 1, 0, 0, -2, 0, 6, -2, 14, -9, -2, 2, 23, 0, -2, -22, 0, 0, -16, 9, 0, 0, -11, 29, -8, 8, 10, 0, 27, 0, -11, 0, -28, 0, 12, 0, -5, 7, 10, 0, 23, 0, -10, -29, 0, -14, 26, 0, 3, 0, 20, 0, 0, 0, -2, 23, 0, -5, 10, 0, -16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, -4, -1, 0, 0, -3, -25, 12, -13, 0, 2, 0, 0, 0, 0, 0, 24, 3, -6, -22, -17, 15, 18, 24, -16, 0, -34, 0, 3, 0, -2, 0, -2, 2, -23, 0, -11, 0, 0, 0, 0, 9, 0, 0, -2, 2, 14, 0, -17, 3, -6, -22, 0, 0, 24, 7, 0, 0, -16, 0, -2, 0, 0, 0, 3, 0, 0, -22, 0, 3, 0, 20, 0, 16, 9, 0, 0, 13, -3, -13, 12, 0, -4, 29, -7, 0, 0, -38, 0, 14, 7, 0, 0, 0, 2, 0, -14, 1, 3, -9, -2, 0, 17, 3, 0, -6, 0, 0, 5, 0, 21, 0, 0, -26, 0, -2, 0, 16, 2, 16, -17, 0, 39, 0, -2, 0, 0, -1, -24, 11, -2, 4, -15, -5, 2, 16, -14, 4, 2, -6, 6, 3, -23, 0, 12, 0, 0, -14, -12, -28, 9, 30, 24, 0, 0, 8, 0, 17, -7, 20, -15, -3, 25, 0, 10, 0, 0, 0, 45, 0, 7, -8, 10, 0, 0, -5, 2, 0, 0, 0, -2, 15, 11, 17, 5, 0, 3, 0, -4, 3, -11, 0, 0, -10, -2, 10, 36, 6, 0, 5, 0, 11, 0, 0, 16, 0, 9, 3, 3, 0, -5, 10, 0, 0, 0, 0, -9, 0, 0, 0, 0, 8, 0, -23, -17, 0, 2, 12, -27, 16, 0, 0, 0, -16, -4, 6, 0, 0, -18, -2, 15, 0, -19, -11, 0, 0, 0, -2, -17, 0, 0, 0, 0, 0, 27, 7, -29, 13, 0, 12, 0, 2, 0, 0, 0, 0, -23, 5, 0, 0, -2, 0, 0, -1, -22, 0, 23, -26, 0, 0, 0, 6, 32, 0, 0, -2, 0, 6, 0, 0, 24, 0, 2, -7, 0, 0, 0, 5, 1, 16, 0, 0, 17, -25, 2, 16, 0, 1, 0, -2, 0, 0, -11, -12, -17, -16, -3, -2, 12, 6, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 19, 0, -16, 0, 0, 0, 0, -2, 2, 0, 0, 16, 0, 10, -10, -5, 1, -42, 13, -5, 13, 9, 0, 8, 24, 2, 0, 0, -19, 0, 0, -34, 2, -12, -12, -4, 25, 0, -39, 0, -7, 0, 0, 0, -24, 1, 25, 15, -6, 15, -23, 0, -2, 0, 17, 3, 10, 0, -2, 0, 0, 3, 0, 44, -13, 0, 12, 0, -26, 0, -7, 0, -1, 0, 0, -26, 0, 0, 0, 16, -36, 0, 0, 0, 9, -19, -15, 0, 13, 0, -3, 0, 10, -7, 0, 20, 10, 0, 1, 2] \n",
      " Dimensions :  [4, 100, 10, 3]\n",
      "Time Taken :  66.58756184577942\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "i = InputData(fileName=\"../ANN/iris\")\n",
    "input_val, output_val = i.main()\n",
    "end_time = time.time()\n",
    "print(\"Time for inputting data : \", end_time - start_time)\n",
    "        \n",
    "print(\"============ Calling FFA to get best weights ===============\")\n",
    "\n",
    "start_time = time.time()\n",
    "a = ffaAnn(initialPopSize=100, m=10, dimensions = [100,10], input_values=input_val, output_values_expected=output_val, iterations = 100)\n",
    "\n",
    "fit, b, weights, dim = a.main()\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Time taken : \", end_time - start_time)\n",
    "\n",
    "print(\"\\n Fitness : \", fit, \"\\n Best Weights : \", weights, \"\\n Dimensions : \", dim)\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "x=b[:]\n",
    "z=[i for i in range(0,100)]\n",
    "plt.plot(z,x)\n",
    "\n",
    "plt.title(\"Firefly Algorithm\")\n",
    "plt.ylabel(\"Fitness\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "end_time = time.time()\n",
    "print(\"Time Taken : \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2830eb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============= MLP Program Begins ============\n",
      "Training\n",
      "\n",
      " Actual / Expected [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2]\n",
      "\n",
      " Predictions [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1\n",
      " 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 1 2\n",
      " 1 2 1 1 2 2 1 2 2]\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[40  0  0]\n",
      " [ 1 37  2]\n",
      " [ 0  7 33]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.98      1.00      0.99        40\n",
      "     class 1       0.84      0.93      0.88        40\n",
      "     class 2       0.94      0.82      0.88        40\n",
      "\n",
      "    accuracy                           0.92       120\n",
      "   macro avg       0.92      0.92      0.92       120\n",
      "weighted avg       0.92      0.92      0.92       120\n",
      "\n",
      "Time taken =  0.011980533599853516\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n============= MLP Program Begins ============\")\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"Training\")\n",
    "m = MultiLayerPerceptron(fileName=\"../ANN/iris_train\", dimensions=dim, all_weights=weights)\n",
    "m.main()\n",
    "end_time = time.time()\n",
    "print(\"Time taken = \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3c970b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n",
      "\n",
      " Actual / Expected [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2]\n",
      "\n",
      " Predictions [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 1 2 2 2 2 2 2 2 2 2 2]\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[10  0  0]\n",
      " [ 0  9  1]\n",
      " [ 0  0 10]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      1.00      1.00        10\n",
      "     class 1       1.00      0.90      0.95        10\n",
      "     class 2       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "Time taken =  0.012987852096557617\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Testing\")\n",
    "m = MultiLayerPerceptron(fileName=\"../ANN/iris_test\", dimensions=dim, all_weights=weights)\n",
    "m.main()\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Time taken = \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245fd1af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
