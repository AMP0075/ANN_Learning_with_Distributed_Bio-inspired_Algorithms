{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb5a447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50dfaafc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn import preprocessing\n",
    "from scipy.special import expit\n",
    "\n",
    "from numpy.random import default_rng\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import time\n",
    "\n",
    "from accgaAnn_thread_V_I import *\n",
    "\n",
    "\n",
    "\n",
    "class MultiLayerPerceptron():\n",
    "    # ================== Activation Functions ================ #\n",
    "\n",
    "    # accepts a vector or list and returns a list after performing corresponding function on all elements\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(vectorSig):\n",
    "        \"\"\"returns 1/(1+exp(-x)), where the output values lies between zero and one\"\"\"\n",
    "        sig = expit(vectorSig)\n",
    "        return sig\n",
    "\n",
    "    @staticmethod\n",
    "    def binaryStep(x):\n",
    "        \"\"\" It returns '0' is the input is less then zero otherwise it returns one \"\"\"\n",
    "        return np.heaviside(x, 1)\n",
    "\n",
    "    @staticmethod\n",
    "    def linear(x):\n",
    "        \"\"\" y = f(x) It returns the input as it is\"\"\"\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def tanh(x):\n",
    "        \"\"\" It returns the value (1-exp(-2x))/(1+exp(-2x)) and the value returned will be lies in between -1 to 1\"\"\"\n",
    "        return np.tanh(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def relu(x):  # Rectified Linear Unit\n",
    "        \"\"\" It returns zero if the input is less than zero otherwise it returns the given input\"\"\"\n",
    "        x1 = []\n",
    "        for i in x:\n",
    "            if i < 0:\n",
    "                x1.append(0)\n",
    "            else:\n",
    "                x1.append(i)\n",
    "\n",
    "        return x1\n",
    "\n",
    "    @staticmethod\n",
    "    def leakyRelu(x):\n",
    "        \"\"\" It returns zero if the input is less than zero otherwise it returns the given input\"\"\"\n",
    "        x1 = []\n",
    "        for i in x:\n",
    "            if i < 0:\n",
    "                x1.append((0.01 * i))\n",
    "            else:\n",
    "                x1.append(i)\n",
    "\n",
    "        return x1\n",
    "\n",
    "    @staticmethod\n",
    "    def parametricRelu(self, a, x):\n",
    "        \"\"\" It returns zero if the input is less than zero otherwise it returns the given input\"\"\"\n",
    "        x1 = []\n",
    "        for i in x:\n",
    "            if i < 0:\n",
    "                x1.append((a * i))\n",
    "            else:\n",
    "                x1.append(i)\n",
    "\n",
    "        return x1\n",
    "\n",
    "    @staticmethod\n",
    "    def softmax(self, x):\n",
    "        \"\"\" Compute softmax values for each sets of scores in x\"\"\"\n",
    "        return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "    # ============ Activation Functions Part Ends ============= #\n",
    "\n",
    "    # ================= Distance Calculation ================== #\n",
    "\n",
    "    @staticmethod\n",
    "    def chebishev(self, cord1, cord2, exponent_h):\n",
    "        dist = 0.0\n",
    "        if ((type(cord1) == int and type(cord2) == int) or ((type(cord1) == float and type(cord2) == float))):\n",
    "            dist = math.pow((cord1 - cord2), exponent_h)\n",
    "        else:\n",
    "            for i, j in zip(cord1, cord2):\n",
    "                dist += math.pow((i - j), exponent_h)\n",
    "        dist = math.pow(dist, (1.0 / exponent_h))\n",
    "        return dist\n",
    "\n",
    "    @staticmethod\n",
    "    def minimum_distance(self, cord1, cord2):\n",
    "        # min(|x1-y1|, |x2-y2|, |x3-y3|, ...)\n",
    "        dist = float('inf')\n",
    "        if ((type(cord1) == int and type(cord2) == int) or ((type(cord1) == float and type(cord2) == float))):\n",
    "            dist = math.fabs(cord1 - cord2)\n",
    "        else:\n",
    "            for i, j in zip(cord1, cord2):\n",
    "                temp_dist = math.fabs(i - j)\n",
    "                if (temp_dist < dist):\n",
    "                    dist = temp_dist\n",
    "        return dist\n",
    "\n",
    "    @staticmethod\n",
    "    def maximum_distance(self, cord1, cord2):\n",
    "        # max(|x1-y1|, |x2-y2|, |x3-y3|, ...)\n",
    "        dist = float('-inf')\n",
    "        if ((type(cord1) == int and type(cord2) == int) or ((type(cord1) == float and type(cord2) == float))):\n",
    "            dist = math.fabs(cord1 - cord2)\n",
    "        else:\n",
    "            for i, j in zip(cord1, cord2):\n",
    "                temp_dist = math.fabs(i - j)\n",
    "                if (temp_dist > dist):\n",
    "                    dist = temp_dist\n",
    "        return dist\n",
    "\n",
    "    @staticmethod\n",
    "    def manhattan(self, cord1, cord2):\n",
    "        # |x1-y1| + |x2-y2| + |x3-y3| + ...\n",
    "        dist = 0.0\n",
    "        if ((type(cord1) == int and type(cord2) == int) or ((type(cord1) == float and type(cord2) == float))):\n",
    "            dist = math.fabs(cord1 - cord2)\n",
    "        else:\n",
    "            for i, j in zip(cord1, cord2):\n",
    "                dist += math.fabs(i - j)\n",
    "        return dist\n",
    "\n",
    "    @staticmethod\n",
    "    def eucledian(self, cord1, cord2):\n",
    "        dist = 0.0\n",
    "        if ((type(cord1) == int and type(cord2) == int) or ((type(cord1) == float and type(cord2) == float))):\n",
    "            dist = math.pow((cord1 - cord2), 2)\n",
    "        else:\n",
    "            for i, j in zip(cord1, cord2):\n",
    "                dist += math.pow((i - j), 2)\n",
    "        return math.pow(dist, 0.5)\n",
    "\n",
    "    # =========== Distance Calculation Ends ============== #\n",
    "\n",
    "    def __init__(self, dimensions=(8, 5), all_weights=(0.1, 0.2), fileName=\"iris\"):\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dimensions : dimension of the neural network\n",
    "            all_weights : the optimal weights we get from the bio-algoANN models\n",
    "        \"\"\"\n",
    "\n",
    "        self.allPop_Weights = []\n",
    "        self.allPopl_Chromosomes = []\n",
    "        self.allPop_ReceivedOut = []\n",
    "        self.allPop_ErrorVal = []\n",
    "\n",
    "        self.all_weights = all_weights\n",
    "\n",
    "        self.fitness = []\n",
    "\n",
    "        # ================== Input dataset and corresponding output ========================= #\n",
    "\n",
    "        self.fileName = fileName\n",
    "        self.fileName += \".csv\"\n",
    "        data = pd.read_csv(self.fileName)\n",
    "\n",
    "        classes = []\n",
    "        output_values_expected = []\n",
    "        input_values = []\n",
    "\n",
    "        # ~~~~ encoding ~~~~#\n",
    "\n",
    "        # labelencoder = LabelEncoder()\n",
    "        # data[data.columns[-1]] = labelencoder.fit_transform(data[data.columns[-1]])\n",
    "\n",
    "        # one hot encoding - for multi-column\n",
    "        # enc = OneHotEncoder(handle_unknown='ignore')\n",
    "        # combinedData = np.vstack((data[data.columns[-2]], data[data.columns[-1]])).T\n",
    "        # print(combinedData)\n",
    "        # y = enc.fit_transform(combinedData).toarray()\n",
    "        # y = OneHotEncoder().fit_transform(combinedData).toarray()\n",
    "\n",
    "        #\n",
    "        y = LabelBinarizer().fit_transform(data[data.columns[-1]])\n",
    "        # print(y)\n",
    "\n",
    "        # ~~~~ encoding ends~~~~#\n",
    "\n",
    "        for j in range(len(data)):\n",
    "            output_values_expected.append(y[j])\n",
    "\n",
    "        # print(output_values_expected)\n",
    "\n",
    "        input_values = []\n",
    "        for j in range(len(data)):\n",
    "            b = []\n",
    "            for i in range(1, len(data.columns) - 1):\n",
    "                b.append(data[data.columns[i]][j])\n",
    "            input_values.append(b)\n",
    "\n",
    "        self.X = input_values[:]\n",
    "        self.Y = output_values_expected[:]\n",
    "\n",
    "        # input and output\n",
    "        self.X = input_values[:]\n",
    "        self.Y = output_values_expected[:]\n",
    "\n",
    "        self.dimension = dimensions\n",
    "        # print(self.dimension)\n",
    "\n",
    "        # ================ Finding Initial Weights ================ #\n",
    "\n",
    "        self.pop = []  # weights\n",
    "        reshaped_all_weights = []\n",
    "        start = 0\n",
    "        for i in range(len(self.dimension) - 1):\n",
    "            end = start + self.dimension[i + 1] * self.dimension[i]\n",
    "            temp_arr = self.all_weights[start:end]\n",
    "            w = np.reshape(temp_arr[:], (self.dimension[i + 1], self.dimension[i]))\n",
    "            reshaped_all_weights.append(w)\n",
    "            start = end\n",
    "        self.pop.append(reshaped_all_weights)\n",
    "\n",
    "        self.init_pop = self.all_weights\n",
    "\n",
    "    # ================ Initial Weights Part Ends ================ #\n",
    "\n",
    "\n",
    "    def Predict(self, chromo):\n",
    "        # X, Y and pop are used\n",
    "        self.fitness = []\n",
    "        total_error = 0\n",
    "        m_arr = []\n",
    "        k1 = 0\n",
    "        for i in range(len(self.dimension) - 1):\n",
    "            p = self.dimension[i]\n",
    "            q = self.dimension[i + 1]\n",
    "            k2 = k1 + p * q\n",
    "            m_temp = chromo[k1:k2]\n",
    "            m_arr.append(np.reshape(m_temp, (p, q)))\n",
    "            k1 = k2\n",
    "\n",
    "        y_predicted = []\n",
    "        for x, y in zip(self.X, self.Y):\n",
    "\n",
    "            yo = x\n",
    "\n",
    "            for mCount in range(len(m_arr)):\n",
    "                yo = np.dot(yo, m_arr[mCount])\n",
    "                yo = self.sigmoid(yo)\n",
    "            \n",
    "            # converting to sklearn acceptable form\n",
    "            max_yo = max(yo)\n",
    "            for y_vals in range(len(yo)):\n",
    "                if(yo[y_vals] == max_yo):\n",
    "                    yo[y_vals] = 1\n",
    "                else:\n",
    "                    yo[y_vals] = 0\n",
    "            y_predicted.append(yo)\n",
    "        return (y_predicted, self.Y)\n",
    "\n",
    "    def main(self):\n",
    "        Y_PREDICT, Y_ACTUAL = self.Predict(self.init_pop)\n",
    "        Y_PREDICT = np.array(Y_PREDICT)\n",
    "        Y_ACTUAL = np.array(Y_ACTUAL)\n",
    "        \n",
    "        n_classes = 3\n",
    "        \n",
    "        label_binarizer = LabelBinarizer()\n",
    "        label_binarizer.fit(range(n_classes))\n",
    "        Y_PREDICT = label_binarizer.inverse_transform(np.array(Y_PREDICT))\n",
    "        Y_ACTUAL = label_binarizer.inverse_transform(np.array(Y_ACTUAL))\n",
    "        \n",
    "        # find error\n",
    "        \n",
    "        #print(\"\\n Actual / Expected\", Y_ACTUAL)\n",
    "        #print(\"\\n Predictions\", Y_PREDICT)\n",
    "        #print(\"\\n\\nConfusion Matrix\")\n",
    "        #print(confusion_matrix(Y_ACTUAL, Y_PREDICT))\n",
    "        \n",
    "        #print(\"\\n\\nClassification Report\")\n",
    "        target_names = ['class 0', 'class 1', 'class 2']\n",
    "        #print(classification_report(Y_ACTUAL, Y_PREDICT, target_names=target_names))\n",
    "        #print(\"\\n\\n\\n\")\n",
    "        return accuracy_score(Y_ACTUAL, Y_PREDICT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d36914a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for inputting data :  0.006981611251831055\n",
      "============ Calling GA to get best weights ===============\n",
      "--------------GENERATION 0-----------\n",
      "--------------GENERATION 1-----------\n",
      "--------------GENERATION 2-----------\n",
      "--------------GENERATION 3-----------\n",
      "--------------GENERATION 4-----------\n",
      "--------------GENERATION 5-----------\n",
      "--------------GENERATION 6-----------\n",
      "--------------GENERATION 7-----------\n",
      "--------------GENERATION 8-----------\n",
      "--------------GENERATION 9-----------\n",
      "--------------GENERATION 10-----------\n",
      "--------------GENERATION 11-----------\n",
      "--------------GENERATION 12-----------\n",
      "--------------GENERATION 13-----------\n",
      "--------------GENERATION 14-----------\n",
      "--------------GENERATION 15-----------\n",
      "--------------GENERATION 16-----------\n",
      "--------------GENERATION 17-----------\n",
      "--------------GENERATION 18-----------\n",
      "--------------GENERATION 19-----------\n",
      "--------------GENERATION 20-----------\n",
      "--------------GENERATION 21-----------\n",
      "--------------GENERATION 22-----------\n",
      "--------------GENERATION 23-----------\n",
      "--------------GENERATION 24-----------\n",
      "--------------GENERATION 25-----------\n",
      "--------------GENERATION 26-----------\n",
      "--------------GENERATION 27-----------\n",
      "--------------GENERATION 28-----------\n",
      "--------------GENERATION 29-----------\n",
      "--------------GENERATION 30-----------\n",
      "--------------GENERATION 31-----------\n",
      "--------------GENERATION 32-----------\n",
      "--------------GENERATION 33-----------\n",
      "--------------GENERATION 34-----------\n",
      "--------------GENERATION 35-----------\n",
      "--------------GENERATION 36-----------\n",
      "--------------GENERATION 37-----------\n",
      "--------------GENERATION 38-----------\n",
      "--------------GENERATION 39-----------\n",
      "--------------GENERATION 40-----------\n",
      "--------------GENERATION 41-----------\n",
      "--------------GENERATION 42-----------\n",
      "--------------GENERATION 43-----------\n",
      "--------------GENERATION 44-----------\n",
      "--------------GENERATION 45-----------\n",
      "--------------GENERATION 46-----------\n",
      "--------------GENERATION 47-----------\n",
      "--------------GENERATION 48-----------\n",
      "--------------GENERATION 49-----------\n",
      "--------------GENERATION 50-----------\n",
      "--------------GENERATION 51-----------\n",
      "--------------GENERATION 52-----------\n",
      "--------------GENERATION 53-----------\n",
      "--------------GENERATION 54-----------\n",
      "--------------GENERATION 55-----------\n",
      "--------------GENERATION 56-----------\n",
      "--------------GENERATION 57-----------\n",
      "--------------GENERATION 58-----------\n",
      "--------------GENERATION 59-----------\n",
      "--------------GENERATION 60-----------\n",
      "--------------GENERATION 61-----------\n",
      "--------------GENERATION 62-----------\n",
      "--------------GENERATION 63-----------\n",
      "--------------GENERATION 64-----------\n",
      "--------------GENERATION 65-----------\n",
      "--------------GENERATION 66-----------\n",
      "--------------GENERATION 67-----------\n",
      "--------------GENERATION 68-----------\n",
      "--------------GENERATION 69-----------\n",
      "--------------GENERATION 70-----------\n",
      "--------------GENERATION 71-----------\n",
      "--------------GENERATION 72-----------\n",
      "--------------GENERATION 73-----------\n",
      "--------------GENERATION 74-----------\n",
      "--------------GENERATION 75-----------\n",
      "--------------GENERATION 76-----------\n",
      "--------------GENERATION 77-----------\n",
      "--------------GENERATION 78-----------\n",
      "--------------GENERATION 79-----------\n",
      "--------------GENERATION 80-----------\n",
      "--------------GENERATION 81-----------\n",
      "--------------GENERATION 82-----------\n",
      "--------------GENERATION 83-----------\n",
      "--------------GENERATION 84-----------\n",
      "--------------GENERATION 85-----------\n",
      "--------------GENERATION 86-----------\n",
      "--------------GENERATION 87-----------\n",
      "--------------GENERATION 88-----------\n",
      "--------------GENERATION 89-----------\n",
      "--------------GENERATION 90-----------\n",
      "--------------GENERATION 91-----------\n",
      "--------------GENERATION 92-----------\n",
      "--------------GENERATION 93-----------\n",
      "--------------GENERATION 94-----------\n",
      "--------------GENERATION 95-----------\n",
      "--------------GENERATION 96-----------\n",
      "--------------GENERATION 97-----------\n",
      "--------------GENERATION 98-----------\n",
      "--------------GENERATION 99-----------\n",
      "Fitness :  70.27816407996448\n",
      "Time taken :  261.57265996932983\n",
      "\n",
      " Fitness :  70.27816407996448 \n",
      " Best Weights :  [-39, 56, -31, -30, 54, -81, 12, 69, 16, -8, 5, 96, 5, 71, 56, -59, 75, -94, -62, 72, 71, -15, -65, 60, 59, -79, -22, 72, -60, -50, 15, 53, -35, 87, 76, -31, -42, 29, 13, -77, -62, -15, -35, -35, 22, -86, -33, -19, -97, -88, 67, 30, -74, 19, 31, 3, 43, -70, 11, 23, -30, 89, 48, 58, 55, 88, -20, -28, 45, 69, -21, -52, 27, -42, -12, -20, -56, -33, -88, 28, -45, 64, 99, -3, -32, 13, -93, 20, 56, -6, 63, -50, 35, 47, 94, 76, -37, -50, -63, 42, -65, 71, 75, -48, 10, -16, 66, -9, 90, 92, 0, 49, -63, -60, -24, -26, -10, -85, -87, -81, 7, -13, 50, -2, 61, -12, -53, -77, -31, -60, 26, -67, -9, 49, -24, -15, -5, -61, -19, 46, -10, -3, 50, -75, -26, -91, -57, -73, -25, 78, 12, -45, -56, 80, -22, -1, -60, -9, 72, -68, -60, -55, -55, -39, 5, -71, -11, 77, 34, 69, -1, -81, -61, -76, 73, 1, 39, -97, -19, 12, 65, -81, 90, 64, 59, 58, 93, 37, -90, -85, -26, 36, -48, -58, 95, 9, -56, -32, -82, -74, -40, 77, 0, -40, 6, 56, -61, -15, -52, -57, -17, -50, -84, 33, -50, -88, 74, -6, -53, -41, 59, 71, -14, 41, -63, -84, -32, -100, 34, -67, 70, 54, 54, -69, -91, 41, 37, -99, 77, -46, -59, -54, 87, 58, 33, 47, -29, 68, -55, 71, 43, 60, 20, 51, -92, 9, 82, 74, 38, -15, 13, -24, 33, -20, -32, 99, 68, 42, -24, 79, -38, -96, 78, 43, 59, 45, -83, -66, 52, 48, -25, 47, 77, 36, -21, -62, 34, -32, -79, 80, 2, 43, 83, 93, 35, 22, 83, -19, 99, 20, -16, 31, -25, -62, -87, -2, 97, -75, 9, -93, 7, -25, 29, 39, -73, 41, 7, 83, 30, 77, 83, -93, 33, -79, 50, 0, -91, 12, -24, 62, 16, 58, -21, 83, 74, 63, -87, 7, 57, 19, -60, -48, 83, 30, -46, -53, -37, 21, -75, 59, -67, 29, -34, 12, 82, 63, -35, 1, -15, -4, 22, -97, 53, -48, 43, -81, -62, 54, 98, 49, 49, -32, 93, 42, -55, 59, -40, 46, 55, 35, -16, 55, -39, 56, -31, -30, 54, -81, 12, 69, 16, -8, 5, 96, 5, 71, 56, -59, 75, -94, -62, 72, 71, -15, -65, 60, 59, -79, -22, 72, -60, -50, 15, 53, -35, 87, 76, -31, -42, 29, 13, -77, -62, -15, -35, -35, 22, -86, -33, -19, -97, -88, 67, 30, -74, 19, 31, 3, 43, -70, 11, 23, -30, 89, 48, 58, 55, 88, -20, -28, 45, 69, -21, -52, 27, -42, -12, -20, -56, -33, -88, 28, -45, 64, 99, -3, -32, 13, -93, 20, 56, -6, 63, -50, 35, 47, 94, 76, -37, -50, -63, 42, -65, 71, 75, -48, 10, -16, 66, -9, 90, 92, 0, 49, -63, -60, -24, -26, -10, -85, -87, -81, 7, -13, 50, -2, 61, -12, -53, -77, -31, -60, 26, -67, -9, 49, -24, -15, -5, -61, -19, 46, -10, -3, 50, -75, -26, -91, -57, -73, -25, 78, 12, -45, -56, 80, -22, -1, -60, -9, 72, -68, -60, -55, -55, -39, 5, -71, -11, 77, 34, 69, -1, -81, -61, -76, 73, 1, 39, -97, -19, -66, 25, 36, -83, -99, -2, 78, -71, 85, -50, -99, 1, -85, 73, -83, -53, -83, -36, -35, -85, 45, -52, -8, 89, -87, -79, 32, -12, 37, 1, 42, -54, -9, 87, 2, 34, -46, -55, 58, 74, 29, -83, 53, -51, -99, 12, -44, 48, -71, 85, -45, -33, 45, 60, -5, -59, 23, 30, 11, 68, -56, -96, -29, 77, -41, 69, 33, -91, 91, -88, -42, 64, -58, 17, -32, 78, 66, -30, 50, 46, -78, -1, -73, 31, 34, 15, 19, -30, 79, -64, 79, -64, 44, -97, 73, -78, 70, -89, -85, -58, 49, 44, -64, -46, -4, -52, -53, -16, 71, 95, 46, 95, -59, 95, -51, 89, 49, 88, 65, -64, 68, 14, 89, -68, -95, 22, -90, 6, 92, -74, 99, -68, 38, -58, -85, -13, -90, -78, 68, 13, -58, 32, 98, -25, 62, 50, -62, -47, -45, -67, -81, -40, 59, -58, -79, -3, 6, 68, 82, -23, -67, -79, 98, 71, -17, 76, -78, 12, -4, -13, 79, -66, -60, 4, 99, -32, 86, 0, -15, 79, 65, -78, -57, 25, 1, -18, -73, 79, -33, 8, 34, -58, -13, 49, 28, 35, 10, -92, 58, 0, 5, 60, 76, 81, 13, -41, 96, 40, -27, -74, -7, 39, -35, -93, 94, 8, 29, -76, 55, -96, -94, -33, -57, 49, -81, -37, -83, 89, 80, -90, -35, -55, 80, 96, 66, -7, -51, 23, -5, -45, -39, -18, -23, -61, -45, -28, -50, -45, 58, 28, 6, -85, 77, 40, -1, 97, 89, 41, 31, 62, -10, 9, 17, -92, -9, -18, 48, -17, -82, -50, -96, -50, 85, -19, 12, 83, 81, 9, -83, 82, 53, -46, 1, -52, 50, -88, 74, -51, 60, 77, 38, -73, -84, 26, -2, 20, -15, -52, 17, 25, -95, 33, 75, 0, -3, -25, 70, 15, 65, 43, -56, -54, -98, -98, 86, 6, 9, 0, -40, 65, 36, 99, 32, 42, -36, -59, 74, -67, 79, -92, 86, -6, -41, -73, 60, -26, 83, 58, -51, -39, -10, 86, 30, 79, 88, -94, 5, -69, 96, -71, -1, 29, 27, 49, -68, 78, -86, -3, -38, -60, 87, -4, 56, 84, -65, 87, 65, 67, -56, 61, -95, -90, -65, 88, -46, 14, 86, 58, 89, -46, 98, 66, -62, -20, -23, 80, -76, 45, 12, -20, -56, 95, 65, 91, 46, 61, 19, -28, 22, 59, 41, -14, 78, 79, -2, -71, 43, -44, -45, 72, 13, -16, 13, -2, -39, -49, -90, -58, -11, 94, 6, -41, -55, 69, -3, 20, -73, 36, -42, 70, 55, 81, -10, 97, -34, -72, 42, -21, 51, 11, 83, 45, 85, -88, 59, 22, -29, -98, -49, -26, -73, 70, -68, -27, 74, 70, 25, -66, -44, 21, 53, -75, -82, 28, 71, -65, -26, 1, -23, 81, -11, -74, -44, 75, 77, -67, 10, 65, 92, -39, 65, -95, 39, -48, -47, -95, 79, 13, -5, 77, 79, 91, -35, 27, -28, -97, 6, -58, -22, 91, 87, -56, -7, -47, -98, -74, -41, 60, -25, -4, 49, 5, 52, 32, 83, -11, 14, 89, -71, -87, -63, 16, 20, -94, 37, -72, 1, 69, 10, 13, -70, -25, -84, 75, -62, 68, -6, -77, 89, -18, -10, 99, 91, 37, 77, 53, -20, 58, 43, 95, -92, -67, -45, -62, -93, -1, 53, -55, -92, 95, -65, 43, -65, 24, -97, -66, 33, 93, 25, -38, 2, 55, 65, 82, 66, 16, -44, 63, 84, -85, -54, -75, -3, 42, 67, -61, -25, -95, -12, -6, 35, 44, -26, 21, -84, -11, 58, -38, 79, 93, -22, 8, -98, 51, -74, -16, -96, 73, 93, -64, -2, 19, -88, 44, 14, 19, 38, 77, -86, -21, -3, 50, 51, 70, -58, -54, 37, -82, -32, -83, 70, 80, 9, 13, -97, 71, -13, 70, 47, -44, 41, 23, -14, 20, 78, 51, 3, -8, 80, 65, 14, -11, 5, -65, 11, 68, -83, 76, 41, 28, 22, -59, -80, -63, -47, -72, 2, -52, 29, -13, -27, 95, -80, 1, -49, -90, -55, 93, 95, -11, 66, -94, 71, -78, -6, 54, 17, 12, -92, 52, 22, 30, -89, -72, -97, 1, 86, 25, 64, 72, 97, -16, 93, -82, -91, 35, 7, -26, 78, -65, -85, -99, -77, 20, 83, 24, 67, -91, 21, -54, -56, 41, 33, 66, 65, 36, 89, 29, -26, -98, 46, 69, -36, -63, -63, -91, 69, -78, -11, -82, -59, -93, 64, -24, -52, 31, -52, 38, 95, 86, -2, 14, -10, -98, 95, -17, 51, 91, -79, -60, 40, 58, -93, 13, 83, 36, 96, 51, -60, 65, -81, -10, 14, 3, 65, -14, -53, -83, 8, 89, 22, -93, 71, -25, 68, -69, -100, -81, 88, 3, -47, -90, 77, 80, -12, -55, -72, 77, -86, -17, 43, -52, 30, -73, -74, 67, -38, -100, 38, -88, -46, -29, -55, 9, 31, -85, -2, 73, -46, 22, 22, -39, -25, -89, 70, -70, 67, 96, 36, -98, -65, 49, -30, -36, -8, 98, -70, 80, 25, 40, -70, 20, -98, 12, -23, 13, -65, -46, 85, 45, 51, -18, -20, 74, -60, -91, -63, 60, -67, 91, -87, 66, 52, -13, -77, -36, 84, 54, -65] \n",
      " Dimensions :  [4, 100, 10, 3]\n",
      "Time Taken :  261.60058522224426\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAaXElEQVR4nO3de7RdZX3u8e+z1oJAgJKQ7CI3SRAOwkklSqAgYKmgRcoRpD1cvKHliG21oPaoaHuKZdQO6EGpenoYI4gQLFIE5FKGpXhSFUUBd9IQgqBcA4QQNshNIpDs/M4f891hsdmXlax37r3nXM9njDX2WnPNueY7M5Mnv/3Od71TEYGZmfWOxmQ3wMzMJpaD38ysxzj4zcx6jIPfzKzHOPjNzHqMg9/MrMc4+G1KkvRrSXts5raSdLGkpyXdLulwSY/mbmPa1yWS/q6kz36fpJvGeL+047J6c/DbpJL0kKTfpKAfeuwcEdtGxAOb+bGHAu8Ado2IAzO18wfpP5JpOT6vExFxWUS8s60NIWnPidq/1ZeD36aC/5aCfujx2FgrS2qO83m7Aw9FxAs5GidpDnAYEMC7c3xmB/tsTcR+rDc5+G1Kaq9uU3fKBZK+K+kF4Pcl7SzpakkDkh6UdHpa91Tg68DB6beHvx32uZ+WdPWwZV+V9JUxmvNB4FbgEuCUcdr9GUmrJT0m6X8MO47tJV2a2rxS0l9LaqT3PiTpFknnS3oK+EJa9uP0/s1pF3ek4zqxbZ9/KemJtN8Pty2/RNL/lfRvaZtbJL1O0j+m317ukfTmsY7H6snBb1XxXuCLwHbAT4B/Be4AdgGOAD4h6Q8i4iLgT4Gfpt8ezhr2Of8MHCVpBmysrE8CLh1j3x8ELkuPP5C040grSToK+BRwJLAncPiwVb4GbA/sAfxe+twPt73/u8ADwI7pWDeKiLelp/ul47oivX5d+sxdgFOBf5I0s23TE4C/BmYDLwE/BZam11cBXx7juK2mHPw2FVwr6Zn0uHaUda6LiFsiYgPwO0BfRJwdES+nawEXUgT4mCJiNXAz8N/ToqOAJyNiyUjrSzqUouvo22md+yn+ExrJCcDFEXFXRKwFvtD2Oc3Uvs9FxPMR8RDwJeADbds/FhFfi4j1EfGb8Y4lWQecHRHrIuK7wK+BvdvevyYilkTEi8A1wIsRcWlEDAJXAK74e5CD36aC4yJiRnocN8o6j7Q93x3Yue0/i2eAz1NUyp1YBLw/PX8/8M0x1j0FuCkinkyvv8Xo3T07D2tn+/PZwBbAyrZlKykq9ZHW79RTEbG+7fVaYNu212vanv9mhNft61qP8AUkq4r2aWQfAR6MiL0287OuBS6QNA84BvjMSCtJ2pqiim9KejwtngbMkLRfRNwxbJPVwK5tr3dre/4kRXW+O/DztOz1wKq2dTxVrk0IV/xWRbcDz0v6rKStJTUlzZN0QCcbp26Pqyiq99sj4uFRVj0OGAT2Beanxz7Ajyj654f7NvBhSftImg78r7Z9Dqb3vyhpO0m7U1wP+OdO2pysobg+YNYVB79VTgrRYyiC+EGKavrrFBc5O7WI4lrBeN08F0fEwxHx+NAD+D/A+4YPuYyIfwO+CnwfuI9iJBAUF1UB/gJ4geIC7o8p/uP5xia0+QvAotS9dcImbGf2KvKNWKwXSXo9cA/wuoh4rqR97AOsAKYN64c3m1Su+K3npLHznwL+JXfoS3qPpGlpSOW5wL869G2qcfBbT5G0DfAcxZQOw8f45/BR4AmKYZ+DwJ+VsA+zrrirx8ysx7jiNzPrMZUYxz979uyYM2fOZDfDzKxSlixZ8mRE9A1fXongnzNnDv39/ZPdDDOzSpG0cqTl7uoxM+sxDn4zsx7j4Dcz6zEOfjOzHuPgNzPrMQ5+M7Me4+A3M+sxlRjHv7kW372GOx55ZrKbYda1bbdq8aG3zmXLlms1616tg/+Hvxzgm7eO+P0Fs8oYmk5r/91nsv/uO0xuY6wWah38Zx87j7OPnTfZzTDryk/vf4qTL7yVl9d7QkXLw783mk1xraYAGNzg4Lc8HPxmU1xDRfCv37BhkltideHgN5viWg1X/JaXg99sims2hip+B7/l4eA3m+KG+vg3OPgtEwe/2RTXcsVvmTn4zaa4ZqP4Z+o+fsvFwW82xbnit9wc/GZTXHPjqB4P57Q8HPxmU5wrfsvNwW82xTU9jt8yc/CbTXGtdHF3/aCD3/Jw8JtNcU3P1WOZOfjNpjj38VtupQa/pDMkrZB0l6RPpGVfkLRK0rL0OLrMNphVnUf1WG6lzccvaR7wEeBA4GXgRkk3pLfPj4jzytq3WZ005Yrf8irzRiz7ALdFxFoAST8Eji9xf2a11GiIhtzHb/mU2dWzAjhM0ixJ04Gjgd3Sex+XtFzSNyTNLLENZrXQajRc8Vs2pQV/RNwNnAvcBNwILAMGgQuANwDzgdXAl0baXtJpkvol9Q8MDJTVTLNKaDbkit+yKfXibkRcFBH7R8TbgKeBX0bEmogYjIgNwIUU1wBG2nZhRCyIiAV9fX1lNtNsyms15HH8lk3Zo3p+O/18PUX//rck7dS2ynsouoTMbAzNpjyqx7Ip8+IuwNWSZgHrgI9FxDOSviZpPhDAQ8BHS26DWeW1GnIfv2VTavBHxGEjLPtAmfs0qyP38VtO/uauWQV4VI/l5OA3qwBX/JaTg9+sAtzHbzk5+M0qoKj4ParH8nDwm1VA0+P4LSMHv1kFtJru47d8HPxmFdD0qB7LyMFvVgEtj+qxjBz8ZhXQbIj1vrhrmTj4zSrAFb/l5OA3q4Cmx/FbRg5+swpwxW85OfjNKqDZaHgcv2Xj4DerAFf8lpOD36wCmk2P6rF8HPxmFeCK33Jy8JtVgEf1WE4OfrMKcMVvOTn4zSrAc/VYTg5+swpwxW85OfjNKqCYj9+jeiwPB79ZBbjit5wc/GYVUIzjd/BbHg5+swpwxW85OfjNKmBoVE+Ew9+65+A3q4BWQwC46LccHPxmFdBMwe/5eiwHB79ZBQxV/O7ntxxKDX5JZ0haIekuSZ9Iy3aQ9D1J96afM8tsg1kdvFLxO/ite6UFv6R5wEeAA4H9gGMk7QmcCSyOiL2Axem1mY1hY8Xvm7FYBmVW/PsAt0XE2ohYD/wQOB44FliU1lkEHFdiG8xqodks/qm64rccygz+FcBhkmZJmg4cDewG7BgRq9M6jwM7jrSxpNMk9UvqHxgYKLGZZlOf+/gtp9KCPyLuBs4FbgJuBJYBg8PWCWDEv8kRsTAiFkTEgr6+vrKaaVYJHtVjOZV6cTciLoqI/SPibcDTwC+BNZJ2Akg/nyizDWZ14Irfcip7VM9vp5+vp+jf/xZwPXBKWuUU4Loy22BWBx7VYzm1Sv78qyXNAtYBH4uIZySdA3xb0qnASuCEkttgVnmtRlGjueK3HEoN/og4bIRlTwFHlLlfs7rZWPF7OKdl4G/umlWA+/gtJwe/WQU0mx7VY/k4+M0qwBW/5eTgN6sAj+qxnBz8ZhXgUT2Wk4PfrAJc8VtODn6zCnilj98Xd617Dn6zCvA4fsvJwW9WAa2mR/VYPg5+swpouY/fMnLwm1VA06N6LCMHv1kFuOK3nBz8ZhXQ8Kgey8jBb1YBrvgtJwe/WQU0PVePZeTgN6uAlsfxW0YOfrMKGKr4N4SD37rn4DergKFJ2tzHbzk4+M0qwH38lpOD36wC3MdvOTn4zSqg0RCSx/FbHg5+s4poNeQ+fstik4Nf0kxJbyqjMWY2umZD7uO3LDoKfkk/kPRbknYAlgIXSvpyuU0zs3atRsMVv2XRacW/fUQ8BxwPXBoRvwscWV6zzGw4V/yWS6fB35K0E3ACcEOJ7TGzURR9/L64a93rNPjPBv4duC8ifiZpD+De8pplZsO54rdcOgr+iLgyIt4UEX+eXj8QEX803naSPinpLkkrJF0uaStJl0h6UNKy9Jjf5TGY9YRWQx7Hb1l0enH3H9LF3S0kLZY0IOn942yzC3A6sCAi5gFN4KT09qcjYn56LOvmAMx6RbPpit/y6LSr553p4u4xwEPAnsCnO9iuBWwtqQVMBx7bnEaamUf1WD4dX9xNP/8QuDIinh1vg4hYBZwHPAysBp6NiJvS21+UtFzS+ZKmjbS9pNMk9UvqHxgY6LCZZvXlPn7LpdPgv0HSPcD+wGJJfcCLY20gaSZwLDAX2BnYJnUPfQ54I3AAsAPw2ZG2j4iFEbEgIhb09fV12Eyz+vKoHsul04u7ZwJvpeivXwespQj1sRwJPBgRA2mb7wBvjYjVUXgJuBg4cPObb9Y7XPFbLp1e3J0O/DlwQVq0M7BgnM0eBg6SNF2SgCOAu9P3AUjLjgNWbEa7zXqO5+qxXDrt6rkYeJmi6gdYBfzdWBtExG3AVRRTPNyZ9rUQuEzSnWnZ7PE+x8wKrvgtl9b4qwDwhog4UdLJABGxNlXsY4qIs4Czhi1++ya20cxIo3o8jt8y6LTif1nS1kAASHoD8FJprTKz13DFb7l0WvGfBdwI7CbpMuAQ4ENlNcrMXqvVFC+tH5zsZlgNdBT8EfE9SUuBgwABZ0TEk6W2zMxexRW/5dJpxQ+wFfB02mZfSUTEzeU0y8yG86gey6Wj4Jd0LnAicBcw9A2SABz8ZhPEFb/l0mnFfxywd/rSlZlNAs/VY7l0OqrnAWCLMhtiZmNzxW+5dFrxrwWWSVpM2zDOiDi9lFaZ2Wt4rh7LpdPgvz492rn0MJtAzYYY9Be4LINOg39GRHylfYGkM0poj5mNotX0qB7Lo9M+/lNGWPahjO0ws3G4j99yGbPiT3PzvBeYK6m9q2c74FdlNszMXs2jeiyX8bp6fkJx96zZwJfalj8PLC+rUWb2Wq74LZcxgz8iVgIrgYMnpjlmNhqP6rFcxuvq+XFEHCrpeV49ikdARMRvldo6M9vIFb/lMl5Xz/sAImK7CWiLmY3Bc/VYLuON6rlm6Imkq0tui5mNodloEAEbHP7WpfGCv/0uW3uU2RAzG1urWfxzdNVv3Rov+GOU52Y2wZqNIvjdz2/dGq+Pfz9Jz1FU/lun5+CLu2YTrtUYqvg3AM3JbYxV2njDOf23y2yKcMVvuXQ6ZYOZTbJXKn4Hv3XHwW9WEc1G8c/VFb91y8FvVhGu+C0XB79ZRWzs4/ec/NYlB79ZRbwyjt/z9Vh3HPxmFeFRPZZLqcEv6ZOS7pK0QtLlkraSNFfSbZLuk3SFpC3LbINZXbiP33IpLfgl7QKcDiyIiHkU3zg5CTgXOD8i9gSeBk4tqw1mdeJRPZZL2V09LYpv/LaA6RQ3dXk7cFV6fxFwXMltMKsFV/yWS2nBHxGrgPOAhykC/1lgCfBMRKxPqz0K7DLS9pJOk9QvqX9gYKCsZppVxit9/L64a90ps6tnJnAsMBfYGdgGOKrT7SNiYUQsiIgFfX19JbXSrDo2VvwezmldKrOr50jgwYgYiIh1wHeAQ4AZqesHYFdgVYltMKsNj+qxXMoM/oeBgyRNlyTgCODnwPeBP07rnAJcV2IbzGrD8/FbLmX28d9GcRF3KXBn2tdC4LPApyTdB8wCLiqrDWZ14lE9lst48/F3JSLOAs4atvgB4MAy92tWRx7VY7n4m7tmFeFRPZaLg9+sIlzxWy4OfrOK8Kgey8XBb1YRrXRx1+P4rVsOfrOKaDZd8VseDn6zinAfv+Xi4DerCI/qsVwc/GYV4YrfcnHwm1WER/VYLg5+s4rYOKrHwW9dcvCbVYQrfsvFwW9WEZ6P33Jx8JtVRMOjeiwTB79ZhbQach+/dc3Bb1YhzYbcx29dc/CbVYgrfsvBwW9WIa74LQcHv1mFtJoNB791zcFvViFNd/VYBg5+swppNeThnNY1B79Zhbjitxwc/GYV0vLFXcvAwW9WIa74LQcHv1mFtBoNBj1Xj3XJwW9WIa74LQcHv1mFtJoe1WPdc/CbVYgrfsuhVdYHS9obuKJt0R7A3wAzgI8AA2n55yPiu2W1w6xOPKrHcigt+CPiF8B8AElNYBVwDfBh4PyIOK+sfZvVlSt+y2GiunqOAO6PiJUTtD+zWmo1PFePdW+igv8k4PK21x+XtFzSNyTNHGkDSadJ6pfUPzAwMNIqZj3HFb/lUHrwS9oSeDdwZVp0AfAGim6g1cCXRtouIhZGxIKIWNDX11d2M80qwXP1WA4TUfG/C1gaEWsAImJNRAxGxAbgQuDACWiDWS00G/LN1q1rExH8J9PWzSNpp7b33gOsmIA2mNVCMY7fwW/dKW1UD4CkbYB3AB9tW/wPkuYDATw07D0zG0PTF3ctg1KDPyJeAGYNW/aBMvdpVme+567l4G/umlWI77lrOTj4zSqkqPg9qse64+A3qxBX/JaDg9+sQtzHbzk4+M0qpOkbsVgGDn6zCmk1XfFb9xz8ZhXiPn7LwcFvViEe1WM5OPjNKqTZEBsCNrjqty44+M0qpNUQAIPh4LfN5+A3q5Bmo/gn635+64aD36xChip+j+yxbjj4zSqkOdTV47H81gUHv1mFtJpDFb9H9tjmc/CbVcjGit9dPdYFB79ZhbiP33Jw8JtViEf1WA4OfrMKccVvOTj4zSrklT5+X9y1zefgN6sQV/yWg4PfrEKGKv71HsdvXXDwm1XI0Dh+X9y1bjj4zSpkaFSPu3qsGw5+swpp+QtcloGD36xCNvbxe1SPdcHBb1YhrvgtBwe/WYU0PZzTMmiV9cGS9gauaFu0B/A3wKVp+RzgIeCEiHi6rHaY1UkrXdz9q+/cyTbTSvvna1PI3x//OxwwZ4esn1na35yI+AUwH0BSE1gFXAOcCSyOiHMknZlef7asdpjVyV47bstJB+zGcy+um+ym2ATZeotm9s+cqJLhCOD+iFgp6Vjg8LR8EfADHPxmHdlqiybn/NGbJrsZVnET1cd/EnB5er5jRKxOzx8HdhxpA0mnSeqX1D8wMDARbTQz6wmlB7+kLYF3A1cOfy8iAhjxKlVELIyIBRGxoK+vr+RWmpn1jomo+N8FLI2INen1Gkk7AaSfT0xAG8zMLJmI4D+ZV7p5AK4HTknPTwGum4A2mJlZUmrwS9oGeAfwnbbF5wDvkHQvcGR6bWZmE6TUUT0R8QIwa9iypyhG+ZiZ2STwN3fNzHqMg9/MrMeoGFE5tUkaAFZu5uazgSczNqcqevG4e/GYoTePuxePGTb9uHePiNeMh69E8HdDUn9ELJjsdky0XjzuXjxm6M3j7sVjhnzH7a4eM7Me4+A3M+sxvRD8Cye7AZOkF4+7F48ZevO4e/GYIdNx176P38zMXq0XKn4zM2vj4Dcz6zG1Dn5JR0n6haT70t2+akfSbpK+L+nnku6SdEZavoOk70m6N/2cOdltzU1SU9J/SrohvZ4r6bZ0vq9IU4LXiqQZkq6SdI+kuyUdXPdzLemT6e/2CkmXS9qqjuda0jckPSFpRduyEc+tCl9Nx79c0ls2ZV+1Df50u8d/opgWel/gZEn7Tm6rSrEe+MuI2Bc4CPhYOs6hW1zuBSxOr+vmDODuttfnAudHxJ7A08Cpk9Kqcn0FuDEi3gjsR3H8tT3XknYBTgcWRMQ8oElxY6c6nutLgKOGLRvt3L4L2Cs9TgMu2JQd1Tb4gQOB+yLigYh4GfgX4NhJblN2EbE6Ipam589TBMEuFMe6KK22CDhuUhpYEkm7An8IfD29FvB24Kq0Sh2PeXvgbcBFABHxckQ8Q83PNcVkkltLagHTgdXU8FxHxM3Ar4YtHu3cHgtcGoVbgRlD9znpRJ2DfxfgkbbXj6ZltSVpDvBm4DY6vMVlhf0j8BlgQ3o9C3gmItan13U833OBAeDi1MX19TT1eW3PdUSsAs4DHqYI/GeBJdT/XA8Z7dx2lW91Dv6eImlb4GrgExHxXPt7Y93isookHQM8ERFLJrstE6wFvAW4ICLeDLzAsG6dGp7rmRTV7VxgZ2AbXtsd0hNynts6B/8qYLe217umZbUjaQuK0L8sIoZuelPnW1weArxb0kMUXXhvp+j7npG6A6Ce5/tR4NGIuC29voriP4I6n+sjgQcjYiAi1lHc1OkQ6n+uh4x2brvKtzoH/8+AvdLV/y0pLghdP8ltyi71bV8E3B0RX257q7a3uIyIz0XErhExh+K8/kdEvA/4PvDHabVaHTNARDwOPCJp77ToCODn1PhcU3TxHCRpevq7PnTMtT7XbUY7t9cDH0yjew4Cnm3rEhpfRNT2ARwN/BK4H/iryW5PScd4KMWvf8uBZelxNEWf92LgXuD/ATtMdltLOv7DgRvS8z2A24H7gCuBaZPdvhKOdz7Qn873tcDMup9r4G+Be4AVwDeBaXU81xT3Jl8NrKP47e7U0c4tIIpRi/cDd1KMeup4X56ywcysx9S5q8fMzEbg4Dcz6zEOfjOzHuPgNzPrMQ5+M7Me4+C3niDp1+nnHEnvzfzZnx/2+ic5P98sNwe/9Zo5wCYFf9s3REfzquCPiLduYpvMJpSD33rNOcBhkpaled6bkv63pJ+lec0/CiDpcEk/knQ9xTdFkXStpCVpbvjT0rJzKGaOXCbpsrRs6LcLpc9eIelOSSe2ffYP2ubVvyx9KxVJ56i4t8JySedN+J+O9YTxKhmzujkT+J8RcQxACvBnI+IASdOAWyTdlNZ9CzAvIh5Mr/8kIn4laWvgZ5KujogzJX08IuaPsK/jKb5pux8wO21zc3rvzcB/BR4DbgEOkXQ38B7gjRERkmbkPXSzgit+63XvpJjzZBnFdNazKG5uAXB7W+gDnC7pDuBWigmy9mJshwKXR8RgRKwBfggc0PbZj0bEBoppNuZQTDn8InCRpOOBtV0em9mIHPzW6wT8RUTMT4+5ETFU8b+wcSXpcIqZIg+OiP2A/wS26mK/L7U9HwRaUcwvfyDFrJvHADd28flmo3LwW695Htiu7fW/A3+WprZG0n9JNzcZbnvg6YhYK+mNFLe5HLJuaPthfgScmK4j9FHcPev20RqW7qmwfUR8F/gkRReRWXbu47desxwYTF02l1DM4z8HWJousA4w8m38bgT+NPXD/4Kiu2fIQmC5pKVRTA895BrgYOAOihlUPxMRj6f/OEayHXCdpK0ofhP51GYdodk4PDunmVmPcVePmVmPcfCbmfUYB7+ZWY9x8JuZ9RgHv5lZj3Hwm5n1GAe/mVmP+f+U63+NKjrydgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "i = InputData(fileName=\"../ANN/iris\")\n",
    "input_val, output_val = i.main()\n",
    "end_time = time.time()\n",
    "print(\"Time for inputting data : \", end_time - start_time)\n",
    "        \n",
    "        \n",
    "print(\"============ Calling GA to get best weights ===============\")\n",
    "\n",
    "n_iterations = 100\n",
    "e_rate = 0.1\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "a = gaAnn(initialPopSize=100, m = 10, dimensions = [100,10], bestCount = 20, input_values=input_val , output_values_expected=output_val, iterations = n_iterations, elicitation_rate = e_rate)\n",
    "\n",
    "fit, b, weights, dim, all_gen_best_weight = a.main()\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Time taken : \", end_time - start_time)\n",
    "\n",
    "print(\"\\n Fitness : \", fit, \"\\n Best Weights : \", weights, \"\\n Dimensions : \", dim)\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "x=b[:]\n",
    "z=[i for i in range(0,100)]\n",
    "plt.plot(z,x)\n",
    "\n",
    "plt.title(\"Firefly Algorithm\")\n",
    "plt.ylabel(\"Fitness\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "end_time = time.time()\n",
    "print(\"Time Taken : \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2830eb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============= MLP Program Begins ============\n",
      "Training\n",
      "Time taken =  0.007976055145263672\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n============= MLP Program Begins ============\")\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"Training\")\n",
    "m = MultiLayerPerceptron(fileName=\"../ANN/iris_train\", dimensions=dim, all_weights=weights)\n",
    "m.main()\n",
    "end_time = time.time()\n",
    "print(\"Time taken = \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3c970b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n",
      "Time taken =  0.00500178337097168\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Testing\")\n",
    "m = MultiLayerPerceptron(fileName=\"../ANN/iris_test\", dimensions=dim, all_weights=weights)\n",
    "m.main()\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Time taken = \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "245fd1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.725\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n",
      "0.8083333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Iterations')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_accuracy = []\n",
    "for weights in all_gen_best_weight:\n",
    "    m = MultiLayerPerceptron(fileName=\"../ANN/iris_train\", dimensions=[4,100,10,3], all_weights=weights)\n",
    "    accuracy_val = m.main()\n",
    "    print(accuracy_val)\n",
    "    all_accuracy.append(accuracy_val)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "x=all_accuracy[:]\n",
    "z=[i for i in range(len(x))]\n",
    "plt.plot(z,x)\n",
    "\n",
    "plt.title(\"Genetic Algorithm\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e9b9c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b71d2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
