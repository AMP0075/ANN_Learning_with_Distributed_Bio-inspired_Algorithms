{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e62cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fedefee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn import preprocessing\n",
    "from scipy.special import expit\n",
    "\n",
    "from numpy.random import default_rng\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import time\n",
    "\n",
    "from accpsoAnn_thread_V_I import *\n",
    "\n",
    "\n",
    "\n",
    "class MultiLayerPerceptron():\n",
    "    # ================== Activation Functions ================ #\n",
    "\n",
    "    # accepts a vector or list and returns a list after performing corresponding function on all elements\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(vectorSig):\n",
    "        \"\"\"returns 1/(1+exp(-x)), where the output values lies between zero and one\"\"\"\n",
    "        sig = expit(vectorSig)\n",
    "        return sig\n",
    "\n",
    "    @staticmethod\n",
    "    def binaryStep(x):\n",
    "        \"\"\" It returns '0' is the input is less then zero otherwise it returns one \"\"\"\n",
    "        return np.heaviside(x, 1)\n",
    "\n",
    "    @staticmethod\n",
    "    def linear(x):\n",
    "        \"\"\" y = f(x) It returns the input as it is\"\"\"\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def tanh(x):\n",
    "        \"\"\" It returns the value (1-exp(-2x))/(1+exp(-2x)) and the value returned will be lies in between -1 to 1\"\"\"\n",
    "        return np.tanh(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def relu(x):  # Rectified Linear Unit\n",
    "        \"\"\" It returns zero if the input is less than zero otherwise it returns the given input\"\"\"\n",
    "        x1 = []\n",
    "        for i in x:\n",
    "            if i < 0:\n",
    "                x1.append(0)\n",
    "            else:\n",
    "                x1.append(i)\n",
    "\n",
    "        return x1\n",
    "\n",
    "    @staticmethod\n",
    "    def leakyRelu(x):\n",
    "        \"\"\" It returns zero if the input is less than zero otherwise it returns the given input\"\"\"\n",
    "        x1 = []\n",
    "        for i in x:\n",
    "            if i < 0:\n",
    "                x1.append((0.01 * i))\n",
    "            else:\n",
    "                x1.append(i)\n",
    "\n",
    "        return x1\n",
    "\n",
    "    @staticmethod\n",
    "    def parametricRelu(self, a, x):\n",
    "        \"\"\" It returns zero if the input is less than zero otherwise it returns the given input\"\"\"\n",
    "        x1 = []\n",
    "        for i in x:\n",
    "            if i < 0:\n",
    "                x1.append((a * i))\n",
    "            else:\n",
    "                x1.append(i)\n",
    "\n",
    "        return x1\n",
    "\n",
    "    @staticmethod\n",
    "    def softmax(self, x):\n",
    "        \"\"\" Compute softmax values for each sets of scores in x\"\"\"\n",
    "        return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "    # ============ Activation Functions Part Ends ============= #\n",
    "\n",
    "    # ================= Distance Calculation ================== #\n",
    "\n",
    "    @staticmethod\n",
    "    def chebishev(self, cord1, cord2, exponent_h):\n",
    "        dist = 0.0\n",
    "        if ((type(cord1) == int and type(cord2) == int) or ((type(cord1) == float and type(cord2) == float))):\n",
    "            dist = math.pow((cord1 - cord2), exponent_h)\n",
    "        else:\n",
    "            for i, j in zip(cord1, cord2):\n",
    "                dist += math.pow((i - j), exponent_h)\n",
    "        dist = math.pow(dist, (1.0 / exponent_h))\n",
    "        return dist\n",
    "\n",
    "    @staticmethod\n",
    "    def minimum_distance(self, cord1, cord2):\n",
    "        # min(|x1-y1|, |x2-y2|, |x3-y3|, ...)\n",
    "        dist = float('inf')\n",
    "        if ((type(cord1) == int and type(cord2) == int) or ((type(cord1) == float and type(cord2) == float))):\n",
    "            dist = math.fabs(cord1 - cord2)\n",
    "        else:\n",
    "            for i, j in zip(cord1, cord2):\n",
    "                temp_dist = math.fabs(i - j)\n",
    "                if (temp_dist < dist):\n",
    "                    dist = temp_dist\n",
    "        return dist\n",
    "\n",
    "    @staticmethod\n",
    "    def maximum_distance(self, cord1, cord2):\n",
    "        # max(|x1-y1|, |x2-y2|, |x3-y3|, ...)\n",
    "        dist = float('-inf')\n",
    "        if ((type(cord1) == int and type(cord2) == int) or ((type(cord1) == float and type(cord2) == float))):\n",
    "            dist = math.fabs(cord1 - cord2)\n",
    "        else:\n",
    "            for i, j in zip(cord1, cord2):\n",
    "                temp_dist = math.fabs(i - j)\n",
    "                if (temp_dist > dist):\n",
    "                    dist = temp_dist\n",
    "        return dist\n",
    "\n",
    "    @staticmethod\n",
    "    def manhattan(self, cord1, cord2):\n",
    "        # |x1-y1| + |x2-y2| + |x3-y3| + ...\n",
    "        dist = 0.0\n",
    "        if ((type(cord1) == int and type(cord2) == int) or ((type(cord1) == float and type(cord2) == float))):\n",
    "            dist = math.fabs(cord1 - cord2)\n",
    "        else:\n",
    "            for i, j in zip(cord1, cord2):\n",
    "                dist += math.fabs(i - j)\n",
    "        return dist\n",
    "\n",
    "    @staticmethod\n",
    "    def eucledian(self, cord1, cord2):\n",
    "        dist = 0.0\n",
    "        if ((type(cord1) == int and type(cord2) == int) or ((type(cord1) == float and type(cord2) == float))):\n",
    "            dist = math.pow((cord1 - cord2), 2)\n",
    "        else:\n",
    "            for i, j in zip(cord1, cord2):\n",
    "                dist += math.pow((i - j), 2)\n",
    "        return math.pow(dist, 0.5)\n",
    "\n",
    "    # =========== Distance Calculation Ends ============== #\n",
    "\n",
    "    def __init__(self, dimensions=(8, 5), all_weights=(0.1, 0.2), fileName=\"iris\"):\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dimensions : dimension of the neural network\n",
    "            all_weights : the optimal weights we get from the bio-algoANN models\n",
    "        \"\"\"\n",
    "\n",
    "        self.allPop_Weights = []\n",
    "        self.allPopl_Chromosomes = []\n",
    "        self.allPop_ReceivedOut = []\n",
    "        self.allPop_ErrorVal = []\n",
    "\n",
    "        self.all_weights = all_weights\n",
    "\n",
    "        self.fitness = []\n",
    "\n",
    "        # ================== Input dataset and corresponding output ========================= #\n",
    "\n",
    "        self.fileName = fileName\n",
    "        self.fileName += \".csv\"\n",
    "        data = pd.read_csv(self.fileName)\n",
    "\n",
    "        classes = []\n",
    "        output_values_expected = []\n",
    "        input_values = []\n",
    "\n",
    "        # ~~~~ encoding ~~~~#\n",
    "\n",
    "        # labelencoder = LabelEncoder()\n",
    "        # data[data.columns[-1]] = labelencoder.fit_transform(data[data.columns[-1]])\n",
    "\n",
    "        # one hot encoding - for multi-column\n",
    "        # enc = OneHotEncoder(handle_unknown='ignore')\n",
    "        # combinedData = np.vstack((data[data.columns[-2]], data[data.columns[-1]])).T\n",
    "        # print(combinedData)\n",
    "        # y = enc.fit_transform(combinedData).toarray()\n",
    "        # y = OneHotEncoder().fit_transform(combinedData).toarray()\n",
    "\n",
    "        #\n",
    "        y = LabelBinarizer().fit_transform(data[data.columns[-1]])\n",
    "        # print(y)\n",
    "\n",
    "        # ~~~~ encoding ends~~~~#\n",
    "\n",
    "        for j in range(len(data)):\n",
    "            output_values_expected.append(y[j])\n",
    "\n",
    "        # print(output_values_expected)\n",
    "\n",
    "        input_values = []\n",
    "        for j in range(len(data)):\n",
    "            b = []\n",
    "            for i in range(1, len(data.columns) - 1):\n",
    "                b.append(data[data.columns[i]][j])\n",
    "            input_values.append(b)\n",
    "\n",
    "        self.X = input_values[:]\n",
    "        self.Y = output_values_expected[:]\n",
    "\n",
    "        # input and output\n",
    "        self.X = input_values[:]\n",
    "        self.Y = output_values_expected[:]\n",
    "\n",
    "        self.dimension = dimensions\n",
    "        # print(self.dimension)\n",
    "\n",
    "        # ================ Finding Initial Weights ================ #\n",
    "\n",
    "        self.pop = []  # weights\n",
    "        reshaped_all_weights = []\n",
    "        start = 0\n",
    "        for i in range(len(self.dimension) - 1):\n",
    "            end = start + self.dimension[i + 1] * self.dimension[i]\n",
    "            temp_arr = self.all_weights[start:end]\n",
    "            w = np.reshape(temp_arr[:], (self.dimension[i + 1], self.dimension[i]))\n",
    "            reshaped_all_weights.append(w)\n",
    "            start = end\n",
    "        self.pop.append(reshaped_all_weights)\n",
    "\n",
    "        self.init_pop = self.all_weights\n",
    "\n",
    "    # ================ Initial Weights Part Ends ================ #\n",
    "\n",
    "\n",
    "    def Predict(self, chromo):\n",
    "        # X, Y and pop are used\n",
    "        self.fitness = []\n",
    "        total_error = 0\n",
    "        m_arr = []\n",
    "        k1 = 0\n",
    "        for i in range(len(self.dimension) - 1):\n",
    "            p = self.dimension[i]\n",
    "            q = self.dimension[i + 1]\n",
    "            k2 = k1 + p * q\n",
    "            m_temp = chromo[k1:k2]\n",
    "            m_arr.append(np.reshape(m_temp, (p, q)))\n",
    "            k1 = k2\n",
    "\n",
    "        y_predicted = []\n",
    "        for x, y in zip(self.X, self.Y):\n",
    "\n",
    "            yo = x\n",
    "\n",
    "            for mCount in range(len(m_arr)):\n",
    "                yo = np.dot(yo, m_arr[mCount])\n",
    "                yo = self.sigmoid(yo)\n",
    "            \n",
    "            # converting to sklearn acceptable form\n",
    "            max_yo = max(yo)\n",
    "            for y_vals in range(len(yo)):\n",
    "                if(yo[y_vals] == max_yo):\n",
    "                    yo[y_vals] = 1\n",
    "                else:\n",
    "                    yo[y_vals] = 0\n",
    "            y_predicted.append(yo)\n",
    "        return (y_predicted, self.Y)\n",
    "\n",
    "    def main(self):\n",
    "        Y_PREDICT, Y_ACTUAL = self.Predict(self.init_pop)\n",
    "        Y_PREDICT = np.array(Y_PREDICT)\n",
    "        Y_ACTUAL = np.array(Y_ACTUAL)\n",
    "        \n",
    "        n_classes = 3\n",
    "        \n",
    "        label_binarizer = LabelBinarizer()\n",
    "        label_binarizer.fit(range(n_classes))\n",
    "        Y_PREDICT = label_binarizer.inverse_transform(np.array(Y_PREDICT))\n",
    "        Y_ACTUAL = label_binarizer.inverse_transform(np.array(Y_ACTUAL))\n",
    "        \n",
    "        # find error\n",
    "        \n",
    "        #print(\"\\n Actual / Expected\", Y_ACTUAL)\n",
    "        #print(\"\\n Predictions\", Y_PREDICT)\n",
    "        #print(\"\\n\\nConfusion Matrix\")\n",
    "        #print(confusion_matrix(Y_ACTUAL, Y_PREDICT))\n",
    "        \n",
    "        #print(\"\\n\\nClassification Report\")\n",
    "        target_names = ['class 0', 'class 1', 'class 2']\n",
    "        #print(classification_report(Y_ACTUAL, Y_PREDICT, target_names=target_names))\n",
    "        #print(\"\\n\\n\\n\")\n",
    "        return accuracy_score(Y_ACTUAL, Y_PREDICT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6cab7fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for inputting data :  0.00897526741027832\n",
      "============ Calling PSO to get best weights ===============\n",
      "--------------GENERATION 0-----------\n",
      "200.12236334211866\n",
      "--------------GENERATION 1-----------\n",
      "197.83425756102932\n",
      "--------------GENERATION 2-----------\n",
      "172.0306734189248\n",
      "--------------GENERATION 3-----------\n",
      "191.00035591011817\n",
      "--------------GENERATION 4-----------\n",
      "235.0\n",
      "--------------GENERATION 5-----------\n",
      "205.99999954929967\n",
      "--------------GENERATION 6-----------\n",
      "196.7939819059223\n",
      "--------------GENERATION 7-----------\n",
      "157.18943661202914\n",
      "--------------GENERATION 8-----------\n",
      "154.074600233973\n",
      "--------------GENERATION 9-----------\n",
      "177.5637934189677\n",
      "--------------GENERATION 10-----------\n",
      "169.0072616660915\n",
      "--------------GENERATION 11-----------\n",
      "197.99993094311418\n",
      "--------------GENERATION 12-----------\n",
      "246.5238013303858\n",
      "--------------GENERATION 13-----------\n",
      "194.979180072361\n",
      "--------------GENERATION 14-----------\n",
      "200.984595156022\n",
      "--------------GENERATION 15-----------\n",
      "202.99997302696332\n",
      "--------------GENERATION 16-----------\n",
      "199.94116715827354\n",
      "--------------GENERATION 17-----------\n",
      "229.99999986023215\n",
      "--------------GENERATION 18-----------\n",
      "219.00107288645742\n",
      "--------------GENERATION 19-----------\n",
      "209.79829959151832\n",
      "--------------GENERATION 20-----------\n",
      "246.92450630042117\n",
      "--------------GENERATION 21-----------\n",
      "239.98643239958773\n",
      "--------------GENERATION 22-----------\n",
      "244.9999965618308\n",
      "--------------GENERATION 23-----------\n",
      "245.9999953484945\n",
      "--------------GENERATION 24-----------\n",
      "244.90324180845928\n",
      "--------------GENERATION 25-----------\n",
      "243.956952462726\n",
      "--------------GENERATION 26-----------\n",
      "221.4630994485355\n",
      "--------------GENERATION 27-----------\n",
      "213.999954273545\n",
      "--------------GENERATION 28-----------\n",
      "213.9861502197389\n",
      "--------------GENERATION 29-----------\n",
      "207.00830932618348\n",
      "--------------GENERATION 30-----------\n",
      "210.13547822078073\n",
      "--------------GENERATION 31-----------\n",
      "214.42581361003653\n",
      "--------------GENERATION 32-----------\n",
      "221.14311597080825\n",
      "--------------GENERATION 33-----------\n",
      "199.92772655560898\n",
      "--------------GENERATION 34-----------\n",
      "238.83064471232822\n",
      "--------------GENERATION 35-----------\n",
      "203.99999989321682\n",
      "--------------GENERATION 36-----------\n",
      "206.99999999999721\n",
      "--------------GENERATION 37-----------\n",
      "216.9924738230851\n",
      "--------------GENERATION 38-----------\n",
      "219.96945766882584\n",
      "--------------GENERATION 39-----------\n",
      "221.91807092832536\n",
      "--------------GENERATION 40-----------\n",
      "215.891128085809\n",
      "--------------GENERATION 41-----------\n",
      "205.47446453808234\n",
      "--------------GENERATION 42-----------\n",
      "207.18457137178265\n",
      "--------------GENERATION 43-----------\n",
      "238.0237835143867\n",
      "--------------GENERATION 44-----------\n",
      "236.7759995615783\n",
      "--------------GENERATION 45-----------\n",
      "252.1431055893302\n",
      "--------------GENERATION 46-----------\n",
      "239.37466310357357\n",
      "--------------GENERATION 47-----------\n",
      "240.9351902773113\n",
      "--------------GENERATION 48-----------\n",
      "226.59764222389074\n",
      "--------------GENERATION 49-----------\n",
      "236.9999821013482\n",
      "--------------GENERATION 50-----------\n",
      "209.98083118606056\n",
      "--------------GENERATION 51-----------\n",
      "199.0988485585628\n",
      "--------------GENERATION 52-----------\n",
      "206.2359277541838\n",
      "--------------GENERATION 53-----------\n",
      "233.00006522863808\n",
      "--------------GENERATION 54-----------\n",
      "233.99999320465656\n",
      "--------------GENERATION 55-----------\n",
      "231.99895231569053\n",
      "--------------GENERATION 56-----------\n",
      "217.86262151301491\n",
      "--------------GENERATION 57-----------\n",
      "229.00964369853915\n",
      "--------------GENERATION 58-----------\n",
      "226.35968687587408\n",
      "--------------GENERATION 59-----------\n",
      "228.5906028767219\n",
      "--------------GENERATION 60-----------\n",
      "226.27713076924184\n",
      "--------------GENERATION 61-----------\n",
      "222.9741967620329\n",
      "--------------GENERATION 62-----------\n",
      "218.6129515600232\n",
      "--------------GENERATION 63-----------\n",
      "207.76710094027595\n",
      "--------------GENERATION 64-----------\n",
      "209.07841481010462\n",
      "--------------GENERATION 65-----------\n",
      "208.09249999294457\n",
      "--------------GENERATION 66-----------\n",
      "240.51808277651017\n",
      "--------------GENERATION 67-----------\n",
      "222.99992144846485\n",
      "--------------GENERATION 68-----------\n",
      "213.98158701647458\n",
      "--------------GENERATION 69-----------\n",
      "219.99978489899797\n",
      "--------------GENERATION 70-----------\n",
      "237.99204182803186\n",
      "--------------GENERATION 71-----------\n",
      "239.01970238287063\n",
      "--------------GENERATION 72-----------\n",
      "232.99997613401152\n",
      "--------------GENERATION 73-----------\n",
      "254.82401249345375\n",
      "--------------GENERATION 74-----------\n",
      "254.67759720734384\n",
      "--------------GENERATION 75-----------\n",
      "209.76004575230922\n",
      "--------------GENERATION 76-----------\n",
      "228.87506217389023\n",
      "--------------GENERATION 77-----------\n",
      "219.4686011017059\n",
      "--------------GENERATION 78-----------\n",
      "231.99976776949367\n",
      "--------------GENERATION 79-----------\n",
      "233.99999968274776\n",
      "--------------GENERATION 80-----------\n",
      "237.99999999341412\n",
      "--------------GENERATION 81-----------\n",
      "237.99999905619921\n",
      "--------------GENERATION 82-----------\n",
      "215.83021147454986\n",
      "--------------GENERATION 83-----------\n",
      "233.97473784176975\n",
      "--------------GENERATION 84-----------\n",
      "203.59309252176885\n",
      "--------------GENERATION 85-----------\n",
      "189.5550839534414\n",
      "--------------GENERATION 86-----------\n",
      "204.94696116597908\n",
      "--------------GENERATION 87-----------\n",
      "203.9848821411003\n",
      "--------------GENERATION 88-----------\n",
      "205.99940862001532\n",
      "--------------GENERATION 89-----------\n",
      "213.96799111967206\n",
      "--------------GENERATION 90-----------\n",
      "219.88937680685063\n",
      "--------------GENERATION 91-----------\n",
      "211.9588540407695\n",
      "--------------GENERATION 92-----------\n",
      "212.9595794049663\n",
      "--------------GENERATION 93-----------\n",
      "215.04151622201044\n",
      "--------------GENERATION 94-----------\n",
      "243.79673691580044\n",
      "--------------GENERATION 95-----------\n",
      "244.88191417364578\n",
      "--------------GENERATION 96-----------\n",
      "247.84155442563264\n",
      "--------------GENERATION 97-----------\n",
      "214.47863358856478\n",
      "--------------GENERATION 98-----------\n",
      "216.06847333067907\n",
      "--------------GENERATION 99-----------\n",
      "221.79504608099657\n",
      "Global :  40.41821041277691\n",
      "Time taken :  35.46318531036377\n",
      "\n",
      " Fitness :  40.41821041277691 \n",
      " Best Weights :  [ 36.51255161 -60.29857641  29.44535418 ... -55.82411646  -3.26965203\n",
      " -98.37460393] \n",
      " Dimensions :  [4, 100, 10, 3]\n",
      "Time Taken :  35.48911643028259\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "i = InputData(fileName=\"../ANN/iris\")\n",
    "input_val, output_val = i.main()\n",
    "end_time = time.time()\n",
    "print(\"Time for inputting data : \", end_time - start_time)\n",
    "        \n",
    "print(\"============ Calling PSO to get best weights ===============\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "a = psoAnn(initialPopSize=100, m=10, input_values=input_val, output_values_expected=output_val, iterations = 100, dimensions = [100,10])\n",
    "\n",
    "fit, b, weights, dim, all_gen_best_weight = a.main()\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Time taken : \", end_time - start_time)\n",
    "\n",
    "print(\"\\n Fitness : \", fit, \"\\n Best Weights : \", weights, \"\\n Dimensions : \", dim)\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "x=b[:]\n",
    "z=[i for i in range(0,100)]\n",
    "plt.plot(z,x)\n",
    "\n",
    "plt.title(\"PSO\")\n",
    "plt.ylabel(\"Fitness\")\n",
    "plt.xlabel(\"Time\")\n",
    "end_time = time.time()\n",
    "print(\"Time Taken : \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "676443f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============= MLP Program Begins ============\n",
      "Training\n",
      "Time taken =  0.006979465484619141\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n============= MLP Program Begins ============\")\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"Training\")\n",
    "m = MultiLayerPerceptron(fileName=\"../ANN/iris_train\", dimensions=dim, all_weights=weights)\n",
    "m.main()\n",
    "end_time = time.time()\n",
    "print(\"Time taken = \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c834af83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n",
      "Time taken =  0.004986286163330078\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Testing\")\n",
    "m = MultiLayerPerceptron(fileName=\"../ANN/iris_test\", dimensions=dim, all_weights=weights)\n",
    "m.main()\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Time taken = \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17e52f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6583333333333333\n",
      "0.6583333333333333\n",
      "0.6583333333333333\n",
      "0.6583333333333333\n",
      "0.6583333333333333\n",
      "0.6583333333333333\n",
      "0.6\n",
      "0.825\n",
      "0.825\n",
      "0.825\n",
      "0.825\n",
      "0.825\n",
      "0.825\n",
      "0.825\n",
      "0.825\n",
      "0.825\n",
      "0.825\n",
      "0.825\n",
      "0.825\n",
      "0.825\n",
      "0.825\n",
      "0.825\n",
      "0.8333333333333334\n",
      "0.8333333333333334\n",
      "0.8333333333333334\n",
      "0.8333333333333334\n",
      "0.8333333333333334\n",
      "0.8333333333333334\n",
      "0.8333333333333334\n",
      "0.8333333333333334\n",
      "0.8333333333333334\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n",
      "0.85\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Iterations')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_accuracy = []\n",
    "for weights in all_gen_best_weight:\n",
    "    m = MultiLayerPerceptron(fileName=\"../ANN/iris_train\", dimensions=dim, all_weights=weights)\n",
    "    accuracy_val = m.main()\n",
    "    print(accuracy_val)\n",
    "    all_accuracy.append(accuracy_val)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "x=all_accuracy[:]\n",
    "z=[i for i in range(len(x))]\n",
    "plt.plot(z,x)\n",
    "\n",
    "plt.title(\"PSO Algorithm\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078982f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
